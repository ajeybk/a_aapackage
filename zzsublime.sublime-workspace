{
	"auto_complete":
	{
		"selected_items":
		[
		]
	},
	"buffers":
	[
		{
			"contents": "##############################################################################\nApple ID  765650\n\nFrench Account\nbrookn341 gmail  Elise237\n\nJapanese Account :\nnoelkev3 gmai  Elise237.\n\napple id \nnoelkev0  Sophie237\nhttps://appleid.apple.com/#!&page=signin\n\n\napplid\nnoelkev3\nElise237.\n\nlutine lisieux\n\n\n\niPad1\nModèle : iPad Air 2\nVersion :iOS 9.3.1\nN° de tél : (080) 653-13935\nNº de série : DMPNMLL0G5YL\nIMEI : 35 589006 211034 6\n\n\n\n\nnoelkev0@gmail.com\n3D8UwTnM\n\n\nhttps://moments.pastbook.com/admin/book/bdb49a07e63092d5c0ccb764bab88afb/\n\n\nAmazon Japan \nUSA :\nnoelkev0 gmail\nnagisa237.\n\n\namazon aws\nnoelkev0 gmail\ngojersio936\n\namazon US\nnoelkev0\n\n\nfacebook\nbrookm291\nelise237.\n\n\nupwork\nyakimono\nelise237.\nlutine\n\n\n\nrakuen\nnagisa237.\n\n\nShipped with ヤマト運輸\nTracking ID \n\n#################################################################################\ntelephone\n090 3599 1807\n\n\n080 4119 4019\ngojersio237\n#################################################################################\n#################################################################################\n\n-------------------------------------------------------------\nLinkedin reset passwords\nnoelkevin1@gmail.com\ntokyoparis237.\n\n\nUQ mobile\n090 3599 1807\n4096\nnoelkevin1\n4091\n\n\n\nresearchgate account\nnoelkevin1@gmail.com\nsophie237\n\n\n\n注文内容がショップに送信されました。\nご登録いただいたアドレスに確認のメールをお送りいたします。\n注文番号：217830-20171123-00525719\n\ns\n\n\nVotre demande a été enregistrée sous le numéro : 2702323\n \nPour des raisons réglementaires, il sera répondu à votre demande exclusivement par voie postale.\n \nCompte tenu des délais de traitement et d'acheminement postal, il est inutile de renouveler votre demande ou d'engager des démarches avant le 20/01/2018.\n\n\n\n\n\n\n#####################     ############################################################################################\nnom prenom\n02 51  77 36 99\n\nVotre demande de copie/d'extrait d'acte d'état civil, concernant Kevin Noel, \na été enregistrée sous le numéro 2655748.\n\n\n\n\n\nnoel kevin  \ncoree du sud. 2015 juillet\n\n\n\n\n\n\nSet-ItemProperty -Path \"HKLM:\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters\" SMB1 -Type DWORD -Value 1 –Force  \n\n\nDetect:\n\nGet-Item HKLM:\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters | ForEach-Object {Get-ItemProperty $_.pspath}\nDefault configuration = Enabled (No registry key is created), so no SMB1 value will be returned\n\n\n\nzenbook\nelise237\n\n\nsumitocard\ntokyoparis237.\n\n\n\nskype\nnoekevin123   \nnoelkev3@gmail elise237.\n\n\n\ngithub account\narita37\nnoelkev0 @gmail .com\ntokyoparis237.\n\n\nPypi \nArita37\nParistokyo237.\n\n\nRakuten website\nnoelkev0 gmail\ngojersio37\n\n\n\n\n\nRakuten\nnoelkev0\ngojersio237\nBank pin: 4096\n\nRegistration number\n　お客さまの登録番号　　　HA15202436\n　お客さまのアクセスキー　 4d47a7\nNoel\nKevin\n\n\n\n\n\nHidetoshi Uchiyama <uchiyama@unerry.co.jp>\n\nMakiko Uchiyama <makiko.uchiyama@unerry.co.jp>\n\n\nunerry_all@unerry.co.jp\n\n\n\n\n\n\n\n\n\n\n#################################################################################\n\nSkype \nkevintokyo1 elise238\nnaomitsukamoto   sophie237\n\nskype\nnoelkev0   elise237.  (web skype)\nnoelkev3  sophie237.\n\n\n386199\n\n\npaypl\nnoelkevin1\nElise237\n\n\n\nSite Ground\nsolut871\nbunkyo237\n\n\n\nmailchimp\nportfolioai\nBunkyo237.\n\n\n\n090     3599   1807\n\nyakimonofr\ntokyoparis 237\n\n\n\ncitibank / smbc  / prestia\nNOELKEVIN0\n\ngojersio237\n\npin 4091\nid noelkevin\n\n\n\nExcel 2013\nMicrosoft account\nnoelkev0@gmail.com\ngojersio231\n\nPremier mois, votre abonnement sera renouvel?automatiquement au prix de ? 10,00 (EUR) par mois, ou au tarif en vigueur. Vous pouvez g?er les d?ails de votre abonnement ou annuler celui-ci ?tout moment en visitant la page http://www.office.com/myaccount. Gr?e ?Office 365 Home, vous pouvez acc?er ?\n\n\n\n\nhttps://stores.office.com/myaccount/home.aspx\n\n\n\nboingo internet wifi\nbrookm291\n\n\nBitdefender\nbrookm291 gmail .com\nElise237.\n\n\n\n######### Gmail ####################################################\nnoelkev0  gmail\nkubo237.\n\n2375 0338\t\n1907 1056\n5751 2756\t\n0008 5899\n6704 4627\t\n3740 0515\n9428 6315\t\n4408 1646\n9830 6383\t\n2408 1931\n\n\n\n\n\nyakimonofr\ntokyoparis237\nbackup\n8715 7898\t\n9919 8697\n6438 2701\t\n1717 1189\n7097 5994\t\n6621 3047\n5576 2534\t\n0619 0051\n0693 4068\t\n0812 3726\n\n\n\nnoelkev3@gmail.com\ngojersio237\n\nBackup code\n2940 0062\t\n2977 2138\n7884 0264\t\n6641 3886\n8493 8627\t\n3031 9008\n5979 4242\t\n8004 9050\n6316 3178\t\n0030 5775\n \n\n\nbrookm291@ gmail\nsophie237.\nBackup code\n 3068 9039    7055 8642\n 3000 6478    6047 4408\n 2716 2145    6281 3478\n 7523 3804    3887 0812\n 7791 4563    6421 0355\n \n \n \n\nnoelkev4@gmail.com\nelise237\nbaskyruwwxzfjzrf\n\n\n\nnoelkevin1 gmail.com\nkyoto237. \n\niphone aznaowjvvaxxgsvo\nBackup verification codes\n2677 9981\t\n7211 5824\n7158 5810\t\n3280 3594\n9221 8276\t\n6977 3408\n4076 9746\t\n0605 9005\n0033 9661\t\n1391 905\n\n\n\nbrookn341 gmail\nsophie237.\n0440 9068\t\n7576 6435\n8955 8564\t\n8547 2685\n7865 5664\t\n1340 4283\n8670 5287\t\n1575 6851\n1676 7753\t\n8809 8763\n\n\n\nnoekev0@hush.com\ntomoko237\n\n\nNOELKEVIN1\ngojersio237\n\n\n\n\ndropbox\nnoelkevin1 gmail\nelise237\n\n\nupwork\nelise237.\n\n\n\n\n\n\n##########################################################################################################################\n##########################################################################################################################\nJPLT\nbrookm291@gmail.com\nsophie237\nYour MyJLPT ID : p4q7s9s\nAP0000637965\n\nAcceptance Number\n\nApplication Acceptance Number    AP0000475493\n\n\nAmazon Japan \nnoelkev0 gmail\ngojersio237.\n\n\nwindows 10\naccount\nnoelkev0\nelise237.\n\n\n\namazon aws\nnoelkev0 gmail\ngojersio936\n\n\n\nFrom Firefox, connect to Instance:\nuser name:   ubuntu\nkeypir lcation: D:\\_devs\\aws\\keypairs\\\n\nPublic IP\n52.78.206.83\n\ntightVNC passwor:  elise237\n52.78.206.83:1\n\n\n#-------Window Graphics for Ubuntu:\n#Only the core functions\nsudo apt-get install lxde-core  \n\n#Many apps : 1 Go\nsudo apt-get install lxde\n\n\n\n\n\n\n#------------------------------------------------------------------\nConnection to EC2  with VNC Screen\n\nSetup Security Group\nCustom TCP rule    Port 5901\n\n\nOn Local Windows, Launch TighVNC:\nec2-52-79-79-1.ap-northeast-2.compute.amazonaws.com:1\n\nVNCpassword: elise237\n\n\n\n\n\n#------------------------------Install Packages----------------------------------------------\nGet latest url https://repo.continuum.io/archive/index.html\n\nIn Terminal, do\n\n   wget https://repo.continuum.io/archive/Anaconda2-4.2.0-Linux-x86_64.sh\n\n   bash Anaconda2-4.2.0-Linux-x86_64.sh\n\n   source .bashrc\n\n# install folder /home/ubuntu/anaconda2\n\n\n\n#Conda Packages : Error\nconda install -c conda-forge pygmo=1.1.7\n\n\n\n\n\n#------------------------------ Ipython Start----------------------------------------------\nmkdir notebook\ncd notebook\njupyter notebook\n\n\nnohup jupyter notebook\n\n\n6) Enjoy your server! \n\nhttps://ip-address:port/\n\n\n\nhttps://ec2-52-78-105-9.ap-northeast-2.compute.amazonaws.com:8888\n\n\n\n\n#--------------------------------------------------------------------\n\nhttp://yangjie.me/2015/08/26/Run-Jupyter-Notebook-Server-on-AWS-EC2/\n\n\n\n\nWordpress.com Jetpack\nkevin.noel@ai-portfolios.com\nAn3ahgUs86Cwd!#\n\n\n\n--------------------------------------------------------------------------------------\nZapier Gmail  Send Email\n\na.i.portfolios@gmail.com\nbunkyo237.\n\n\n\n\nhttps://zapier.com/app/dashboard\n\n\n\n\nAngel co\nhttps://angel.co/login\nK N (kevin.noel@ai-portfolios.com)\nelise237\n\n\n\n\n\nWebsite Password :\n\n\nbrookm291\nbunkyo237.\n\n\n\nFacebook\nnoelkev3@gmail\nbunkyo237.\n\n\n\n\nai-portfolios\nbrookm291\nkohinata237.\n\n\nkevin.noel@solution-ai.com\nbunkyo987.\n\n\n\nhttps://solution-ai.com:2096/\nmichel.riesterer@solution-ai.com\nsolution654.\n\n\n\n\nLinux password  (be careful of text)\nsophie237\n\n\n\n\n\nAmazon Access :  for EC2\ndata_access\nAKIAJDE3GSLR5FCRIXIQ\nKvmo+MS8OfAKcS9Y5HxNdHWU6T5SAAhse+pftfVF\n\n\n\n\n\n\n\n\nSummary\nThis article describes how to enable and disable Server Message Block (SMB) version 1 (SMBv1), SMB version 2 (SMBv2), and SMB version 3 (SMBv3) on the SMB client and server components.  \n\nWarning: We do not recommend that you disable SMBv2 or SMBv3. Disable SMBv2 or SMBv3 only as a temporary troubleshooting measure. Do not leave SMBv2 or SMBv3 disabled. \n\nIn Windows 7 and Windows Server 2008 R2, disabling SMBv2 deactivates the following functionality:\nRequest compounding - allows for sending multiple SMB 2 requests as a single network request\nLarger reads and writes - better use of faster networks\nCaching of folder and file properties - clients keep local copies of folders and files\nDurable handles - allow for connection to transparently reconnect to the server if there is a temporary disconnection\nImproved message signing - HMAC SHA-256 replaces MD5 as hashing algorithm\nImproved scalability for file sharing - number of users, shares, and open files per server greatly increased\nSupport for symbolic links\nClient oplock leasing model - limits the data transferred between the client and server, improving performance on high-latency networks and increasing SMB server scalability\nLarge MTU support - for full use of 10-gigabye (GB) Ethernet\nImproved energy efficiency - clients that have open files to a server can sleep\nIn Windows 8, Windows 8.1, Windows 10, Windows Server 2012, and Windows Server 2016, disabling SMBv3 deactivates the following functionality (and also the SMBv2 functionality that's described in the previous list):\nTransparent Failover - clients reconnect without interruption to cluster nodes during maintenance or failover\nScale Out – concurrent access to shared data on all file cluster nodes \nMultichannel - aggregation of network bandwidth and fault tolerance if multiple paths are available between client and server\nSMB Direct – adds RDMA networking support for very high performance, with low latency and low CPU utilization\nEncryption – Provides end-to-end encryption and protects from eavesdropping on untrustworthy networks\nDirectory Leasing - Improves application response times in branch offices through caching\nPerformance Optimizations - optimizations for small random read/write I/O\nMore Information\nThe SMBv2 protocol was introduced in Windows Vista and Windows Server 2008.\n\nThe SMBv3 protocol was introduced in Windows 8 and Windows Server 2012.\n\nFor more information about the capabilities of SMBv2 and SMBv3 capabilities, go to the following Microsoft TechNet websites:\n \nServer Message Block overview\n\nWhat's New in SMB\nHow to gracefully remove SMB v1 in Windows 8.1, Windows 10, Windows 2012 R2, and Windows Server 2016\nWindows Server 2012 R2 & 2016: PowerShell methods\n\nSMB v1\n\nDetect:\n\nGet-WindowsFeature FS-SMB1\n\nDisable:\n\nDisable-WindowsOptionalFeature -Online -FeatureName smb1protocol\n\nEnable:\n\nEnable-WindowsOptionalFeature -Online -FeatureName smb1protocol\n\nSMB v2/v3\n\nDetect:\n\nGet-SmbServerConfiguration | Select EnableSMB2Protocol\n\n\n\n\n\n\nInteractive Brokers Paper account:\n\nPrint this page and note the password you specified on the prior page. You will need this information to paper trade. \n\nYour Paper Trading Account application has been submitted, and if received by 4 PM (Eastern Time) on any normal business day, will be processed by the next business day under normal circumstances.\nYour username is:\telvis237\nYour account number is:\tDU519469\n\n\n\nMorning Star :\n\n\n\n\n\n\nAuthentication Keys\nClient ID:\t78kxuyuca1aczo\nClient Secret:\t1a2m55jJitpcbAsx\n\n\n\n\n\n\npass det\n\nivolatility.com\n\nPlease find below your IVolatility.com account access information:\n\n\nUser Name:kelvin123\n:bunkyo237\n\nYou can change your IVolatility.com password here:\n\nhttps://www.ivolatility.com/personal_info.j\n\nThank you,\nIVolatility.com \n\n\nhttp://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID2837664_code2498383.pdf?abstractid=2837664&mirid=1&type=2\n\n\n\n\n\n\n\n\nToutout\n\nnoelkevin1 gmail\nrecovery email kevin.yakimono gmail\nsecret question chien\n\nbrookm291 gmail.com\nrecovery email  kevin.yakimono gmail\nsecret question chien\n\n\n\n\n\n\nVincent Camerlynck\n\n\nCitigroup Global Markets Deutschland AG Co. KGaA. \nREUTERWEG 16 60323, FRANKFURT, AM, GERMANY \nBLZ: 50210900 \nCode SWIFT BIC de la banque: CITI DE FF \nInternational Banking Account Number (IBAN): DE21502109000119754038 \nBank Account Name: Interactive Brokers LLC. \nNum?o de compte bancaire: 0119754038 \nFor further benefit to: U944754 / Kevin Noel \n\n\n\n\n\nDear Mr Carmerlynck,\n\nAm in position in reinsurance hedge program at ING Reinsurance Japan\nfor Japan Variable Annuity hedging program (20 bioUSD), \nand work on the fund VA hedging program and development of fund for VA.\n\nMy profile might interest one of your risk team at BNPIP in Asia-Pac.\n\nPreviously, I have worked at BAML in fund derivatives/structured fund\nand at BNP Paribas IB on Equity/Fund derivatives.\n\nI have a strong business knowledge of Japan Lifer ALM\nand structured/systematic funds in Asia/Pac.\n\nIf you might have some mins. available, \nwould be glad to discuss over a coffee.\n\nThanks\nKind regards.\nKevin Noel-Koide\nM: 0081 80 4119 4019\n\n\n\n\n\n\n\nAm looking for re-location in London\n(ING reinsurance is closing this year in Japan...).\n\nWondering if you have contacts at Nomura/Mizuho/MUFJ JP institutions since\nam pretty familiar with Japanese business culture.\n\nI can speak business japanese (but not written) and have experience\npreviously at BAML and BNP Paribas on risks.\n\nThanks for your time\nKind regards\nKevin Noel-Koide\nM 0081 80 4119 4019\n\n\n\n\n\nBonjour Mr Mathieu,\n\nJe me permets de vous contacter amicalement.\n\nEn position sur les fonds de Japan variable annuity chez ING Reinsurance a Tokyo, peut etre mon profile pourrait interesse l'une de vos equipes (risk/...).\n\nJ'ai une experience precedente chez BAML et BNP Paribas (a HK) sur le fonds structures et strategies systematiques.\n\n\nSi vous avez une seconde, que penseriez vous d'un cafe ?\n\nExcellente journee a vous\nKevin Noel\nTel: 080 4119 4019\nEmail: noelkev3@gmail.com\n\n\n\n rachelle@joveinternational.com\n\n\n\nBonjour Mr Averre.\n\nJe me permets de vous contacter amicalement par Linkedin.\n\nA Tokyo, je suis en activite sur la resinsurance et market risks des hybrides VA, \nchez ING Life Reinsurance (20 MDS d'encours), qui se relocalise pour l'IPO...\n\nPeut etre mon profile pourrait interesse l'une des vos equipes (risks, treasury,...),\nsachant que j'ai aussi une experience  precedente chez Bank of America Merrill Lynch \net chez BNP Paribas, apres avoir fait Centrale.\n\nJe reste disponible si vous avez une seconde pour un cafe.\n\nEn vous souhaitant une excellente journee.\nAmicalement.\nKevin Noel\nM: 0081 80 4119 4019\n\n\n\n\n\nJ'envisage de me re-diriger a Londre ou mon expertise pourrait etre utile, notamment, vers les institutions japonaises car je parle japonais couramment (mais pas encore l'ecrit..).\n\n\n\nAuriez vous des contacts avec les institutions japonaises (Nomura/MUFJ, Mizuho) ?\n\nEn vous souhaitant une excellente journee.\nAmicalement.\nKevin\nM: 0081 80 4119 4019\n\n\n\n\n\n\n\nBonjour Mr Poullaouec,\n\nJe me permets de vous contacter amicalement par Linkedin.\n\nJe suis actuellement sur les fonds de Variable Annuity Japan chez ING Tokyo. \nJe suis specialiste des fonds structures (systematique/smart beta/multi asset) sur Japan+Asie apres une experience chez BNP/BAML.\n\nPeut etre mon profile pourrait interesse l'une de vos equipes.\n\nJe restes disponible pour discuter a l'occasion.\nExcellente journee a vous\nKevin Noel\nEmail: noelkev4@gmail.com\n\n\n\n\n\n\n\n\n\nmarie.portier@quanteam.co.uk\n\nBonjour madame Marie Portier, \n\nJe me permets de vous contacter amicalement par Linkedin.\n\nJe suis en activite sur la resinsurance des VA au Japon, chez ING Life Reinsurance (ING Life reinsurance ferme au Japon).\n\nJ'envisage de me re-diriger a Londre ou mon expertise pourrait etre utile, notamment, vers les institutions japonaises car je parle japonais couramment (mais pas encore l'ecrit..).\n\nJ'ai aussi une experience  precedente chez BAML et BNP Paribas, apres avoir fait Centrale.\n\nAuriez vous des contacts avec les institutions japonaises (Nomura/MUFJ, Mizuho) ?\n\nEn vous souhaitant une excellente journee.\nAmicalement.\nKevin\nM: 0081 80 4119 4019\n\n\n\n\n\n\nBonjour Mr Francois Marmion\n\nJe me permets de vous contacter amicalement par Linkedin.\n\nJe suis en activite sur la resinsurance des VA au Japon, chez ING Life,\net peut etre mnon profile pourrait interesse l'une de vos equipes  chez Nomura(risks ou autres)\n(ING Life reinsurance ferme au Japon).\n\nNotamment, j'essaye de me diriger vers les institutions japonaises car je parle japonais couramment\n(mais pas encore l'ecrit..) et possde une excellente connaissance de l'ALM des Lifer Japonais.\n\nJ'ai aussi une experience  precedente chez BAML et BNP Paribas.\n\nJe suis disponible pour une discussion amicale, si vous avez un moment.\n\nEn vous souhaitant une excellente journee\nAmicalement.\nKevin\n\n\n\n\n\n\n\nFrancais en activite a Tokyo sur market risks de reinsurance pour Lifer Japonais chez ING Life, j'envisage de me re-diriger a Londres ou mon expertise pourrait etre utile.\n(Raison ING Life ferme au Japon...)\n\nEn particulier, auriez vous des contacts avec Nomura/Mizuho ?\n\nJe parle japonais courant (mais pas l'ecrit) et une experience chez BAML et BNP Paribas.\n\nDisponible pour discussion.\n\nAmicalement\nKevin\n0081 80 4119 4019\n\n\n\n\n\n\n\n\nBonjour Laetitia,\n\nFrancais en activite a Tokyo sur market risks de reinsurance pour Lifer Japonais chez ING Life, \nj'envisage de me re-diriger a Londres ou mon expertise pourrait etre utile.\n(Raison ING Life ferme au Japon...)\n\nEn particulier, auriez vous des contacts avec Nomura/Mizuho ?\n\nJe parle japonais courant (mais pas l'ecrit) et une experience chez BAML et BNP Paribas.\n\nDisponible pour discussion.\n\nAmicalement\nKevin\n0081 80 4119 4019\n\n\n\n\n\n\n\nDear Emily san,\n\nI contact you kindly through Linkedin.\n\nAm in position in market risk at ING Reinsurance Japan,\ncovering Japanese Insurance Variable Annuity. Am looking for re-location in London\nin an japanese institution since am french and speaking Japanese.\n\nMy profile might fit one of your needs in Market Risk Fixed Income, \nFunding Risk and CVA...\n\nI have strong technical experience at BAML and BNP Paribas on Front Office risks.\n\nIf you have some time, we might discuss over the phone.\n\nThanks for your time\nKind regards\nKevin Noel-Koide\nM 0081 80 4119 4019\nnoelkev3@gmail.com\n\n\n\nlive.barcap.com\nkoikenke\ngojersio123\n\n\n\n\n\n\n\n\n\n\n\n\nnoelkev3@gmail.com\nobata235\n\n\n\nMichael Page\nChristopher Snow\n+81 3 6832 8685.\nUS guy, senior recruiter.\n\nConsultant Name:    Christopher Snow\nConsultant Email:    christophersnow@michaelpage.co.jp\nConsultant Tel:    + 81 3 5733 7166\nJob Title:    Fixed Income, FX & Rates Product Control - Associate - Global Investment Bank\nJob Reference:    H1853800\n \n Bonjour Mr Moissinac.\n\nResident a Tokyo,\nje me permets de vous contacter amicalement par Linkedin\n\nAncien de Centrale, et en activite chez ING Reinsurance Japan sur les fonds et VA Japon, peut etre mon profile pourrait interesses l'une de vos equipes de Risk. J'ai une experience chez BAML aussi.\n\nAu plaisir de prendre un cafe, si vous avez un peu de  temps.\n\nBonne journee a vous.\nKevin\n\n\n\n \n Bonjour,\n\nJe me permets de vous contacter amicalement par Linkedin\n\nAncien de Centrale, et en activite chez ING Life Japan sur les fonds et VA Japon, peut etre mon profile pourrait interesses l'une de vos equipes de Risk. J'ai une experience chez BNP aussi.\n\nAu plaisir de prendre un cafe, si vous avez le temps.\nBonne journee a vous.\nKevin\n\n \n \n Equities & Futures Business Risk Control, AVP ? Global US Bank\n  Paulina Oh on + 81 3 5733 7166 quoting jobref H2089060\n  \nMichael Page Website\nnoelkev4@gmail.com\nsophie237\n\n\n  Dear Mr Andy Clubbe,\n\nFollowing this senior position, wondering if the hiring managers might also have some needs with mid level positions (asssociate- AVP) in this risk related departement.\n\nIn this case, I might fit for Associate/AVP level since I have past experience in US IB.\n\n\nThank you for your time.\nKind regards\nKevin Noel-Koide\n\n  \n  \n  \n  \n\nAndy Clubbee\n03 5733 7166\nAndy Clubbe\nConsultant, Financial Services at Michael Page Japan\nEnglish Guy\n\n\n\nMetLife Alico\nDimitri Lorenzon\nChief Risk Officer, \n\nhttps://www.linkedin.com/profile/view?id=93433527&authType=OUT_OF_NETWORK&authToken=B4Sf&locale=en_US&srchid=61422871398529293851&srchindex=16&srchtotal=106&trk=vsrp_people_res_name&trkInfo=VSRPsearchId%3A61422871398529293851%2CVSRPtargetId%3A93433527%2CVSRPcmpt%3Aprimaryhttps://www.linkedin.com/profile/vie w?id=93433527&authType=OUT_OF_NETWORK&authToken=B4Sf&locale=en_US&srchid=61422871398529293851&srchindex=16&srchtotal=106&trk=vsrp_people_res_name&trkInfo=VSRPsearchId%3A61422871398529293851%2CVSRPtargetId%3A93433527%2CVSRPcmpt%3Aprimary\n\n\nPaul Gaspar\nSVP AIG data\n\n\n\n\n\n\n\n\n\n\nPaypal commande@yakimonos.com  elise237\n\nAnonymous China\n@AnonymousChina\nirc: http://webchat.voxanon.net/  channel: #AnonymousChina \n New contact: anonchina@hushmail.co\n \n nettam\n ge\n kyoto237\ngeijitsugallery@gmail.com\n \n http://sortir.telerama.fr/evenement/formulaire\n \n \n     \n Voici vos identifiants de connexion :\n \n eMail : contactparis@yakimonos.com\n Mot de passe : exposition\n Pseudo : contactparis\n\nPrivate VPN\nbrookm291@gmail.com\nSophie237\nEasy installer is located at http://strongvpn.org/vpnclient.shtml <---- click on this link for Mac/Win\nAlso emails with \"Setup Instructions\" sent, please remember if you don't see the emails to check your spam folder.\nWe also have how to's at http://strongvpn.org/setup.shtml\n\n\n\n\nMerci de votre email.\nJe pourrais contacter madame Habaya de votre part (si vou pouvez indiquer son email, merci).\n\nElle peut presenter tout type d'artiste, on choisira apres le theme.\n\nExcellente journee a vous.\nKevin\n\n\n\n\nComplete Application Below \n\nNeed Help? \nContact JobStreetSupport@statestreet.com or 816-871-7888.\n\nState Street Application Job\nnoelkev1\nSophie237\n\nhttps://www.linkedin.com/jobs2/view/13339318?trk=vsrp_jobs_res_name&trkInfo=VSRPsearchId%3A61422871397693388947%2CVSRPtargetId%3A13339318%2CVSRPcmpt%3Aprimary\n\n\nhttps://psh.statestreet.com/psc/HRPRDEREC/ERECRUIT/ERECRUIT/c/HRS_HRAM.HRS_CE.GBL\n\n\nJP Morgan \nnoelkev1\nSophie237\nnoelkev3@gmail.com\n\n\nBlackrock\nnoelkev1\nobata235\n\n\n\nDaichi Frontier Life issued an AUD denominated 110% variable annuity in October 2013 which has raised ?10 billion to date.\n\n\n\n\n\n\n\n \n \nwhatismyserp\ntokyo.yakimono@gmail.com\nstevem999\nyakimono1\n \n imesnoo@gmail.com\n kevinime\n \n paypal\n tokyo.yakimono\n tomoko237\n \n Wikipedia Account\n https://fr.wikipedia.org/wiki/Discussion_utilisateur:Wiki1237\n wiki1237\n sophie237\n \n https://plus.google.com/+Yakimonoparis/posts\n \n \n Bonjour,\n \n Nous sommes une galerie qui faisons des expositions, chez nous a Paris.\n Par exemple, \n \n Telerama.fr est gratuit:\n sortir.telerama.fr/?\n \n \n Event sur Paris\n http://www.evene.fr/\n \n \n On a faison de faire l'inscription comme dans un annuaire, en remplissant\n le formulaire et en contactant les personnes du site.\n \n Merci\n Kevin\n \n \n \n\n \n hacking details\n stevemn17@gmail.com\n montag127\n montag123\n \n \n http://www.hackersinfinity.com/services.html\n\nboutiqueYakimono  kevin.yakimono@gmail.com   elise23\n\nDRI dri Website Gestion: https://www.produhost.net\n14125 jetaime\n\nftp.ceramiquejaponaise.fr\n2545_webmaster\njetaime\n\n922 559 537\nobama\nsophie12\n\nkevinyaki23\n\n7824_yakimono\nkevinyaki23\n\n\n\n7824_kevinnoel\nkevinyaki23\n\n\n\nProduhost\n14125_admin1\nkyoto123\n\n\nmailchimp\nyakimono123\nelise237\n\n\n\nParis\nparis.yakimono@gmail.com\nparis239 \n\nNet Tam\ngeijitsugallery@gmail.com\nkyoto237\n\nFlickr\nyakimonofr\ntokyoparis37\n\nhttp://moz.com/\ntokyo.yakimono\nyakimono23\n\ncopydrive0gmail.com\n\nhttp://bit.ly/IPaehN\n\nhttps://www.citicards.co.jp/JPCRD/jba/ada/InitADAXmlPortletForJP.do?TTC=1&categoryId=4\nCitibank\n4907 1581 0500 869quatre\n664\n07/17\n\n\nZapier 2\nbrookm291@gmail.com\nsophie237\n\nDear Mr Sangjoon Kim,\n\nAm taking opportunity to contact you directly through LinkedIn.\nAm in position re-insurance ING Life Japan on Variable Annuities risk,\nafter an experience in derivatives market (BAML / BNP).\n\nMaybe, my profile might fit inside one of your risk team (operational/market)\nor future needs. If this is the case, and if you have some  time available,\nwould be glad to introduce  myself.\n\nThank you\nKind regards\nKevin Noel\nM: 080 4119 4019\nM: noelkev4@gmail.com\n\nhttp://www.linkedin.com/profile/view?id=39154836&authType=NAME_SEARCH&authToken=32aE&locale=en_US&srchid=61422871395802866027&srchindex=1&srchtotal=14&trk=vsrp_people_res_name&trkInfo=VSRPsearchId%3A61422871395802866027%2CVSRPtargetId%3A39154836%2CVSRPcmpt%3Aprimary\n\n\n\nOperational Risk Management Analyst \nChallenge and Review\nTokyo \n7M to 9M\n\nLeading global financial institutions is currently looking for an ambitious and creative person to join their Operational Risk Management Team as an Analyst.\n\nThis is a very dynamic role which offers the opportunity to gain in depth knowledge of both securities and banking business with front to back office coverage. The role focuses on building relationships and providing guidance in driving operational risk initiatives and tools, including Risk Events Reporting, Risk & Control Self Assessments and Key Risk Metrics.\n\nAs there is no standard approach to doing the job, the ideal candidate will have a dynamic personality with risk background and will be able to show initiative in resolving occurring incidents. Product Control, Audit or Risk exposure of around 3 or less is preferred but there is flexibility. \n\nLanguage Requirements:\n\nEnglish - Fluent \nJapanese - Business - Preferred but not mandatory\n\nFor more information please contact Dragos Giugula at 3560 2659 or e mail to dragos.giugula@hays.co.jp\n\n\n\n\nOrder Number: 503-0244704-3482436\n1 item will be shipped to Kevin Noel    from ????????? (The Book Depository). Estimated delivery: Jun 11, 2014 - Jun 19, 2014\nOrder Number: 503-6565779-6469665\n2 items will be shipped to Kevin Noel    from Amazon.com Int'l Sales, Inc.\nYour delivery has been scheduled with the carrier for:\nMay 31, 2014 8:00 PM - 9:00 PM\n\n\n\n\n\n\nnoelkevin1@gmail.com\nvklpqhcyeykcqesq\n\n\n\nNOELKEVIN1\ngojersio237\n\nnoelkev3@gmail.com\nsophie237\nrecovery email kevin.yakimono\n\n 9344 1564    1608 9871\n 2811 9810    6768 1470\n 8043 2012    2856 4957\n 4532 6234    8735 8709\n 5614 4683    7075 8644\n \n rfexvsxopwuagwer\n\n\n\n\n\nnoelkev4@gmail.com\nelise237\nbaskyruwwxzfjzrf\n\n\nnoekev0@hush.com\ntomoko237\n\nPandabot\n121.115.138.208\n1/13/2014 12:10:25 PM\n\n\nstevem999\n\n\nFTP:\nftp.yakimonos.com\n7824_webmaster\nkevinyaki23\n\n\nBDD\n7824_wp2    \n7824_wordpress2\n\n\n\nWordpress Admin\nwebmaster\nyakimono237\n\n\n\n\n\n\n\nhttps://artjapon.wordpress.com/wp-admin/widgets.php\nBlog en Francais.\n\n\n\nhttp://japanartnews.wordpress.com/\n\nBlog en Anglais\n\n\n\nhttp://geijutsujapan.wordpress.com/\nBlog en Japonais\n\n\nhttps://ifttt.com/buffer\n\n\n\nhttp://yakimonos.wordpress.com/\nBlog en Anglais sur les ceramiques/\n\n\nTraduction, pour 14 mars\n\n\n\n\n\n\nLangeac Agence:\n\n\nimmobilierebeaumarchais@orpi.com\nVincent LIHOREAU <bureaux@immobilieredeboulogne.com>\nGwen Loheac <GLoheac@evolis.fr>\nLucile.GARANDEL@colliers-keops.fr\nSabrina Nataf <snataf@agtbastille.com>\nMathieu GESTIN <mathieu.gestin@gifom.com>\nMyimmo <myimmo75@gmail.com>\nAur?ie Pho-Chheng <aurelie@pointdevente.fr>\nCedric BELILTY <c.belilty@negovalor.com>\nLaurent Nataf <lnataf@agtbastille.com>\nContact Gifom <immo@gifom.com> \nMichael Charles Uzan <mcu@iburoshop.fr>\nm.bordichon@monopole.fr\n\nG.P.I.Transaction <contact@gpitransaction.com>\nIsabelle BOKOBZA <ibokobza@septime.fr>\n\n\n\n\nM?ro Ecole Militaire \n\n\n\n\n   Exposition TAKATORI YAKI, \n   C?amiques Kirei Sabi.\n\n\n\n16 Nov. - 30Nov. 2013\nMardi au Samedi: 13h-18h.\nTel: 09 51 53 29 43\n\n\n\n\nLe fiagro\nartjapon\ntokyo.yakimono@gmail.com\nfigaro123\n\n\n\nTelephone Mr Badros\n01 43 15 04 20\n\n\nhttps://yakimonos.insight.ly/\nkevin.yakimono@gmail.com\nyakimono123\n\n\n\nhttps://www.graphic.jp/shop/myPage.php?func=registNew\ntokyo.yakimono\nsophie237\n\n\n\nBuffer\ntokyo.yakimono@gmail.com\nkyoto237\n\n\n\n\nYakimono Pages with Google Name\nhttps://plus.google.com/+Yakimonoparis/posts\nyakiomonofr@\n\n\nBuffer Update\nYakimono Business Pages:\nhttps://plus.google.com/108195429324354892699/posts\nyakiomonofr@\n\n\nYakimono Paris Gmail\nhttps://plus.google.com/103229134307982565458/posts\n\nhttps://plus.google.com/b/108195429324354892699/108195429324354892699/posts\n\n\n\nTwitter\nhttps://twitter.com/Art_Japon_Paris\n\n\nTumblr\nhttp://photosofjapan.tumblr.com/\n\n\nArt News Japan\nhttp://japanartnews.wordpress.com/\n\nArt Japan Tumblr\nhttp://www.tumblr.com/blog/artjapan\n\n\n\n\nHootSuite\nYakimonofr@gmail\nhttps://hootsuite.com/dashboard\npierre237\n\nPIN Interest\nhttp://www.pinterest.com/japanartparis/japan/\ntokyo.yakimono@gmail.com\n\nPINT Boutique Japon\ncontacts.yakimono@gmail.com\nyakimono123\nhttp://www.pinterest.com/boutiquejapon/\n\n\nParis Post\nFacebook Management\nGalerie Yakimono Facebook Account\ntokyo.yakimono@gmail.com\nyakimono237\n\nhttp://www.pinterest.com/boutiquejapon/pieces-du-japon/\n\n\n\n\nBonjour monsieur, madame,\nNous voudrions faire l'annonce d'une nouvelle galerie dans le 7ime arrondissement:\nGalerie Yakimono, Art Japonais\n29 Rue de L'Exposition, 75007 \nExposition C?amiques Kirei Sabi,\nEsth?ique Japonaise traditionnelle.\n(Mardi-Samedi 13h-18h, Nov-Dec 2014)\nAnnonce sur Ambassade du Japon.\nhttp://www.fr.emb-japan.go.jp/culture/calendrier/paris.html\nCommunique de Presse:\nhttp://www.yakimonos.com/gallery/exposition-paris/exposition-takatori-yaki-ceramique-kirei-sabi/\nEn vous remerciant d'avance\nGalerie Yakimono\n\n\n\n\n\nTumblr\ntokyo.yakimono@gmail.com\ntomoko237\n\n\nPhotos of Japan Post\nsfcrcc86junfj@tumblr.com\n\n\n\nBackgroun image imagevues Themes Abyss\nab_bamboo4.swf\n\n\n\nPost by email :\nsfcrcc86junfj@tumblr.com\n\n\n\nWordPress\nxozo936moda@post.wordpress.com\n\nBlogSpot\nyakimonofr.124@blogger.com\n\n\nLe Japon Forum\nhttp://www.lejapon.org/forum/threads/17093-IM\nPseudo : Pierre237\nNouveau mot de passe : 1TpyJPdq\n \nhttp://www.lejapon.org/forum/content/1267-Vente-Sp%C3%A9ciale-au-profit-des-victimes-du-s%C3%A9isme-de-Fukushima-et-Tohoku\n\n\nForum japon\nsophie237\nsophie123\n\n\n\n\nBonjour,\nEtant une galerie japonaise, nous cherchons un bureau sur Paris.\nPouvons-nous convenir ensemble d'un rendez-vous pour visiter le bien ? \n(Je suis a l'etranger pour l'instant, pourriez vous confirmer par email) \nMerci et bonne journee.\nMr Noel\n\n\n\nRetrouvez cette annonce sur SeLoger.com : Location Bureau | Paris 2?e (75002) - Quartier Vivienne-Gaillon\nCopyright ? SeLoger.com\n\n\nUdpate Tumblr\nsfcrcc86junfj@tumblr.com\n\nTwitter Access\nhttps://twitter.com/Art_Japon_Paris\ntokyo.yakimono@gmail.com\nkyoto237\n\n\n\n\n\n\n#------------Acces -------------------\nftp.yakimonos.cohttps://www.facebook.com/yakimonos/photos_albumsm\n7824_yakim4\nyakim1234567\n\n\n#----------------------\nBase de donnees\nBDD: 7824_wp\n7824_yakimono\nosozeland31\n\n#------------Acces -------------------\nftp.yakimonos.com\n7824_wordpress\nyakim1234567\n\nLe fichier d'exportation a ??sauvegard?sous /var/lib/phpMyAdmin/save/7824_wp2backup1.sql.zip.\n\n\n\nhello work:\nanpe\n\ncpnseiul gratuit, anglais\n\n\nHarassment ING Compliance\nKyowa Sogo Partners\nEmail: ing@kyowa-sogo.gr.jp\nTel : 03-3126-1171 (9:00-17:00)\n\n\n\n\n7824_wordpress2\nyakim1234567\n\n\nHushmail  pour ING Compliance\nnoekev123@hushmail.com\nsophie237\n\n\n\n\n\nDear Mrs Marjolein Van Hellemont,\n\nI took a long time to think before sending this email to you,\nand obviously there would have some consequences,\nespecially on me thereafter. \n\nI thought  I have no other choice, that's am contacting \nexternal compliance officer for advise.\n\nMy goal is not to harm anyboby to disturb organization\nbut to let people know there are some real issues which \nneed to be dealt it approprietely.\n\nObviously, there are review this week and next week by managers\nof my division, so people are under pressure to have \na \"good review\" this week, myself included.....\n\n\nThis concerns ACMS Team at ING Life Japan division,\nmanagers are Karsten Klein and Daniel Heer.\n\nIn the past year, the following events happenned:\n\nFor my goal settings at ING, I have few trainings included as\npart of normal trainings and those training have been\nclearly presented and advocated to me.\n\nOne external training has been canceled explictelty whereas other people\nof my division have participated, reasons this is not adapted to me\nwhereas it was put on my goal settings.....\n\n\nThe other external training have purely canceled (not enough joiner).\n\nThere were an internal training with Peter Chapman, ING trainer\nwhere all the division member (around 20) have participated\nin various sessions, except me, I was excluded.\n\nObviously, I was not invited and did not email of training....\n\nI asked recently the reasons, but am stil waiting for clear answer.\n\n\nConstant pressure of discrimination is day to day, obviously\nthis is very difficult to get evidence.\n\nI could not go internally byt HR/Compliance because \nthey are managers and putting pressure on me and any other person am talking to...\n\nI dont to create trouble in this particular situation: Life Japan going to new company,\nbut I think this one way to find some relief \nand let those managers know there is a minimun of respect for people,\nand systematic discrimination like this training is really hurting and humiliated.\n\n\nI dont know if you can help or not, at least I would to do internally first.\n\n\nThank you for your understanding, time.\nKind regards\nKevin Noel, ACMS division of ING Life Japan.\n\n\n\nFor urgent matters, pls contact Margreet Veenstra at +31 20 541 6469 or\nAstrid van Heezik at + 31 20 504 9643 who will assist you in reaching \nout to another member of the EurAsia Corporate Compliance team.\n\n\n\n\n\n\n\n\n----------------------------------------------------------------------------------------\n\n\nDear Mrs Marjolein Van Hellemont,\n\nFollowing the documentation, your took time to provide me,\nplease find more formal description, hope it would clarify and be explicit:\n\n\nThe fact:\n\n A serie of Soft Skills training (teambuilding/training/MBTI) has been conducted \n by internal ING trainer Peter Chapman where all the ACMS division members\n have participated in various sessions at various time, except myself, showing \n one evidence of discrimination or exclusion in HR training.\n \n\n\nPurpose:\n Obviously, this is not to highlight one item and I do understand sometimes,\n this is feasible or not (especially Budget constraints).\n \n This is to highlight systematic exclusion and this event is one clear example showing it.\n To highlight unformal humiliation by exclusion of training/meeting. \n Of course, there are other examples, but they are informal and not evidence of it... \n Especially informal pressure on people where I am talking to\n \n \n This is not to disturb the organization, this is to raise alert\n that such kind of systematic exclusion,  of behaviour should not be persistent over long time,\n should not go below the minimun line of employee human respect and not lead to humiliation,\n and some safeguard and check should be put in place to assure employee minimun protection\n of abusive decisions.\n \n This is very difficult to raise alert because as an employee I have to follow\n manager decisions and there are consequences of such of alert, especially on me \n thereafter. I spent a long time to think if I should raise or not.\n \n\n\nHow do I know:\n \nDuring some days of the training (ex: one in end december 2013), \nI was alone in my department and also see some training booklets\nof my colleagues on MBTI or First Line Manager, and they are talking about the training at that time\nduring lunch time.\n\nI was the one who did not participate at that time.... \nManager Karsten Klein was present in office during those periods.\n\nOf course I did not receive any invitation email...., probably team members\ngot emails for the different sessions where I dont have access.\n\n\n\n\nFact 1:\n There was another cancelation of training (project management, Prince 2 Training) in 2013 \n where it was mentionned to my goal settings and it was explicitely explained \n through the year by my direct manager.\n \n Japan HR, by email, 1 week before, asked me if I should participate among people of my division,\n I said yes.\n But, division manager confirmed the cancelation, arguing verbally\n this training is not fitting to me and I do not deserve it this year.\n Japan HR acknowledge manager decision.\n \n Of course, I need to follow manager instructions and keep it for myself.\n \n \n \n \n Fact 2:\n Another external HR training has been canceled (Human Communication by Dale Carnegie). \n (here, it was canceled by the external party,  not internally).\n \n \n Two other trainings based on wishlist of technical trainings have been not approved\n by division manager this year reasons: not fitting to me. \n (some other members have been granted).\n \n \n In 2012, This wishlist trainings of techincal skills have been approved by managers, \n (other team members have been granted).\n I understood at that time, there were rotations on such trainings,\n this is mainly at the Division Manager discretion.\n \n \n In  2011, The wishlist training has not been approved.\n I understood at that time other team members have been granted.\n this is mainly at the Division Manager discretion.\n\n \n I got one day training in 2013 :\n     HR communication skills with other member \n     with a specific trainer hired by the Finance/ACMS division.\n     \n     \n I got one serie in training in 2012 :\n     HR communication skills with other members \n     with a specific trainer hired by the Finance/ACMS division.\n \n \n \n Fact 3:\n in 2013, There was a training called \"How to be happy\", organized by the manager Karsten Klein,\n and internal trainer.\n But this is not to gain soft skills but to get some training \"how to be happy.\"\n \n I did not join it because I could feel trust in such trainings given the various\n refusal of soft skills trainings...\n \n \n \n Fact 4:\n For Year End review 2013, happening now, my direct manager informed me by email that\n contrary to previous year, we should not copy and past the detail of goal description,\n training details,\n but just only indicate personal assessment of the year.\n \n I found very strange thats fact, description or training details of the past year\n should not be copy and paste before the personal assessment.\n\n \n As mentionned before, I would like to keep anonymity although I asked to\n my direct manager, by email, why I was excluded of the training by division ACMS\n senior managers : Karsten Klein, Daniel Heer. I still dont have any clear answer\n whereas it was more than one week ago....\n \n \n Hope it would help the investigation and setup minimun safeguards, checks and controls\n to abusive decisions and systematic exclusion.\n \n \n Thank you very much for your time and understanding.\n Kind regards\n Kevin\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n \n \n \n \n \n \n \n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFake Refferer\nhitleap\n\n\nhttp://bitly.com/1iXvoVG\n\nhttps://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fbitly%2Ecom%2F1iXvoVG&urlhash=dL14&trk=NUS_UNIU_SHARE-lnk\n\nhttp://linkd.in/RnjNcw\n\n\n\n\n\n\nhttps://www.linkedin.com/redir/redirect?url=\nhttp%3A%2F%2Fwww%2Ejapantoday%2Ecom%2Fcategory%2Fpolitics%2Fview%2Fabe-visits-louvre-as-he-arrives-in-france&urlhash=VcKp&trk=NUS_UNIU_SHARE-title\n\n\nhttps://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fplus.google.com%2F%2BYakimonoGalleryParis%2Fposts&urlhash=VcKp&trk=NUS_UNIU_SHARE-title\n\n\nhttps://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fwww%2Ejapantoday%2Ecom%2Fcategory%2Fpolitics%2Fview%2Fabe-visits-louvre-as-he-arrives-in-france&urlhash=VcKp&trk=NUS_UNIU_SHARE-title\n\n\n\nhttps://www.linkedin.com/nhome/nus-redirect?url=\n\n\nhttp%3A%2F%2Fhereisthecity%2Ecom%2Fen-gb%2F2014%2F05%2F03%2Fubs-hires-new-global-chairman-of-corporate-client-solutions%2F&urlhash=GGe8&pos=3%3A1&trkToken=action%3DviewArticle%26pageKey%3Dmember-home%26contextId%3DsNUlrLuGaxOweBy1MisAAA%3D%3D%26isSponsored%3Dfalse%26distanceFromViewer%3D1%26aggregationType%3Dnone%26isPublic%3Dtrue%26verbType%3Dlinkedin%3Ashare%26activityId%3Dactivity%3A5869308327346855936%26isDigested%3Dfalse%26isFolloweeOfPoster%3Dfalse%26actorType%3Dlinkedin%3Amember%26feedPosition%3D3%26actorId%3Dmember%3A3305436%26objectId%3Darticle%3A8083358452590499593%26moduleKey%3Dhp_feed%26rowPosition%3D1%26objectType%3Dlinkedin%3Aarticle&tev=0&trk=object-title\n\n\n\n\n\nhttp://www.linkonym.com/\n\nhttp://www.blankreferer.com/#\n\nhttp://bitly.com/1q9dtoM\n\n\n\n\n\n\nWordpress AVADA\nadmin\npierre237\n\n\n\n\n\nWhat are your prefered artists in Edo period ?  and Why ?\nWhat are your prefered artists in Meiji period ?  and Why ?\nWhat are your prefered artists in Showa period ?  and Why ?\nDi you already experience Japanese Tea Ceremony ?\nHow many times do you visit museum a month ?\nDo you have interest in Paris and France , and why ?\nHow much free time do you have (outside of your work) ? \n\n\n\n\nPiece de Bizen Disponible :\"Le long dialogue avec la flamme fait na?re ?l?int?ieur du four des changements impr?isibles, d?o? l?apparence si complexe \"\n\n\n\n\n\n\nBonjour monsieur Dupin,\n\nVoici nous avons deux possibilit? :\n\n  1 Yunomi noir (tasse noir) avec c?amiste de Kyoto\n        Prix: 75 euros + Frais de transport 40 euros.\n\n  1 Yunomi noir de madame Sophie Galle,c?amiste ayant vecu au Japon,\n  dont nous faisons l'exposition le 9 f?rier.  Prix environ : 70 euros\n\nBonne journ? a vous\nKevin pour Yakimono !\n\n\n\n\n\ninisanjulia@gmail.com\nxavier.ragot@cegetel.net\nPhilippe_chatel@hotmail.com\nplavalisica@gmail.com\njoaquim.cerqueira@ca-cib.com \nnognal.lucie@hotmail.fr\nmeluska26@hotmail.fr\nmfchevet@gmail.com\nmarion.lemoussu@wanadoo.fr\nk.kalayciyan@wanadoo.fr\ncchehowah@gmail.com\nestellboileau@hotmail.com\nsybillebenmoussa@yahoo.fr\nimacbubu@gmail.com\nnathaly.faliere-denise@laposte.net\nnicolas.dupin@free.fr\nmariejose.weber@wanadoo.fr\n\n\n\n\n \n\n\nECWID\nparis.yakimono@gmail.com\ntokyo237\n\n\nBonjour madame Marise Del Socorro,\n\n\nNous organisons une exposition d'une ceramiste\nfrancaise ayant vecu au Japon, le samedi 9 fevrier.\n\nBeaucoup de ses amis et nos clients viendront.\n\nSeriez vous interessee pour une petite installation Ikebana\na l'occasion ?\n\nEn echange, nous pouvons mettre vos cartes et details pour \nfaire connaitre au public.\n\n\nEn vous souhaitant une excellente journee.\nL'equipe Yakimono !(Mr Noel)\n\n\nPhotos des expos precedentes:\n\n\n\n\n\n\n06 30 96 35 50\n\n\n\n\n\n\n\n\n\n\n\n\nCeramic Japan\ncontact_e@ceramic-japan.co.jp\n\n\n\nMr Shukoku pour 11h30.\nMr Manuel Cordel le dimanche pour 14h\nExpo pour 2014,\nEnvoye les cartes de visites ou ?\nPiece d'identite par scanner\n\nContactez Hiroko et les cles.\nMadame Marjolaine Berthod au telephone pour Rendez vous.\n\n\n\n\n\nDemain email.\n\n10h30 -20h00\n\nPrecisez:   Obata, Selective Art\n57 rue quai des grand augustins , 75006 paris\n  \n\nDemain: 9h, paris, \n16h -17h\n\n\n\n\nOxyde de Zinc et Silice\nQuartz : la Vinete, Pris\nCroissance Cristalline.\nCeramique Usuel\nTheiere Usuel, Vase\n\n\nRegions : Kyoto, Tokyo, Okinawa\ntere\n\n\n\n\n\n\n\n\n\nJess\nP: +33(0) 662 547 413\n\n\nFTP repertoire: 7824_yakimono osozeland23\n7824_develop osozeland23\nBDD: 7824_boutique\n\n\n\n\nFTP ftp.yakimonos.com\n7824_webmaster   kevinyaki23\n7824_yakimono    yakim1234567\n\n\n\nAccess DRI pour websmaster Cliff\n7824_yakimono\nosozeland31\n\n\n\n\nColissimo    \nIdentifiant : 178685 Mot de passe : yakimono1 \nhttps://www.coliposte.fr/pro/\n\n\n\nkatia.ficheux@hotmail.fr\n\n\n\nTimbre en Ligne\nmontimbrenligne@eservices-laposte.fr\nkevin.noel@yakimonos.com\nyakimono1\n\n\nsophie.kusama gmail.com\nbrookm291\n\n\nTomoko237\nitunes applestore HK Store\nbrookn341@gmail.com\nTomoko237\n\n\nFrance Store\nbrookm291@gmail.com\nTomoko237\n\n\nhttp://camp-fire.jp/ (Japan, Crowd funding for all kind of creative projects)\nhttps://www.maneo.jp/ (Japan)\n\n\n\n\n\nFujiwara Yukari\n33 09 80 45 24 95\n\n\n\nMme. Naoko Herbort-Tanno\n\ntanno(at)cerclesuissejapon.ch\n\nVICE-PR?IDENT\nM. Nicolas Urech.\nurech(at)cerclesuissejapon.ch\n\n021 311 38 56\n\nMEMBRES DU COMIT?\nMme. Sakuya Koda\nkoda(at)cerclesuissejapon.ch\nMme. Charlotte Pfeiffer\npfeiffer(at)cerclesuissejapon.ch\nMlle. Caroline Vuagniaux\nvuagniaux(at)cerclesuissejapon.ch\nM. Bao-Lan Huynh\nhuynh(at)cerclesuissejapon.ch\nMlle. Talissa Gasser\nGasser(at)cerclesuissejapon.ch\n\n\n\n\nSebastien L. ( Upgrade for full name )\nDirector at Macquarie\nTokyo, Japan Banking\nCurrent    \nFixed Income, Currencies and Commodities at Macquarie Group\nPrevious    \nBNP Paribas, Societe Generale\nEducation    \nLeadership For Development at BNPP & College de Polytechnique\n\n\nReferecement\nref.yakimono@gmail.com\nyakimono123\n\n\n\nOdesk\nyakimono\nsophie237\n\n\n\nMailChimp\nparis.yakimono@gmail.com\nsophie237\n\n\nD?ustation de matcha\n\n\n\nJess Grinner\n09 50 12 12 90\n\n\n\nyooda\nyakimono\nyakimono1\n\nJRU-603-JRV\n\nA envoyer:\n\n\nFujiwara\n(0)9 80 45 24 95\n\n\n\nref.yakimono @ gmail.com\nyakimono123\n\n\nRobert Walters\nnoelkev0@gmail.com\nsophie237\nhttp://www.robertwalters.co.jp/en/banking-financial-services/jobs/risk-quantitative/640752-financial-engineer-pre-sales-portfolio-valuations.apply.html\n\n\n\nConsultant Name:    Byron Sato\nConsultant Email:    byronsato@michaelpage.co.jp\nConsultant Tel:    + 81 3 5733 7166\nJob Title:    Market Risk Monitoring-Associate Level\nJob Reference:    H1898130\n\n\n\n\n\nVINCENT KC CHEUNG\n(852) 36630018\ncheungvincentkc@hsbc.com.hk\n    \n    \n    access_token=273525309415145|iHgXlOV-CY4cJUe8pOSQEWKfg24\n    \n\nEDF\nmika.yakimono\nyakimonoedf1\n\n\nMrs Obata Mika\n06 52 29 17 17\n\n\nHomegroup Win\nsophie237\n\n\nOuvertures: \nMardi au Samedi 13h-18h\nSur RDV au 06 52 29 17 17\n\n\n\n\nbureau@afj-japon.org\ncontact@autrementlejapon.com\nVivre le Japon\nJapan Veo\nBertrand.de.lavergne@wanadoo.fr \n\n\n\nPierre-Richard Royer, Armetal S.A., \n14 rue des Tournelles F - 75004 Paris, \nT. 33/1.48.87.60.06. F. 33/1.48.87.60.06. GSM +33/6.08.54.70.31. \nprroyer@aol.com\n\n\nGalerie Arcanes, Nelly Fouchet, Le Louvre des Antiquaires - 2, place du Palais Royal - 27, all? Riesener 75001 Paris\nT. +33/1.42.61.23.65. GSM +33/6.08.24.35.77. galerie.arcanes@hotmail.com\n\n\nLes Armes du Chevalier, Jean-Robert de Lavergne, Le Louvre des Antiquaires, 2 place du palais-Royal 75001 Paris T. +33/1.40.15.03.10. F. +33/1.64.05.45.93. GSM +33/6.09.90.45.32.\nles-armes-du-chevalier@wanadoo.fr\n\n\nCSS Transposh\n\n\n\nJapanese Website Editor\nHi,\n\nWe need a Japanese  speaker to maintain a promotionnal website.\n\n1) Write down content in Japanese from English/Japanese content\n2) Post the content on a Blog and make the follow up once a week over 6 months (not time consuming but follow up is necessary)\n\nOnly skill is Japanese and a minimun of website management.\n\n\n\nfunction ContactSync() {\n\n  var spreadsheet = SpreadsheetApp.getActiveSheet();\n  var lastrow = spreadsheet.getLastRow();\n  // Clearin the old data\n  if(lastrow>1) {\n     spreadsheet.getRange(2, 1, lastrow, spreadsheet.getLastColumn()).clear();\n  }\n  \n  \n  var contacts = ContactsApp.getContacts();\n  \n \n  Logger.log('Total contact in google is '+contacts.length);\n  var row = 2;\n  for(var i in contacts) {\n    var contact = contacts[i];\n    \n    var contact_id = contact.getId();\n    // Process if contact has full name\n    if(contact.getFullName()) {\n      \n    spreadsheet.getRange(row, 1).setValue(contact_id);\n    spreadsheet.getRange(row, 2).setValue(contact.getFullName());  \n      \n      var addressFields = contact.getAddresses();\n      for (var i = 0; i < addressFields.length; i++) {\n        Logger.log(addressFields[i].getLabel());\n      }\n      row++;\n    }\n    \n  }\n}\n\n\nfunction onOpen() {\n  var ss = SpreadsheetApp.getActiveSpreadsheet();\n  var menu = [ \n    /*{name: \"Export\", functionName: \"ContactSync\"},*/\n     {name: \"Get Contacts from group\", functionName: \"showDialog\"},\n    ];  \n  ss.addMenu(\"Google-Contact\", menu); \n}\n    \nfunction showDialog() {\n  // create a new application\n  var app = UiApp.createApplication();\n  app.setTitle(\"My Application\");\n  // create panels, text boxes and widgets\n  var panel = app.createVerticalPanel();\n  var listbox = app.createListBox().setId('myGroupSelect').setName('myGroupSelect');\n  //textBox.setName('myTextBox').setId('myTextBox');\n    \n  var groups = ContactsApp.getContactGroups();\n  for(var group in groups) {\n    listbox.addItem(groups[group].getName());\n  }\n    \n  var button = app.createButton('Submit');\n  // add widgets to panels\n  panel.add(listbox);\n  panel.add(button);\n  // create handler to respond to events\n  var clickHandler = app.createServerClickHandler(\"respondToSubmit\");\n  button.addClickHandler(clickHandler);\n  clickHandler.addCallbackElement(panel);\n  // assemble everything in app\n  app.add(panel);\n  var doc = SpreadsheetApp.getActive();\n  // show the app\n  doc.show(app);\n  \n}\n \n// this function responds to submit button\nfunction respondToSubmit(e) {\n var spreadsheet = SpreadsheetApp.getActiveSpreadsheet().getActiveSheet();\n var lastrow = spreadsheet.getLastRow();\n\n if(lastrow>1) {\n    Logger.log(lastrow)\n     spreadsheet.getRange(2, 1, lastrow, spreadsheet.getLastColumn()).clear();\n }\n  \n \n var app = UiApp.getActiveApplication();\n // get the value of the text box\n var myGroupSelect = e.parameter.myGroupSelect;\n Logger.log(myGroupSelect)\n\n  \n  var contacts = ContactsApp.getContactGroup(myGroupSelect).getContacts();\n  \n \n  Logger.log('Total contact in google is '+contacts.length);\n  \n   var row = 2;\n  for(var i in contacts) {\n    var contact = contacts[i];\n    \n    var contact_id = contact.getId();\n    // Process if contact has full name\n    if(contact.getFullName()) {\n      var emails = contact.getEmails();\n      var emailids = [];\n     \n      if(emails.length==1) {\n        emailids.push(emails[0].getAddress());\n       \n      }\n      else {        \n        for (var i = 0; i < emails.length; i++) {\n          if(emails[i].getAddress()!='') {\n            emailids.push(emails[i].getAddress());              \n          }\n        }\n      }\n      var uniqueData = ArrayLib.unique(emailids);\n      for(var email in uniqueData) {\n       var emailid=  uniqueData[email];        \n        var threads = GmailApp.search('from:'+emailid);\n        for(var i in threads) {         \n          if(threads[i].getMessages() && threads[i].getMessages()[0]) {                      \n            spreadsheet.getRange(row, 1).setValue(contact.getFullName());\n            spreadsheet.getRange(row, 2).setValue(emailid);  \n            var subject = threads[i].getMessages()[0].getSubject(); \n            subject = subject.replace('\"','');\n            var hyperlink = '=hyperlink(\"' + threads[i].getMessages()[0].getThread().getPermalink() + '\";\"' + threads[i].getMessages()[0].getSubject() + '\")';\n            spreadsheet.getRange(row, 3).setValue(hyperlink); \n            spreadsheet.getRange(row, 4).setValue(threads[i].getMessages()[0].getDate()); \n            row++;\n          }\n           break;\n        }\n        //break;\n      }\n     \n    }\n    //break;\n  }\n  \n  \n\n return app;\n  \n}\n\nfunction test(){\n  var emailid='';\n  var threads = GmailApp.search('from:'+emailid);\n        for(var i in threads) {\n         \n         Logger.log(threads[i].getMessages()[0].getSubject());\n         Logger.log(threads[i].getMessages()[0].getDate()) \n         \n         \n        }\n  \n  \n\n  \n}\n\n\n\nmedia=\"all\"\n.dropdown dd ul {\n\n\nmedia=\"all\"\n.dropdown dt a {\nbackground: rgb(255, 255, 255) url(arrow.png) no-repeat scroll 90px 10px;\n\n.dropdown dd ul {\nbackground: rgb(255, 255, 255) none repeat scroll 0 0;\n\n\n\n      \nJACQUES BARR?E    \nStand N?:   72\n\n\njacques@barreresa.com \n\nantoine@barreresa.com\n\n      \nAntoine Barr?e\n36 Rue Mazarine\nF-75006 Paris\nFrance\nT +33 (0)1 43 26 57 61\nF +33 (0)1 46 34 02 83\n\n\nVINCENT L'HERROU\ngalerietheoreme@club-internet.fr\n\n      \nERIC POUILLOT\n\n8 Rue de Beaune\nF-75007 Paris\nericpouillot@gmail.com\n\n\n\nGALERIE LAMY\ngalerielamy@skynet.be \n\n\nhm.byobu@gmail.com\n\n\n\nFew art lovers get an opportunity to purchase genuine historical Japanese porcelain,\nso this is a rare chance for collectors to branch out. While the auction might not have artifacts that carry as impressive provenance as the ones at the MOA Museum of Art, they are quite valuable. That fact alone is turning more than a few heads.\n\n\nYakimono !\n\n\n\n\nWordpress BLOG\nyakimonos\n\ncontacts.yakimono@gmail.com\npierre237\n\n\n\nJETRO TTPP.\nUser ID      : contact@yakimonos.com\nPassword     : BBGFDFUB\n\n\n\n\n\nChange interne:\n   Perd, important---->\n\n\n\n\nn\n\n\n\n\n\n\n\n\n https://lettreenligne.laposte.fr/lpl/etape1AjouterDocument.action?modeModif=false&couleur=non&recto=non\nhttp://www.maileva.com/pushtotalk.php\n\n\nhttps://agence.eaudeparis.fr/login.aspx\nyakimono\nAon&YgG4\n\n\n\n\n\nPrice Minister\nyakimono\nsophie237\n\n\nJETRO\nUser ID      : contact@yakimonos.com\nPassword     : BBGFDFUB\nUser Number  : 1416449\n\n\nManuel Cordel\n06 62 22 09 05\n\n\nLe Monde\ncontact@yakimonos.com\nsophie23\n\n\nRepondeur Telephonique:  chez Bureau 24\n01 82 88 29 22\nsophie123\n\nBureau24\n(0) / 1 - 70614100\n\n\ncontactparis.yakimono@gmail.com\ntokyo237\n\n\nMail Chimp\n\n\n\nGmail\nparis.yakimono@gmail.com\nkyoto237\n\n\nskydrive\nSky Drive Microsoft\nparis.yakimono@gmail.com\nobata123\n\n\n\n\n\nPole Emploi\n+33 01 77 86 39 95\nPole Emploi\nTESE\n\nPages jaunes\njeanpierreparis\ngalerieartjaponparis@nym.hush.com\njapon237\n\n\n\nGoogle Ad Words\n967 975 3653\n\n\nDocumentation: \n\n\n\n\n\nMagnifique Coffret a feuille d'or a gagner:\n\nIl suffit de Partager ou \"aimer\" le plus possible, nos Posts jusqu'au 20 Ao?t.\n\nLe gagnant sera nomme ici et se verra offrir ce magnifique coffret.\n\nExcellente Participation.\n\n\n\n\nTeam viewer Langeac\nID: 958 234 119\nmdp: yakimono\n\n\n\nTeam Viewer Obama\nID: 922 559 537\nmdp: sophie123\n\n\nRAJA RIB\n30087 33440 00014268801 14 EUR\nBIC CMCIFRPP\nRAJA Paris Nord 2\n\n\n\nOffice Depot\nyakimono1\nYAKI1\n\nadmin\nwww.yakimonos.com/japan/imagevue identifiant : admin123321 mot\nde passe : kenaruvin987\n\n\nhttp://boutique.yakimonos.com/administration/gestadm.php\nadmin thelia\nadmin admin elise237\nKevin\n\n\nBonjour,\n\nNous souhaiterions nous deplacer vers le centre,\npour un loyer modere (activite de galerie japonaise)\n\nNous sommes a Convention actuellement\nMerci\nMr Noel\n\nGerant de SARL\nkevin.yakimono@gmail.com\ntomoko237\n\n\n\nMalakoff Assurance retraite\nAdherent: 202825493\nTelecophoe\njruiz@malakoffmederic.com\n\n\n\n+33 (0)1 40 70 35 00\n162.46\n\n\n\nSoho\nkevin.yakimono\ntomoko237\n\n\n\nhttp://www.stephensalel.com/japaneseArtDatabase\nuser\nasianart\n\n\nparis.yakimono@gmail.com\nkyot237\n\n\nparsi239\n\n\nCr?it Mutuel - CCM PARIS 15 MONTPARNASSE, 2 RUE DE L'ARRIVEE, 75015 Paris 15e\n10278  06045 00020816901 19 EUR\nCatherine Bodinier\nTel: 08 20 09 98 87 \nPortable :  06 73 53 78 07\nFax: 01 45 49 42 27\n\nCredit Mutuel  Paris\n0604520816901  ID Internet\nPasswords gojersio\n\nCr?it Mutuel Carte Bleu\nAutorisation tel 0825 82 42 26\nD?annage tel 0825 00 38 16\n\nMME SANSON MISAKI\n16 BD DU LEVANT\n92000 NANTERRE\n\nBanque Hypoth?aire Europ?nne\n\nCl?IBAN        FR76\nBanque          44319\nGuichet         78479\nCompte         05994636240\nCl?RIB          41\nDomicilation  BHE VERSAILLES\n\n\n\nCloudfare\nkevin.yakimono@gmail.com\nhttps://www.cloudflare.com/forgot-password-change.html?reset_code=2267358345T1339500724Rcc4a03070d8e19490964fee16ea47542U104516\nsophie237\n\n\n\n\n\n\n\nDear Mr Noel,\n \nToday we received a fax from you containing a cheque copy. Please be assured that the hold for the account was removed per instruction of Inland Revenue Department on 29/6. and that we did not stop the cheque or account since then. As mentioned in our earlier email communication, please ensure there is sufficient fund in your joint name current account (account suffix -001) for payment of the cheque. Account transfer can be done via internet banking or phonebanking, please kindly note that no fax instruction can be accepted.\n \nPlease contact us if there is any question. Thank you!\n\nBest Regards,\n\nLisa HO\nPremier Relationship Officer\nThe Westwood \n\nPremier Centre\nLG01-03 The Westwood,\n8 Belcher's Street, Hong Kong.\nTel: +852 36630054\n\n-----Lisa Y S HO/HBAP/\nwrote: -----\n\n    To: Mr Noel <brookm291@gmail.com>\n    From: Lisa Y S HO/HBAP/HSBC\n    Date: 04/07/2012 10:01AM\n    cc: Vincent Cheung <cheungvincentkc@hsbc.com.hk>\n    Subject: HSBC The Westwood Premier Centre\n\n    Dear Mr Noel,\n     \n    Thank you for your fax containing the cheque image.\n    As per instruction from Inland Revenue Department on 29/6, the hold for the account was removed. Please ensure there is sufficient fund in the current account for payment of the cheque. Information for inward TT payment is attached for your reference. Please also be reminded that your Premier credit card payment will be settled by autopay on 09/07/2012. Please contact us if there is any question. Thank you!\n\n    Best Regards,\n\n    Lisa HO\n    Premier Relationship Officer\n    The Westwood HSBC Premier Centre\n    LG01-03 The Westwood,\n    8 Belcher's Street, Hong Kong.\n    Tel: 36630054\n\n    ************************************************************\n    The Hongkong and Shanghai Banking Corporation Limited\n    whose registered address is 1 Queen's Road Central, Hong Kong\n    ************************************************************\n\n\n\n\n\n\n\n\n\n\nhttps://yakimonos.createsend.com/\nyakimonos\nsophie237\n\n\n\nPaypal\ncommande@yakimonos.com\nsophie237\n\n\n\nLE DIVAN RIB\n30076 02147 12214700200 48\nBIC NORDFRPP\n\n\nPhillippe illon\n33 01 47 23 00 07\n\n\n\n\nEURODOMICILIATIOn\nFr76 3006 6108 5700 0102 4870 257\nCMCIFRPP\nCIC paris pereire\n\n\n\nlejapon.org\nPierre237\nsophie237\n\n\n\n\n\nPole Emploi\nVoici votre num?o identifiant : 01308277\n\nVotre code : 04466 ensuite vous indiquez le d?artement de l'entreprise : 75\n\nNum?o pour commander l'attestation : 3995\n\nNum?o pour aide au remplissage de l'attestation : 3949\n\n\n\nAdresse mail et nom d'utilisateur Yahoo! :\ngalerieartjaponparis@yahoo.com\nsophie237\n\nAdresse secondairecontacts.yakimono@gmail.com\nAnniversaire19 avril 1980\nQuestion secr?e 1chien\nMa r?onselutine\nQuestion secr?e 2maman\nMa r?onsemaryvonne\nCode postal75015\n\n\n\n\nhttp://www.urssaf.fr/\n\nJunko mobile: 06 31 32 86 78\n18 Rue Benoit Malon, 92310 Sevres\n\n\nMy social security number is 2 75 09 99 217 041 46\nKURI BOTELLA  My birth is :23/09/1975\n26-28 rue Pelleport 75020 PARIS, FRANCE.\nTel ; 06 17 99 43 75 / 01 43 64  57 65\nE-mail ; yorigami@free.fr\n\nyorigami@free.fr\n\n\n\nglassjunko@gmail.com\nelise237\n\n\n\n09A16\n\nPages Jaunes\npierrot237\nsophie237\n\n\n\nPages Jaunes\nsophie237\nsophie237\n\n\nCOMPTABLE\nknoel\nLogin: knoel\nMot de passe: 701558fb\nAdresse du site: itool.com\n\nGreffe le depose comme augmentation de capital.\n\n\nVOTRE_EXPERT Comptable:  0141432390\nVOTRE_EXPERT Comptable:  dalia lafond\nMarc SMADJA\nTel  33 (0)1 41 43 23 90\nFax   33 (0)1 41 43 23 99\nmsmadja@alephconsultants.com\n\n\n\nnoekev2@gmail.com\nsophie237\n\n\n\nMashiko\n06 43 58 21 89\n\n\nhttps://businesscenter.pagesjaunes.fr/servicepro/creerCompte.do\nyakimono\nsophie237\ncontact@yakimonos.com\n\n\nReferencement Site Web\nhttp://forum.webmaster-rank.info/ucp.php?mode=register\nyakimono\nsophie237\n\n\nsophiekutani@gmail.com\nelise237\n\n\n\nhttp://www.webrankinfo.com/support.php\nkevinyakimono\nkevin.yakimono@gmail.com\n1RIBIHVL\n\n\n\n\n\n\ndeveloppez com\nyakimono\n6yQMWJhq\n\n\n\nMachiko( ep .ARIKI) TAKEUCHI \nChez M.DELAHAYE 69 rue Crozatier 75012\ntel: 06 43 58 21 89\ntel: 01 43 42 24 27 \n\n06 43 58 21 89\n\n\nNous sommes une galerie boutique d'art japonais\nentre Paris et Tokyo avec fort potentiel.\nNous cherchons un associe sur Paris pour le developpement\naupres de nos clients.\n\nPersonne bilingue (francais, japonais),\ndisponibilite obligatoire et souhaitant s'investir a plein , \nInteret et experience en arts japonais.\n\n\nContactez sur :  galerieartjaponparis@nym.hush.com\n\n\n\nPhilippe Nandillon\nDAICI Repreneur de Yakimono !\n06 08 61 40 27\n01 47 23 00 07\nannie@daici.com\n\n\n\n\n\n\n\n\n\n2014:\n\nGateaux, \nDetails: Prix\n300 - 500 : Tenmoku\n\nYakishime: Jarre,\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMr Jean Francois Strak\nv-berkhane@svt-international.com\nReference : 329808\nwww.pic-inter.com\n\n14 juillet au 6 aout.\n\n01 47 23 00 07 \n\nJean Francois Strak\n01 44 09 03 44\n\n\n\n\n\nhttp://forum-juridique.net-iris.fr/register.php?do=addmember\nsarl_sophie\nsophiet237\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPole Emploi\nVoici votre num?o identifiant : 01308277\nVotre code 04466 puis vous indiquez 75 en d?artement\n\nLundi 09 juillet 2012| Plan du Site\nAccueil pole-emploi.fr\nCandidat\nEmployeur\nActualit?\nR?lementation\nEn r?ion\nQuitter mon espace\n\nYakimono!\n\nVotre compte\nVos aides\nVos courriers\nQuittez votre espace personnalis?\n\nBienvenue YAKIMONO!Toutes vos coordonn?s\nVos ?h?nces\nVous n'avez aucune ?h?nce en cours.\nVOTRE COMPTE\n\nVos obligations ?l'?ard du salari?\n\nProposez ?votre salari? en cas de proc?ure de licenciement ?onomique engag? avant le 1er Septembre 2011, la convention de reclassement personnalis? (CRP)    >Acc?er au service\nProposez ?votre salari? en cas de proc?ure de licenciement ?onomique engag? ?partir du 1er Septembre 2011, le contrat de s?urisation professionnelle (CSP)    >Acc?er au service\nSaisissez en ligne l'attestation destin? ?P?e emploi    >Acc?er au service\nCommandez en ligne des attestations destin?s ?P?e emploi    >Acc?er au service\nEstimation des allocations ch?age\n\nSimulez les droits aux allocations du salari?   >Acc?er au service\nD?larations sociales\n\nFaites les d?larations de vos Organismes de protection sociale    >Acc? ?Net Entreprises\n\n\n\nAcc? d?icients visuels | Votre p?e emploi | Site institutionnel | Foire aux questions | Contactez-nous | Sites utilesNos partenaires\nAccessibilit?| Informations l?ales | Lexique | Info trafic | Flux RSS - Copyright 2012 ? POLE EMPLOI\n\n\n\n\nTel: 39 40.\n01 40 30 60 00\n\nMediateur :\n\n\nAssurance Retraite\nDDAS\nhttps://www.e-ventail.fr/ss/Satellite?c=Page&childpagename=E-ventail%2FEV_Layout&cid=1295424509125&pagename=EV_wrapper\n089994065\nyakimono\nYakimono1\n\n\nBonjour madame Akiko Gishi,\n\nJe vous remercie de la discussion aujourd'hui.\nNous sommes heureux que l'idee de collaboration avec une artiste ceramiste francaise\nvous plaise. Madame Le Portier participera a l'exposition Internationnal de Chawan,\na Taiwan en octobre 2013.\n\nVoici les pieces qu'elle realise, qui sont tres proche d'une esthetique japonaise.\nComme indique par ma collegue Mika san, nous souhaiterons\nrealiser une collaboration entre une artiste francaise et une artiste maitre japonaise,\nsous le theme de \"Cristallisation Florale\", permettant le dialogue culturel entre les deux pays.\n\n\n\nAu niveau du budget des fleurs, j'ai mis en copie une indication,\nNous pouvons en discuter sans souci amicalement.\n\n \n\nJe me permets de vous mettre en copie l'explication\nde ma collegue Mika san, responsable a Paris, qui sera heureuse de vous faire\nrencontrer madame Le Portier a un moment convenable, a notre gallerie.\n\nEn vous souhaitant une excellente journee\nYakimono ! (Mr K. Noel)\n\n\nstaffparis.yakimono@gmail.com\nyakimono123\n\n\nFacebook Secret Email\nfought263lisbon@m.facebook.com\nhttps://m.facebook.com/upload.php\n\n\n\n\n\n\ntokyo.yakimono @ gmail.com\nibaraki235\n\n\nNet Entreprise\n\n53061277900013\nyakimono\nKevin\ncontact@yakimonos.com\nsophie237\n\n\nL'acc? ?certains des services n?essite une identification.\nVotre adresse email : kevin.yakimono@gmail.com\nVotre mot de passe : iwi070bp\nhttps://www.net-iris.fr/espace-client/identification.php\n\n\nPseudonyme : sarl_sophie\nMot de passe : wFB6sQsf\n\n\n\n\nHiroko Amice\n01 71 73 48 45\n\n\n\nMalakoff\nhttps://www.malakoffmederic.com/entreprises/acces-client/index.jsp\nkevin.yakimono gmail.com\nsophie237\n 202825493\n\n\n\n32943\nURSAFF  letese\n53061277900013\nelise237\n\n53061277900013\n\n\nWhiteWall FR\nVotre commande a ??pass? avec succ? sous le num?o de commande 30115000058263.\n\n\n\nYakimono\nSARL au capital de 25000 Euros\n4 Rue Galvani,,\n75838 Paris Cedex 17\n530612779 R.C.S. Paris\nPar d?ision de L'Assembl? G??ale Extraordinaire en date du 1 mai 2013 il a ??d?id?de modifier le capital de la soci??en le portant de 25000 Euros ?25000 Euros\nAutres modifications :\n- il a ??pris acte de la nomination de Monsieur Mika OBATA, demeurant 146 Rue de Charenton 75012 Paris en qualit?de nouveau G?ant, pour une dur? illimit?, en remplacement de Monsieur Kevin NOEL, d?issionnaire.\nMention en sera faite au Registre du Commerce et des Soci?? de Paris\n\n750\n\n\nYakimono\nSARL au capital de 25000 Euros\n4 Rue Galvani,\n\n75838 Paris Cedex 17\n\n530612779 R.C.S. Paris\nPar d?ision de L'Assembl? G??ale Extraordinaire en date du 1 mai 2013 il a ??pris acte de la d?ission de G?ant Monsieur Kevin Noel, ?compter du 1 mai 2013. G?ant Monsieur Mika Obata demeure ?compter de cette m?e date.\nMention en sera faite au Registre du Commerce et des Soci?? de Paris\n \n\n\n\n\n\nWe usually work as follow :\n\n        Understand the richness/possibilities of the artist/pieces.\n\n        Find a theme for the artist, so it can match their expectation of future developement : aesthetics, philoshophy,....\n\n        Exposition will bring also some development in their career (not only pure selling).\n\n\n\n\n\n        \n        Yakimono  aims to let public discover and exchange on the theme of Japanese Culture and Art.\n    \n    Particularly, Japanese Ceramics has a profound history in Japan and still influences\nstrongly the art there and major characteristics are less known in France.\n        \n        \n        \n\nTESE: \n\n\nCIC PARIS VICTOIRES\nEn pr?isant le N? de commande RPN130588457\nRIB identifiant national de compte\nCode banque    Code guichet    No de compte    Cl?RIB\n30066    10021    00020018601    04\nCode BIC  : CMCIFRPP\nCode IBAN : FR76 3006 6100 2100 0200 1860 104\nAnnonce Legale\n\n\nYakimono\nSARL au capital de 25000 Euros\n4 Rue Galvani,\n75838 Paris Cedex 17\n530612779 R.C.S. Paris\nPar d?ision de L'Assembl? G??ale Extraordinaire en date du 1 mai 2013 il a ??pris acte de la nomination de Madame Mika OBATA, demeurant 146 Rue de Charenton 75012 Paris en qualit?de nouveau G?ant, ?compter du 1 mai 2013 pour une dur? illimit?, en remplacement de Monsieur Kevin NOEL, G?ant d?issionnaire.\nMention en sera faite au Registre du Commerce et des Soci?? de Paris\n\n\n\n\nTrucs pour Paris:\ngateaux de matcha.\nSake a Paris :\n\n\nDecembre 2014.\n\n\n<!-- Google Tag Manager -->\n<noscript><iframe src=\"//www.googletagmanager.com/ns.html?id=GTM-MLPSZG\"\nheight=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\nnew Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\nj=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n})(window,document,'script','dataLayer','GTM-MLPSZG');</script>\n<!-- End Google Tag Manager -->\n\n\n\n\n\n\n\n530\nSARL Yakimono !\nCapital de 40,000 EUROS.\nSIRET 530 612 779 00013\nTVA FR61530612779\nCode NAF 4778C\nTel: 09 51 53 29 43\nFax  33 1 74 18 08 37\nTel Tokyo: 050 5532 8252\nAdrese boutique:  14 Rue Langeac, 75015, Paris\nSiege social administratif\n4 Rue Galvani\n75838 Paris Cedex 17\n\n\n\n\n\nBonjour monsieur, madame,\n\nNous voudrions faire l'annonce d'une nouvelle galerie dans le 7ime arrondissement:\n\nGalerie Yakimono\n29 Rue de L'Exposition, 75007 Paris\n\nExposition C?amiques Kirei Sabi,\nEsth?ique Japonaise traditionnelle.\n(Mardi-Samedi 13h-18h, 16 Nov- 20Dec 2014)\n\n\nAnnonce sur Ambassade du Japon.\nhttp://www.fr.emb-japan.go.jp/culture/calendrier/paris.html\n\n\nCommuniqu?de Presse:\nhttp://www.yakimonos.com/gallery/exposition-paris/exposition-takatori-yaki-ceramique-kirei-sabi/\n\n\nExcellente r?eption,\nEn vous remerciant d'avance\nGalerie Yakimono\n\n\n\n\n\n\n\nAdresse Bureau (toujours celle ci a utiliser):\nSARL Yakimono !\n14 Rue Langeac\n75015 Paris\n\nAdresse Siege Sociale:  (Jamais utiliser cette adresse)\n4 Rue Galvani\n75838 Paris Cedex 17\n\n\nLa poste Desnouettes, Paris 15ieme\n09 169 397 398 Service Etranger\n\n\nLa poste Desnouettes, Paris 15ieme\n01 44 19 62 10 \n\nFax La postte\n33144197570@myfax.com <33144197570@myfax.com>\n \nMadame Christelle,\n \n\n\nSt?hane Calisti  Octolys\nTel: 04 73 74 31 19\n\n\nnoelkev0@gmail.com\nobata235\n\niphone\nejtbfagwwxugrzsk\nPC\nbsmkjpjhzsrapkfb\n\n\n\n17515\n90000\n04649198983\n72\n\nMr Kwon:  06 23 03 38 79\n\n\nHSBC Japan\nNOELKEVIN0\n960550\n\n\n\n\nMarie Therese\nAssurance Retraite\n01 44 09 62 51\n\n\nJolie Boutique/Bureau a Convention\n\n\n\n\n\n\n\n\nJolie Boutique a Paris, Sans Pas de Porte\n\nBoutique 32m2, Quartier de Convention\nAncienne Galerie: Blanc Lumineux et Calme,  \nEnti?ement r?ov?\nPoint d'eau, arri?e salle, stockage sur cour.\nAngle de la Rue de Vaugirard, Metro Convention.\n\nPeut convenir pour Architecte, Boutique.\nSans Pas de porte.\n\n\nContact: 06 11 97 40 24\narnaud@nicolay-associes.com\n\n\nvivastreet1\n\n0611974024\n\n\n\n\n\n\n\nYakimono Presentation\n\n\n<html>\n    <head>\n        <title>Yakimono Presentation</title>\n    </head>\n    <h1>Yakimono Presentation</h1>\n    <p>Yakimono Presentation</p>\n</html>\n\nBonjour,\n\nVoici un Local disponible en location/Cession de Bail\npour cause de D?art des locataires:\n\n14 Rue de Langeac, 75015 Paris Convention,\n(Angle du 356 Rue de Vaugirard)\n32m2, avec vitrine. Lumineux et enti?ement r?ov?\nPoint d'eau, arri?e salle, arri?e cour.\nQuartier de Convention\nId?l pour Bureau / Boutique.\nSans pas de porte.\n1200 euros +90 euros charges\nTotal: 1290 euros / mois\nLoyer mensuel\n\nCession du BAIL par le locataire, \nsans DROIT DE BAIL.\n\n\nLocataire:\nMr Kevin Noel\n\nEmail: kevin.yakimono@gmail.com\nTel(Japon): 0081 80 4119 4019\n\npour faire visite et mandat de cession de Bail SIMPLE.\n\n\n\nLe propri?aire est d'accord.\nSCI De la Grande Armee\n35 Avenue Victor Hugo, 75016\n\n\nExcellente journ? a vous\nKevin\n\n\n\n\n\n\n\nMandat Simple de Cession de Bail avec le Locataire (nous)\nSans Exclusivit?\n\n1200 euros +90 euros charges\nTotal: 1290 euros / mois\nLoyer mensuel\n3 mois de cautions.\nDroit au Bail: 2000 euros (ou moins si le nouveau locataire prend tout de suite).\n\n\n14  Rue de Langeac, 75015\nBoutique 32m2, 5mins du Metro, Quartier de Convention\nBlanc Lumineux et Calme,  \nEnti?ement r?ov?\nPoint d'eau, arri?e salle, stockage sur cour.\nAngle de la Rue de Vaugirard, Metro Convention.\nPeut convenir pour Architecte, Boutique.\n\n\n\n\n\n0613134820\n\n\n\n\n\n\n\n\n0613134820\n\n\n\n\n\n\n\n\n\n\n\nAgora Biz\ncontacts.yakimono @yakimonos\nyakimono123\n\nhttp://www.agorabiz.com/compte-annonceur/deposer-annonce/fin-paiement\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMr Frederic Gibert\nSCI De la Grande Armee\n35 Avenue Victor Hugo\n75016 Paris\nSIREN 503 165 623\n\nTechnicien Nicolas 06 72 33 69 83\n35 av Victor Hugo 75116 PARIS : Residence de courrier.\n\n\nProprietaire:\n- Mr Pierre Brizi  06 84 55 50 63\n- Mr Frederic Gibert 06 73 77 05 02\n\nArnaud Nicola?\n\nAK HOME\n40 avenue Hoche\n75008 Paris\nFrance\nMobile : 06 11 97 40 24\narnaud@nicolay.net\n\n\n\nEuro Domicialisation\nTel . (33) 1 56 68 91 12\nFax. (33) 1 56 68 91 13 \n33156689113@myfax.com\n\n\n\n\nIkea\nkevin.yakimno gmail\n1yakimono\nDe l'?ranger / from abroad\nNT +33 825 10 3000\n\n\n\nRAJA comamnde\nkevin.yakimono@gmail.com\nyaki1\n\n\n\nnoelkev0@gmail.com\nobata235\n\nM. Jean-Marie BADROS  \nEURO-PARTENARIAT\n5 Rue Constant Berthaut\n75020 Paris\n\n\nBADROS JEAN-MARIE peut ?re contact?au si?e de la soci??BADROS JEAN-MARIE , par t??hone au , par t??opie au ou par courrier ?l'adresse \nMONSIEUR JEAN-MARIE BADROS SORDAB 15 RUE DES JARDINS 14000 CAEN. \n\n\n\n\n\nChronopost \nService Clients Entreprises : \n0 825 801 801 (0,15 ? TTC /min)\nService Clients Particuliers : \n0 969 391 391 (appel non surtax?\nPar fax : 0 825 801 802\nDu lundi au vendredi de 8h ?19h et le samedi de 9h ?13h.\n\n\n\n\nSCOOP IT\nkevin.yakimono@gmail.com\nyakimono\n\n\nyakimonofr@gmail.com\ntokyoparis37\n\ncommande@yakimonos.com\norder.yakimono @gmail.com\nibaraki237\n\n\ncontact@yakimonos.com\ncontacts.yakimono @gmail.com\nibaraki237\n\n\n\nYakimono Fax Number\n33 1 74 180 837\nkevin.yakimono @ gmail.com\nsophie237\n\nSend a Fax:\nfaxnumber(country code)_@myfax.com\n\nSubject: Name of the person\nBody: Your Name and reference\n\n\n\n\n\nLa poste\n3436\nsouhila.ouachemi@laposte.fr\n\n\n\nMurai Nobuyuki\n0748-82-3635\n\ncontacts.yakimono@gmail.com\nibaraki237\n\nEau de paris\nIdentifiant;yuko.yakimono@gmail.com\nMot de passe ; AqbwsSJw8T\n\n\nSARL Yakimono !\nCapital de 25,000 EUROS.\nSIRET 530 612 779 00013\nCode NAF 4778C\nTel: 09 51 53 29 43\nFAx  33 1 74 180 837\n\n01 71 73 48 45\n\n\nJapan:\n162-0827\n????????\n?26-306\n???????? ???\nYakimono, Kevin Noel\n(???? 5?)\nPhone: 080\n4119 4019\n\n\nFrance,Paris:\n29 Rue de L?Exposition\n75007, Paris,\nFrance\n(?????? 10?)\ncontactparis@yakimonos.com\n\n\nhttp://www.artactuel.com/galerie-art/galerie-paris-yakimono-3637.html\ncontactparis@yakimonos.com\nexposition\n\n\n\n\n\n\nhttp://evene.lefigaro.fr/culture/agenda/exposition-laque-japonaises-contemporaines-2642745.php\n\n\n\n\n\n\n\nPour contacter [les ?uipes d?Evene...]\nEVENE\n14 bd Haussmann\n75009 Paris\nFax : 01 57 08 61 51\ninfo@evene.fr\nEVENE R?action\ncomite-redaction@evene.fr\nEVENE Publicit?\nDirecteur : Fr??ic Bena?\nculture@figaromedias.fr\nEVENE Partenariats\nResponsable des partenariats culturels : Antonin Chauchard\nculture@figaromedias.fr\nEVENE Boutique\nResponsable e-commerce : Alexandra Nguyen\nboutique@evene.fr\nLES ATELIERS DU FIGARO - Agence de solutions culturelles sur mesure\nEric Leray\nhttp://www.figaromedias.fr/content/figaromedias-lance-les-ateliers-figaro \n\n\nEVENE Studio\nDirecteur artistique : G?aud Feybesse\nstudio@evene.fr\n \nWebmaster\nwebmaster@evene.fr\n\n\n\nXilisoft iPhone Transfer license Immediate License Code sent by Email (102117-136)\n\nThank you for ordering 1 copy(s) of Xilisoft iPhone Transfer. \n\n_____________________ \n***Please Note: The following information is important, and please keep it for further reference. \n\n~~~~~~~~~~~~~~~~~~~~~~~~~ \nUser Name: Kevin Noel \nLicense Code: \nFC7A1A7D-FEDB-454C-888AC-4E27-E5F0-8500 (for Xilisoft iPhone Transfer V5 only) \n~~~~~~~~~~~~~~~~~~~~~~~~~ \n\n1. Download and install it: \nhttp://www.xilisoft.com/downloads/x-iphone-transfer.exe \n2. Register it: \nPlease click \"Enter License Code...\" in \"Help\" menu or the menu named by our software name, enter your user name and license code in the corresponding box, and then press the \"OK\" button. \nNote: Please COPY and PASTE the license info when register without adding any blank. \n_____________________\n\n\nevene.fr\nparis.yakimono@gmail.com\nexposition1\n\n\n\n\n\nhttp://www.franceculture.fr/oeuvre-pays-de-neige-de-yasunari-kawabata.html\n\n\neMail : contactparis@yakimonos.com\nMot de passe : exposition\nPseudo : galerieparisyakimono\n\n\n\nWordpress Login     \nadmin\nkyoto237\n\n    \n    \n\nName    \nE-mail    Role    Posts\nSelect admin    admin\nEdit\nArt gallery Japan Yakimono    tokyo.yakimono@gmail.com    Administrator    23\nSelect Art Gallery Paris Japan    Art Gallery Paris Japan\nArt Gallery Paris Japan    paris.yakimono@gmail.com    Administrator    0\nSelect ArtGallery    ArtGallery\nArt Gallery News    lupinewolf@hush.ai    Editor    72\nSelect corrector1    corrector1\nCorrector    files.yakimono@gmail.com    Editor    0\nSelect webmaster    webmaster\nwebmaster123 webmaster124    smartdeveloper98@gmail.com    Administrator    0\nSelect yakimono    yakimono\nArt Gallery Paris    mika.yakimono@gmail.com    Editor    0\n\n\n\nRemote Control PC\nobama\nsophie237\n\n\n\n\n\nPhotos and File Upload\n\n\nhttps://drive.google.com/?authuser=0#folders/0BzGyNrOXSQweblFINDVmUG1xbTQ\nLogin:   files.yakimono@gmail.com\npass:    yakimono123\n\n\n\n\n\n\n\n\nAdresse Bureau (toujours celle ci a utiliser):\nSARL Yakimono !\n14 Rue Langeac\n75015 Paris\n\nAdresse Siege Sociale:  (Jamais utiliser cette adresse, adresse administrative)\n4 Rue Galvani\n75838 Paris Cedex 17\n\nADMINISTRA TION,G?ant M. NOEL K?in\ndemeurant 28-12, daik yocho, shinjuku-ku ShinjukuGyoen, 99 Tok yo\nJapon\n\nNouvelle Adresse Tokyo:\n162-0827\nTokyo, Shinjuku Ku, Wakamiyacho 26\nMyrtle Court Shinjuku WakamiyaCho\nF306\n162-0827\n?????????26???????F306\n\nNum?o de t??hone ; 00 81 80 4119 4019\n\nTampon texte:\n\nSARL Yakimono !\n14 Rue Langeac, 75015 Paris\nSIRET 530612779 00013\ncontact@yakimonos.com\n\n\nYakimono Fax Number:    33 1 74 180 837\nwww.Myfax.com\n\nPour envoyer un Fax,\n\n1. Envoyer un email avec pieces jointes PDF ou Word\n2. Adresse   Exemple Fax: 01 41 43 23 99,   email adresse: 33141432399@myfax.com\n3. Le fax va etre automatiquement envoye au numero +33 (0)1 41 43 23 99, une confirmation sera envoyee\nKFXPEQZYR5\n\nBanque Details:\nHSBC Business Direct\nCompte: 30056   00949   0949 002 8252  66\n\n\nSIRET 530 612 779 00013\nCode NAF 4778C\nTel: 09 51 53 29 43\nFAx  33 1 74 180 837\n\n\nRemboursement de TVA:9 mai 2012, 14 mai 2012, pas de rejet.\nDate:  2512 euros  \nJustificatif: \n\n\n\nCompte est cloture.\net montant du virement.\n\n\n\n\nDirectement de l'etranger: \nImp?s du 17e (M. Perrier / +33 1 40 53 21 33).\n 2512 euros, date: \n 09h00 :   \n\nERVICE IMPOTS DES ENTREPRISES - PARIS 17E TERNES\n\nCENTRE DES FINANCES PUBLIQUES\n6A BD DE REIMS\n75844 PARIS CEDEX 17\n\nT??hone : 01 40 53 22 39\nCourriel : SIE.PARIS-17E-TERNES@DGFIP.FINANCES.GOUV.FR\n\nR?eption : \nDU LUNDI AU VENDREDI 9H-12H30\n13H30-16H OU SUR RENDEZ-VOUS\n\n\nhttp://personals.gaijinpot.com/facebook.jhtml\nartdirector1\nelise237\n\n\n\n\nBonjour,\n\nJ'habite a Tokyo, Kagurazaka, et responsable d'une galerie d'art Japonais a Paris.\n\nJ'ai trouve votre profile int?essant car je cherche une personne pour faire des visites de galeries et d'exposition sur Tokyo.\n\nSi cela vous interesse, n'hesitez a me contacter sur:\nbrookm291 gmail com\n080 4119 4019\n\nBonne journee a vous.\nMr Kevin. Noel \n\n\n\nBonjour,\n\nAm living in Tokyo, Kagurazaka, \nand responsible for a Japanese Art Gallery in Paris.\n\nI found your profile interesting because I am looking for a person\nto visit galleries and Art exhibitions in Tokyo.\n\nIf you are interested, feel free to contact on: \nbrookm291 gmail com\n080 4119 4019\n\nHave a nice day.\nMr Kevin No.\n\n\n\n\n\nMr Jabri\n06 25 24 56 34\n\n\n\nstevem994@gmail.com\n\n\nMr, Kevin Noel\n\n162-0827\nTokyo, Shinjuku Ku, Wakamiyacho 26\nMyrtle Court Shinjuku WakamiyaCho\nF306\n\n\n\n\nReferencement\nhttps://ahrefs.com/users/activation_key_sent_ok.php?email=kevin.yakimono%40gmail.com\nkevin.yakimono@gmail.com\nsophie\n\n\n\n\n\n\nDARTY\n\nkevin.yakimono@gmail.com\nyakimono\n\n\n\nIkea Details\nhttps://secure.ikea.com/webapp/wcs/stores/servlet/ProtectedUpdateUser\n\nLogin:   kevin.yakimono@gmail.com\n Pass:  1yakimono\n\nWang Dan - 14 r Langeac, 75015 PARIS\n01 72 60 76 24\n\nEDF :\nkevin.yakimono@gmail.com\nelise237\n\n\nL'indentifiant Internet: yuko.yakimono@gmail.com\nMot de passe :   elise237\nQuestion secr?e : Mon lieu de naissance - Tokyo\nR??ence client : 100 1225 763\nEl?tricit?: 3 05 3005 751 001\nIdentifiant compteur : U89 99 90\nIdentifiant Internet : KFXPEQZYR5\n\n\nEspace client ; https://agence.edfpro.fr/ASPFront/appmanager/WebPro/front?_nfpb=true&_pageLabel=pro_page_authentification\n\nmika.yakimono@gmail.com\n vaFrtZjV\n\nexposition1\n\n\n\n0 810 333 776 (prix d?un appel hors surco?t impos?par certains op?ateurs)\nD?annage ?ectricit?:\n0 972 675 075 (prix d?un appel local hors surco?t impos?par certains op?ateurs)\n\nvotre num?o client ?rappeler lors de tout ?hange avec EDF Pro : 1001225763\n\n\n\n\nZOHO CRM\nkevin.yakimono@gmail.com\ntomoko237\n\n\nparis.yakimono@gmail.com\nkyoto237\nkyoto237\n\n\n\n\n\n\n\nBonjour,\n\nNous sommes une galerie dans le 15ieme, Convention,\net souhaitons nous deplacer plus au centre,\nmais un local plus petit (frais plus simple).\n\nNotre site web: www.yakimonos.com\n\nResponsable, suis au Japon, souhait\navoir plus de details sur cela.\n\nCordialement\nMr Noel.\n\n\n\n\n\n\nA c?er, droit au bail d'une boutique de 15 m? situ? rue de l'Universit?entre \nles rues du BAC et de Bellechasse.\n583 euros\n\nType de locaux : boutiques / locaux commerciaux\nSurface des locaux : 15m? environ\nType de transaction : Location\nAgence Manestel\n59 RUE DU FAUBOURG ST ANTOINE\n75011 - Paris\nFax : 01 43 44 03 31\n\n\n\n\n\n\nCENTURY 21 ALPHA EN L'ILE Jean Philippe Th?ond\n6 rue le Regrattier\n75004 - Paris 4?e\nFax : 01 55 42 92 01\n\n\n\n\n\n\n\n\n\n\n\n\n\norganiser les oeuvres,\nReference Ono Bernard\n\nAppuyer :interessse pour mars: Printemps Japonais,\nthematique de Printemps, japonaise\n\nMars : appuyer \n\n\n\n\nVoss Tabe: \nGalerie pas ouvert au public.\n\n\n\nRermercier, \n\nMars c'est itneressant, le printemps Japonais connaitre maniere.\nVoss Tabe: -35%\n\n\n\n\nCommunication Quartier : Liste\n\nDates : Mami Mars\n\nAvril :  Mai,\n\nMakiko : Avril, Mai\n\n\n\nEvenements : vu le mieux, \n\n\n\n\n\n\nBonjour madame Mami San,\n\n\nNous sommes une galerie japonaise a Paris 15ieme,\net vous nous avez contacte il y a quelques temps.\n\n\nNous essayons de montrer la qualite et la beaute de l'Art Japonais\nau public francais, notamment la Ceramique et les Urushis, \net sommes une equipe entre la France et le Japon.\n\nNous organisons des expositions et des evenements sur Paris,\net sommes en recherche d'assistant pour organiser.\n\nSi cela vous interesse, nous pourrions organiser\nune discussion avec la responsable sur Paris, madame Mika Obata,\nspecialiste de l'art.\n\nBonne journee\nL'equipe Yakimono !\n\n\nwww.yakimonos.com\n\n\n\ngeijitsugallery@gmail.com\nyakimono1\n\n\nThemeForest\nyakimono\nparis.yakimono @ gmail.com\ntomoko237\n\n\nhttp://theme-fusion.com/wp-admin/profile.php?updated=1\ntokyo.yakimono\nkyoto123\n\n0147001068\n\nLICENSE CERTIFICATE : Envato Marketplace Item\n==============================================\n\nThis document certifies the purchase of:\nONE REGULAR LICENSE\nas defined in the standard terms and conditions on the Envato Marketplaces.\n\nLicensor's Author Username: ThemeFusion\nLicensee: Yakimono\n\nFor the item:\nAvada | Responsive Multi-Purpose Theme\n\nhttp://themeforest.net/item/avada-responsive-multipurpose-theme/2833226\nItem ID: 2833226\n\nItem Purchase Code: 694dabb1-d3f3-43ca-a718-948a992a61e7\n\nPurchase Date: 2013-02-23 17:10:30 UTC\n\nFor any queries related to this document or license please contact Envato Support via http://support.envato.com/index.php?/Live/Tickets/Submit\n\nEnvato Pty. Ltd. (ABN 11 119 159 741)\nPO Box 21177, Little Lonsdale Street, VIC 8011, Australia\n\n==== THIS IS NOT A TAX RECEIPT OR INVOICE ====\n\n\n\nDRIVE:\nhttps://drive.google.com\n\nfiles.yakimono@gmail\nyakimono123\n\n\n\n\n\nhttp://theme-fusion.com/wp-admin/profile.php?updated=1\ntokyo.yakimono\nkyoto123\n\n\nFREE (Internet et t??hone)\nNum?o de t??hone ; 09 51 53 29 43\n\nPour acc?er mon compte sur le web\nhttps://adsl.free.fr/suivi/suivi.pl?id=10457789&idt=0e4ff22a1e85f649\nIdentifiant : 0148284583\n(Ancien Identifiant   : 0142501580)\nMot de passe : aicheivu\n\n\n\nR??ence Client\nIdentifiant : 10457789\nCode : 2798\n\n\n\n\n\n\n7824_yakimono\nosozeland31\n\n\n\n\nRaja\n346 euros\n\nCher Mika Obata (SARL Yakimono),\n\nSi vous avez demand?un nom de domaine au cours de votre commande, nous allons enregistrer ce dernier et cela peut prendre 24 heures.\n\nS'il vous pla? gardez ?l'esprit que votre nom de domaine ne sera visible sur l'Internet entre 24 et 72 heures. Ce processus est appel?propagation. Jusqu'?ce que votre nom de domaine aille propag? votre site Web et le courrier ?ectronique ne fonctionneront pas. Afin de rem?ier ?ceci, nous avons fourni une url qui permet d'afficher votre site Web temporairement.\n\nSi vous avez demand?le transfert de votre nom de domaine, nous vous invitons svp ?suivre les ?apes d?rites dans cet article :\n\nhttps://support.planethoster.net/index.php?/Knowledgebase/Article/View/39/6/transfert-de-nom-de-domaine---tapes--suivre\n\nIMPORTANT: Assurez-vous de t??erser vos fichiers dans PUBLIC_HTML ou dans le dossier www du serveur, sinon ils ne seront pas visible sur l'Internet. Nous vous sugg?ons d'utiliser FileZilla: http://www.filezilla-project.org/ si vous n'avez pas de client FTP.\n\nLes informations de votre compte sont ci-dessous.\n\nVos identifiants - Hybride Multi\n\nNom de domaine: yakimonos.com\nNom d'utilisateur: cmeqvwuy\nMot de passe: 1nG0Xlg8y2\nPlan d'h?ergement: Hybride Multi\nIp du serveur: 85.236.158.52\nDNS 1: nsa.planethoster.net\n199.188.223.10\nDNS 2: nsb.planethoster.net\n85.236.159.10\nDNS 3: nsc.planethoster.net\n185.22.111.10\nServeur MySQL: localhost\n\nTemporairement, en attendant la propagation de votre nom de domaine, vous pouvez utiliser les adresses ci-dessous pour g?er votre site Internet.\n\nH?e FTP temporaire: 85.236.158.52\nURL Site Web temporaire: http://85.236.158.52/~cmeqvwuy/\nURL Panneau de contr?e temporaire: http://85.236.158.52:2083\n\nD? que votre nom de domaine sera propag?\n\nH?e FTP: www.yakimonos.com\nURL Site Web: http://www.yakimonos.com\nURL Panneau de contr?e: http://www.yakimonos.com:2083\n\nParam?res de messagerie\n\nVoir tous les emails avec votre compte par d?ault\n\nPOP3 Adresse H?e: mail.yakimonos.com\nSMTP Adresse H?e: mail.yakimonos.com\nNom d'utilisateur: cmeqvwuy\nMot de passe: 1nG0Xlg8y2\n\nComptes emails additionnels ajout?\n\nPOP3 Adresse H?e: mail.yakimonos.com\nSMTP Adresse H?e: mail.yakimonos.com\nNom d'utilisateur: L'adresse email COMPL?E que vous aurez choisie (ex: info@votredomaine.com).\nMot de passe : Celui que vous aurez indiqu?dans votre panneau de contr?e.\n\nMerci d'avoir choisi planethoster.\n\nMeilleures salutations,\nPlanetHoster\n\nNous contacter: http://www.planethoster.net/Contact\nContact Us: http://www.planethoster.net/en/Contact\n\n\n\n\nHiroko\n++33(0)1 71 73 48 45\nPortable : 06 70 03 29 51\n63, boulevard Lefebvre, 75015 Paris, France                              \n\n\n\n\n\n\n\nProprietaire:\n\nMr Frederic Gibert\nSCI De la Grande Armee\n35 Avenue Victor Hugo\n75016 Paris\nSIREN 503 165 623\n\n\n\nBank name: The Bank of Tokyo-Mitsubishi UFJ, Ltd.\nBranch name: Fujisawa Branch\nBank address: 2-1-3 Minami-fujisawa, Fujisawa-shi, Kanagawa 251-0055 JAPAN\nAccount no: 1513212\nAccount name: Naomi Tsukamoto\nSwift code: BOTKJPJT\n\n\n\n1 99A NISHITOBE CHO\nNISHI KU\nYOKOHAMA 220 0046 JAPAN\n\n\nfrais proffessionel \n\nindemmnite  05 prime de\n1 mois contrat\n\n\nremuneration totale, net\ntitre\n\nimprime\n\nemail\ncentrebordeaux@urssaf.fr\n48h.,bulletin\n\n\n\n\nBonjour,\n\nLe TESE a emis un nouveau bulletin de paie\npour salarie JUNKO GLASS, Janvier 2012.\n\n\nErreur Cotisation:\nPAYE (mai2013) 602.42 euros pour 1118.82 euros BRUT:\n\nNouveau Cotisation: 451.41euros pour 1118.82 BRUT.\nDEJA PAYE en 2012: 96.61 euros.\n\n\nA rembourser: (602.42 - 451.41) + 96.61 = 247.62 euros\n\n\n\nEst ce possible d'etre rembourse des cotisations\ncar nous avons des difficultes enormes de tresorerie ?\n\n\nMerci d'avance\nKevin\n\n\n\n\nRCS 530512779\n53061277900013\nTESE de Bordeaux\nTSA 10101\n\n\nURSAFF Region Parisienne\n08 20 01 10 10\n\n39 57\n\nUrsaff\nAdresse de l'organisme\n3 rue de Tolbiac\n75013 Paris\nT? : 08.20.01.10.10\nFax : 01.49.20.82.08\n\n\nTESE Bordeaux\n05.34.30.41.41.\n(recoit le mot de passe par courrier, et faire les declarations sur internet).\nURSAFF Bordeaux\n05 56 11 73 00\n\n\n\n\n\n\n\nCFE kevinyakimono elise237\nDemadne ACCRE\n\nImage Votre partenaire CFE est celui de la CCI de : CCI DE\nPARIS - CFE DE PARIS 2 RUE DE VIARMES 75001 PARIS\n\nE-mail : autoentrepreneur75@ccip.fr Internet :\nwww.entreprises.ccip.fr/web/formalites\n\nT?. : 0 820 012 112 Fax : 01 55 65 48 88 Ouvert au public sans\ninterruption de 9h ?16h, du lundi au vendredi. Ouvert le\nmercredi jusqu'?12h.\n\n\nDossier ACCRE Exoneration M.  Noel Kevin   - Soci??Yakimono\nBienvenue dans votre espace personnel. Dossier n? VX27IXPG\nReste ?compl?er:\n    * Formalit?n? C75012759377 (ACCRE)\n\n\n\n\nThelia Yakimono, Kevin  Motdepasse ju3uq84v\nLe dossier /client/gfx/photos/* (contenu|produit|rubrique|dossier) contient les images d'origine de chaque enregistrement, il faut faire la corr?ation entre les images pr?entes dans la base de donn?s et celles sur ces diff?ents dossiers, et supprimer les fichiers orphelins. Il est ?noter que le fichier d'origine n'est jamais rendu tel quel, il passe toujours pas une phase de redimensionnement, m?e sur le back office, ou la photo n'est qu'une vignette de l'origine.\nVous avez la possibilit?de modifier les pages retours (si paiement effectu? ou non), pour cela, page d'administration > contenu > divers.\n\n    ?itez Merci pour modifier le message quand le paiement a ??effectu?et que le client retourne sur le site (phase de retour sur le site non obligatoire pour finaliser la commande).\n    ?itez Regret pour modifier le message quand le paiement n'a pas ??effectu?et que le client retourne sur le site.\n\nPour modifier le compte PayPal, administration > configuration > gestion des variables:\n\n    modifiez paypal2 et cliquez sur modifier\n    modifiez serveur2 et cliquez sur modifier\n        valeur pour le serveur de test (sandbox) : https://www.sandbox.paypal.com/cgi-bin/webscr\n        valeur pour le serveur de prod : https://www.paypal.com/cgi-bin/webscr\n\nPour modifier le co?t de la livraison, modifier le fichier source suivant : /client/plugins/malivraison/Malivraison.class.php\n\n    il faut modifier les lignes 20 ?28 et/ou ins?er d'autres conditions pour un ?entail plus large et plus fin de co?t.\n\nLes fichiers PDF sont au couleur de Yakimonos.\nLes commandes arrivent bien d?ormais sur commande@yakimonos.com, un email part sur commande@yakimonos.com et contient les informations de la commande (avec les liens vers les pdf).\n\n\nPour modifier le compte PayPal, administration > configuration > gestion des variables:\n\nmodifiez paypal2 et cliquez sur modifier\nmodifiez serveur2 et cliquez sur modifier\nvaleur pour le serveur de test (sandbox) : https://www.sandbox.paypal.com/cgi-bin/webscr\nvaleur pour le serveur de prod : https://www.paypal.com/cgi-bin/webscr\nolivi_1300061819_biz@bolender.org\nhttps://www.sandbox.paypal.com/cgi-bin/webscr\n\n\nyakimono.1234@blogger.com\n\n\n\nREGULAR EXPRESSION TEXTPAD\n\n\nRemove All Blank Lines\n^\\n\nIn regular expression ?^? indicates the start of the line, ?\\n? is end of line,  \nso ?^\\n? is that any line starting new line character , replace with blank character.\n\n\n\n\n\n\nAVADA Wordpress\nadmin1\ntomoko237\n\n\n\n\nAppointment\nyakimono\nrendezvous1\n\nhttp://yakimono.appointy.com/admin\n\n\n\n<iframe style=\"border: 0;\" src=\"https://www.google.com/calendar/embed?src=contactokyo@yakimonos.com&amp;ctz=Asia/Calcutta\" height=\"600\" width=\"800\" frameborder=\"0\" scrolling=\"no\"></iframe\n\n\n\n\n\n<!-- these are the content boxes -->\n\n[content_boxes]\n[content_box title=\"Responsive Design\" image=\"http://theme-fusion.com/avada/wp-content/uploads/2012/07/ico-02.gif\" link=\"http://themeforest.net/user/ThemeFusion\" linktext=\"Learn More\"]Avada is fully responsive and can adapt to any screen size. Try resizing your browser window to see the adaptation.[/content_box]\n\n[content_box title=\"Awesome Sliders\" image=\"http://theme-fusion.com/avada/wp-content/uploads/2012/07/ico-02.gif\" link=\"http://themeforest.net/user/ThemeFusion\" linktext=\"Learn More\"]Avada includes the awesome Layer Parallax Slider as well as the popular FlexSlider2. Both are super easy to use![/content_box]\n\n[content_box title=\"Unlimited Colors\"  image=\"http://theme-fusion.com/avada/wp-content/uploads/2012/07/ico-03.gif\" link=\"http://themeforest.net/user/ThemeFusion\" linktext=\"Learn More\"]We included a backend color picker for unlimited color options. Anything can be changed, including the gradients![/content_box]\n\n[content_box last=\"yes\" title=\"500+ Google Fonts\"  image=\"http://theme-fusion.com/avada/wp-content/uploads/2012/07/ico-04.gif\" link=\"http://themeforest.net/user/ThemeFusion\" linktext=\"Learn More\"]Avada loves fonts, choose from over 500+ Google Fonts. You can change all headings and body copy with ease![/content_box]\n[/content_boxes]\n\n\n<!-- this the is recent posts widget -->\n\n[three_fourth last=\"no\"]\n[title size=\"2\"]Latest From The Blog[/title]\n[recent_posts thumbnail=\"yes\" title=\"yes\" meta=\"yes\" excerpt=\"yes\"][/recent_posts]\n[/three_fourth]\n\n\n<!-- this is the testimonial slider -->\n\n[one_fourth last=\"yes\"]\n[title size=\"2\"]What Clients Say[/title]\n[testimonials]\n\n[testimonial name=\"John Doe\" company=\"My Company\"]Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.[/testimonial]\n\n[testimonial name=\"Peter Doe\" company=\"Imperio Theme\"]Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt[/testimonial]\n[/testimonials]\n[/one_fourth]\n\n\n\n\nBooking Systeme\nlogin: yakimonos\npass: yakimono\n\n\nhttp://yakimonos.simplybook.me/booking/index#mce_temp_url#\n\n<script type=\"text/javascript\" src=\"http://yakimonos.simplybook.me/iframe/pm_loader.php?width=800&url=http://yakimonos.simplybook.me&theme=&layout=modern_widget&timeline=flexible\"></script>\n\n\n[booking nummonths=2 startmonth='2013-07']\n\n\n\nAPI details on your account:\nhttps://www.onehourtranslation.com/profile/apiKeys\nAccount ID: 177104\nSecret Key: 4e07ec4b77f30d0df814355ecb9b076f\nPublic Key: f3HFKknDVCLm8jYpc9Zd\n\n\n\n[gallery type='picasa']\n[gallery type='facebook' gallery='100001547546587_26255' ]\n\n\n\n\n<script type=\"text/javascript\"> var _ohtConfig = { debug : false, v : 0.1, mscp : ('https:' == document.location.protocol ? 'https://' : 'http://') + 'owsassets.onehourtranslation.com/build/0.4/', services : { WeST:{ src : 'https://www.onehourtranslation.com', pubkey : 'f3HFKknDVCLm8jYpc9Zd', skip_selectors : ['code','pre'], l10n_uuid : 'l10n-52274610914454-41936030' } } }; (function () { var head = document.getElementsByTagName('head')[0], oscr = document.createElement('script'); oscr.type= 'text/javascript', oscr.src = _ohtConfig.mscp + 'all.js', oscr.async = true; head.appendChild(oscr); })(); </script\n\n\n\n <iframe src=\"https://docs.google.com/document/d/1dj7AaTznn-sIPtVcvkt8AN7QTUk7WV09zVDkmA1I6q8/pub?embedded=true\"></iframe>\n \n \n \n Evernote\n yakimono1\n elise237\n \n \n France:\n Yakimono\n 29 Rue de L?Exposition\n 75007, Paris, France\n(?????? 10?) \n\n\n \n \n \n \n \n \n \n <vpn>[title size=\"2\"]Contact Japan[/title]</strong>\n \n <strong> Email: </strong>contactparis@yakimonos.com\n \n <strong> Phone:</strong>  080 4119 4019\n \n  \n \n <strong>[title size=\"2\"]Adresse Japan[/title]</strong>\n MYRTLE COURT WAKAMIYACHO\n Tokyo, Shinjuku Ku, Wakamiyacho 306-26\n 162-0827\n \n \n<iframe width=\"425\" height=\"350\" frameborder=\"0\" scrolling=\"no\" marginheight=\"0\" marginwidth=\"0\" src=\"https://maps.google.co.jp/maps?q=wakamiyacho+26&amp;hl=fr&amp;ie=UTF8&amp;sll=48.856803,2.303594&amp;sspn=0.012636,0.030212&amp;t=m&amp;brcurrent=3,0x60188c0c0b13f54d:0xb630953beee48188,0&amp;hnear=T%C5%8Dky%C5%8D-to,+Shinjuku-ku,+Wakamiyach%C5%8D,+%EF%BC%92%EF%BC%96&amp;hq=&amp;ll=35.69918,139.740368&amp;spn=0.028719,0.041671&amp;z=14&amp;output=embed\"></iframe><br /><small><a href=\"https://maps.google.co.jp/maps?q=wakamiyacho+26&amp;hl=fr&amp;ie=UTF8&amp;sll=48.856803,2.303594&amp;sspn=0.012636,0.030212&amp;t=m&amp;brcurrent=3,0x60188c0c0b13f54d:0xb630953beee48188,0&amp;hnear=T%C5%8Dky%C5%8D-to,+Shinjuku-ku,+Wakamiyach%C5%8D,+%EF%BC%92%EF%BC%96&amp;hq=&amp;ll=35.69918,139.740368&amp;spn=0.028719,0.041671&amp;z=14&amp;source=embed\" style=\"color:#0000FF;text-align:left\">Agrandir le plan</a></small>\n\n\n \n<iframe src=\"https://docs.google.com/document/d/1dj7AaTznn-sIPtVcvkt8AN7QTUk7WV09zVDkmA1I6q8/pub?embedded=true\" height=\"500\" width=\"100%\" frameborder=\"0\" scrolling=\"no\" align=\"left\"></iframe>\n \n \n \n https://docs.google.com/document/d/1dj7AaTznn-sIPtVcvkt8AN7QTUk7WV09zVDkmA1I6q8/pub\n \n \n \n \n \n \n \n \n \n Website Adresses:\n \n \n \n \n \n Emailss\n \n 3a@goshihan.fr \n adlcj@wanadoo.fr \n afjgi1988@gmail.com \n annecyjapon@yahoo.fr \n ascjct@sfr.fr \n cdram@sfr.fr \n contact@japonfrance-grenoble.org \n francejapon73@yahoo.fr \n jfl44@aol.com \n lyonnihonjinkai@gmail.com \n mutsuko.tomokiyo@orange.fr \nniwa@emse.fr\n\n\n\n\nafjtoulon@gmail.com \nantipodes-japon@laposte.net \nassfranchaiku@yahoo.fr \nbamboo-orchestra@lafriche.org \ncontact@association-francojaponaise.fr \ncontact@taikobashi.net \ncum@ville-nice.fr \nfkeriguy@free.fr \nfrancejapon06@free.fr \nfrancojaponaix@free.fr \nhbonjean@yahoo.fr \njdgiacometti@hotmail.com \nkikyomoki@orange.fr \nmdjm@orange.fr\n\n\n\nakdn@free.fr \nakiko.gishi@free.fr \naleajapon@yahoo.fr \nbureau@epitanime.com \ncontactfr@artlevant.com \ncontacts@afjbulletins.com \ncontacts@ccfj-paris.org \nenseasie@ensea.fr \neuphonie@noos.fr \nikebana.paris@gmail.fr \nikebanaparis@free.fr \nikebanasogetsu.branchefrance@hotmail.fr \ninfo@bonjourparis.jp \ninfojipango@yahoo.fr \ninfos@espacejapon.com \njazzfrancejapon@free.fr \njetaafrance@yahoo.fr \nlilasdias@hotmail.fr \nmidori.s@free.fr \nreservations@ccfj-paris.org \nSoleilevant-lumieres@hotmail.fr\n\n\nacomnippon@gmail.com \napejali.comite@li-sectionjaponaise.org \nayasekoguchi@yahoo.co.jp \ncontact@tengumi.com \ncontact@wadaiko-makoto.org \ninfo@tenri-paris.com \nlayuaiassociation@gmail.com \nnardlife@numericable.fr \nokinawaburo@hotmail.com \npanafit@eurasiam.com \npigmentsetarts@yahoo.fr \npresident@nihon-go.net \nsfj@free.fr \nstpaumier@quartier-japon.fr \nvillage.monde@wanadoo.fr\n\n\n\nafjsakura@club-internet.fr \nassociationkaeru@orange.fr \natlantiquejapon1@gmail.com \nbambousy@yahoo.fr \nchristine.gouy@free.fr\n\n\nfrancejapon06@free.fr\n\n\naafj_tottori@hotmail.com \nadfejo@gmail.com \naecfj-nara@netz.co.jp \nafnagoya@afafa.jp \napek.kansai@gmail.com \napel-tu@themis.ocn.ne.jp \nfjkyoto@gmail.com \nfrancengs@utopia.ocn.ne.jp \nfukui_france@yahoo.co.jp \ni-grec@mub.biglobe.ne.jp \nifrajak@yahoo.co.jp \ninfo@ifjk.jp \ninfo@minatogumi.co.jp \nkikakuka@gamma.ocn.ne.jp \nkobenichifutsu@yahoo.co.jp \nm-fujimoto@re.commufa.jp \nnakajima@lastec.co.jp \nnichifutsu@suntory.co.jp \noffice@afj-tokushima.com \nsakurai.k@anahotel-kumamoto.com \nsetsuko.ryukyu.france@gmail.com \nsfif@siren.ocn.ne.jp \nsfjhimeji@yahoo.co.jp \nsfjhiro@crocus.ocn.ne.jp \nsfjkagawa@etude.ocn.ne.jp \nsnfm@wstone.miyasankei-u.ac.jp \nsocietefjk@yahoo.co.jp\n\n\n\n\n\nMami WATANABE mamwatalf@yahoo.co.jp\n\nNadia ODAJIMA : nadia.odajima@gmail.com \n\n\n Christophe PAUCOD (president@acpfj.com) \n Philippe BATTON (vice-president@acpfj.com) \nLionel BECCAT (vice-president2@acpfj.com) \nThierry VOISIN (vice-president3@acpfj.com) \n Alain VERZEROLI (vice-president4@acpfj.com) \nOlivier ODDOS vice-president5@acpfj.com\n Nicolas JAMBERT (secretaire@acpfj.com) \nDany FEC (secretaire2@acpfj.com) \n Cl?ent GROISNE (webmaster@acpfj.com) \nDominique TREMUREAU (tresorier@acpfj.com) \nDamien MAZARS (tresorier2@acpfj.com)\n\n\nMatthieu SEGUELA matthieu.seguela@sciences-po.org\n\n\ncontact@femmesactivesjapon.org \n\nYuki WATANUKI teapot-3@joy.ocn.ne.jp\n\n\n japon@ffe-ps.org \n \n  eelv.tokyo@gmail.com \n Janickmagne.eelv@gmail.com \nCedric.bertrand.cb@gmail.com \n\ncontact@bretonsdujapon.com \n\n\ndirection.sakuras@gmail.com \n\nSylvie MULLER sylmuller@gmail.com\n\n\nsabtechjapon@luck.ocn.ne.jp \n\netpaj@gol.com \n\npresident@sciencescope.org \n\n\nGoogle key APi\n\nKey for browser apps (with referers)\nAPI key:    \nAIzaSyCJ1DTw1dsB7JiZAsVtTIvB5krYWxmuQ-0\nReferers:    \nAny referer allowed\nActivated on:    Mar 5, 2013 5:18 AM\nActivated by:     yakimonofr@gmail.com ? you\n\n\n\namazon web front\nhttps://portal.aws.amazon.com/gp/aws/developer/registration/index.html\nyakimono\nobata235\n\n \n \nphotonic-picasa-panel-113183444192712523498-1-5897390857489390609\n\n\n\n\n\n\n\nL'utilisation du carnet ATA pour des op?ations d?admission temporaire\nIl n?y a pas de liste exhaustive de produits admissibles sur un carnet ATA. Toutefois, les marchandises devant faire l?objet d?une ouvraison ou d?une r?aration ou encore les consomptibles ne peuvent ?re repris sur un carnet ATA. \n\nLes motifs d?utilisation des marchandises repris en case C du document peuvent ?re les suivants : \n\n- marchandises destin?s ??re pr?ent?s ou utilis?s ?une exposition, foire, congr? ou manifestations similaires \n- mat?iel professionnel \n- conteneurs, palettes, emballages, ?hantillons et autres marchandises dans le cadre d?une op?ation commerciale \n- marchandises import?s dans le cadre d'une op?ation de production \n- marchandises import?s dans un but ?ucatif, scientifique ou culturel \n- effets personnels des voyageurs et marchandises import?s dans un but sportif \n- mat?iel de propagande touristique \n- marchandises import?s en trafic frontalier \n- marchandises import?s dans un but humanitaire \n- moyens de transport \n- les animaux \n- marchandises import?s en suspension partielle des droits et taxes ?l'importation \n\nPour chacun de ces motifs, des conditions sp?ifiques doivent ?re remplies pour b??icier de l?exon?ation totale. (Par exemple : pour le mat?iel professionnel, celui-ci doit ?re utilis?exclusivement par la personne qui se rend dans le pays d?importation ou sous sa propre direction.)\n\nervice\nM?ier\n\nNom usuel\nParis C.I.\nDirection\nPARIS\nAdresse\n2 RUE PAUL DUBOIS\n75003 PARIS \n*\n\n\nEtat-membre\nFrance (FR)\nCode EUROPA\nFR003230\n*\n\n\nT??hone\n09 70 27 21 10 \nFax\n01 42 71 26 47 \nE-Mail\nci-paris@douane.finances.gouv.fr  \nHoraire d'ouverture au public\n \n\n\nS?il s?agit d?une ?uvre qui est import? temporairement en France :\nGr?e ?l?importation temporaire (ou Admission Temporaire) une ?uvre peut entrer sur le territoire fran?is en suspension des droits et taxes applicables ?l?import.\n1? Une ?uvre d?art peut ?re import? temporairement en France en vue d?une exposition, d?une restauration ou d?une vente ?entuelle :\nL?importateur doit faire une demande d?Admission Temporaire et devra cautionner ?hauteur du montant des droits et des taxes (TVA) exigible ?l?import.\nL?admission temporaire est accord? pour un d?ai de 6 mois renouvelable jusqu??deux ans ?compter de son enregistrement aupr? des douanes.\nL??uvre en importation temporaire doit imp?ativement se localiser ?l?adresse d?lar? lors de la demande d?Admission Temporaire. Tout d?lacement hors de ce lieu doit recevoir autorisation pr?lable du Receveur des Douanes.\nUne ?uvre sous Admission Temporaire en France, devra obligatoirement voir r?ulariser son statut en ?ant r?xport? ou import? d?initivement.\n> Vous ?es un particulier : En aucun cas une ?uvre ne peut ?re admise temporairement en France au nom d?un particulier.\n> Vous ?es une maison de vente aux ench?es publiques :\nLa proc?ure d?admission temporaire d?une ?uvre en France peut ?re accord? aux maisons de vente en vue d?une vente aux ench?es.\nLe b??ice de l?Admission Temporaire en suspension des droits et taxes doit ?re garanti.\nAinsi, dans ce cas il existe trois possibilit? de garantir :\n1) Le cautionnement bancaire :\nLa banque de la maison de vente se porte caution.\n2) La consignation :\nLe montant des droits et taxes est pay?aupr? des douanes.\nCette somme sera d?uite des droits et taxes ?payer r?llement si l??uvre est vendue. Cette somme sera rembours? si l??uvre n?est pas vendue.\n3) La dispense de cautionnement :\nLes maisons de vente peuvent ?re dispens?s de cautionnement, si elles font partie du SYMEV ou de la Chambre des Commissaires Priseurs, en demandant par le biais de leur transitaire en douane une dispense de caution aupr? des douanes.\n> Vous ?es une galerie :\nVous pouvez ?re dispens? de cautionnement si vous appartenez au Comit?des Galeries d?Art (CGA) ou au Syndicat National des Antiquaires (SNA).\n2? Si l?exposition ou la restauration de l?objet est termin?, ou si l?objet n?a pas ??vendue :\ncelui-ci est r?xport?en exon?ation totale de toutes taxes (TVA) et droit de douane.\n3? Si la vente ?eu lieu :\nDans le cas ou l?objet est vendu ?un acheteur non r?ident europ?n, l?objet est r?xport?en exon?ation totale de toutes taxes (TVA) et droit de douane ?entuels (Voir le chapitre : Les formalit? de douane et la fiscalit??l?exportation, Sect I, 2?).\nDans le cas ou l?objet est vendu ?un acheteur fran?is ou r?ident europ?n, il est donc import?d?initivement apr? payement de la TVA ?5,5 % ou ?19,6 % et droits de douane ?entuels selon la nature de l?objet en question (voir ce chapitre : Sect I, ci-dessus).\nDans le cas ou l?objet est vendu ?un acheteur r?ident europ?n souhaitant b??icier d?une exon?ation de TVA sur son achat. La mise ?la consommation se fait alors en exon?ation de TVA mais apr? payement des droits de douane ?entuels. Cela ?la condition que l?acheteur soit  un assujetti enregistr?dans son pays et qu?il puisse communiquer son num?o de TVA Intracommunautaire (n? NII).\n\nD?laration en douane IMA = IMPORTATION\n\n\nD?laration en douane (IM4*)\nPour importation d?initive en provenance d?un pays tiers = D?laration de mise ?la consommation\nD?laration en douane (IM5*)\nPour importation temporaire en provenance d?un pays tiers = Admission Temporaire\nD?laration en douane (IM6*)\n* (Nomm? selon l?ancienne appellation de la proc?ure SOFI)\nPour r?importation au retour d?une exportation temporaire dans un pays tiers\nD?laration INF3 / INF6 :\nPour le transfert d?une Admission Temporaire entre deux pays de l?Union Europ?nne\n\n\n\n\n\n\nhttps://membres.planethoster.net\nCourriel: paris.yakimono@gmail.com\nMot de passe: EHi8ibJCH7\n\n\nPlanet Hoster\nparis.yakimono\nkyoto237\n\n\n\n\n\n\n\n\nYour application for the role of AVP/VP - Product Control has been sent to the following Michael Page consultant who will review your application and will be in touch with you as soon as possible:\nConsultant Name:    Christopher Snow\nConsultant Email:    christophersnow@michaelpage.co.jp\nConsultant Tel:    + 81 3 5733 7166\nJob Title:    AVP/VP - Product Control\nJob Reference:    H2002160\n\n\nYour application for the role of Manager, Risk Advisory - Big 4 Professional Services has been sent to the following Michael Page consultant who will review your application and will be in touch with you as soon as possible:\nConsultant Name:    Andy Clubbe\nConsultant Email:    andyclubbe@michaelpage.co.jp\nConsultant Tel:    + 81 3 5733 7166\nJob Title:    Manager, Risk Advisory - Big 4 Professional Services\nJob Reference:    H2114090\nFor your convenience you will also receive an email confirming your application containing the above information.\n\n\n\n-\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoe CHAN\nPremier Relationship Officer | The Hongkong and Shanghai Banking Corporation Limited\nThe Westwood HSBC Premier Centre LG01-03 The Westwood, 8 Belcher's Street, Hong Kong\n___________________________________________________________________________________\n\nPhone.     (852) 3663 0054\nFax.         (852) 3418 8777\nEmail.       joeyhchan@hsbc.com.hk \n\nBlackrock\nnoelkev1\nobata235\n\nChronopost:  08\n \nVous pouvez ?alement joindre Yuko,\nsa collaboratrice au n? : 07 86 02 45 18\n\nHSBC Japan\n\nsophieswchartz@nym.hush.com\n\n\nDear Mr Yellin,\n\nThansk for your kindness and still apologies:\n\n\nHere, the links:\n\n\nhttp://www.facebook.com/photo.php?fbid=361590643874244&set=a.295147417185234.79485.134946743205303&type=1&theater\n\n\nHere, the text, translation from Passion Ceramique Text:\n\nIn the context of Paris (France) Ceramic Fesival, one year after the earthquake in Japan, Paris Festival Team wishes to help and support the work of Japanese Ceramist colleagues through this festival. Thanks for your contribution.\n\n\n\n\n\nDestination Account: \tYen Savings 0007275822 JPY\nAccount balance after this transaction: \t288,647 JPY Available amount\n \nSource Account: \tPRESTIA MultiMoney Foreign Currency Savings Deposit 93479871 USD\nAccount balance after this transaction: \t0.82 USD Available amount\n \nForeign exchange rate:  \t103.05 JPY for 1 USD\n \nAmount: \t2,500.00 USD\n\n\nRemitter:\tMR. KEVIN NOEL\nDebit account:\tYen Savings: 0007275822\nAvailable amount:\t138,380 JPY Available amount\nBeneficiary name:\tKA)KANRIBANKU./n\nBeneficiary bank name:\tRISONA HEISEIDAIICHI\nAccount number:\t****42950\nAmount:\t150,000 JPY\nTransfer fee:\t267 JPY\nTotal to be deducted:\t150,267 JPY\n\n\n\n\n\nSecurity Code: o9ns7Rx%\nhttps://jpmchase.taleo.net/careersection/application.jss?lang=en&type=1&csNo=2&portal=540240092&reqNo=1272845&iamRegisterAttribute=1&iamCode=13919704\nkevno237\nsophie237\n\nchien \nlutine\n\n\n\n\nHSBC paris\n32367729390\ncateline\nGOJERSIO\n\n\n\ncitibank  23sep2013  details / prestia\nNOELKEVIN0\ngojersio237   \nPIN 4091\n\n\n\n\n960550\ngojersio\n4091\n\n\nPasswords for network    \nwc9Qk7nT8V\n\n\n\n\nHSBC\nAkasaka Branch\nFutsu\nBranch number: 110\n110 038346 888\n\nSWIFT HSBCJPJT\n\nTeamviewver\n8472\n958234119\n\n\nCFE\nkevinyakimono\nelise237\n\nMme Isabelle FLEURY\n01.53.68.56.73.\n\nSchumann, F. (Frank); Dannenburg, D.R. (Dennis); Meel, P.J.M. van (Peter); Mooijaart, H.K. (Klarien); Yee-Joy, V. (Vanessa)\n\n\n\nPackage no email \n\n\npr? le succ? retentissant, la marque renouvelle son amour et propose une ?ition limit? ?1650 exemplaires de la palette ?paupi?es bleu Facebook.\n\n\n\nYVES SAINT LAURENT RENOUVELLE L'OP?ATION TO FANS#1\nSignaler un abus\npubli?le 15 mars 2013\n? J'AIME61  \n\nL'??dernier souviens-toi Yves Saint Laurent rendais hommage ?ses fans Facebook en d?iant en exclusivit?une palette d'ombres ?paupi?e baptis? Devoted To fans#1.\nApr? le succ? retentissant, la marque renouvelle son amour et propose une ?ition limit? ?1650 exemplaires de la palette ?paupi?es bleu Facebook.\n \n \n \n\n\n\nING\n4829\n\n\nNarumi Kawasaki\n9, rue Stanislas\n75006 Paris\n\n\nING Life\n02244k_n\nkevin.noel-koide\n4829 \n\n\nAdresse Mr Kevin Noel\n162-0827\nTokyo, Shinjuku Ku, Wakamiyacho 26\nMyrtle Court Shinjuku WakamiyaCho\nF306\n\n\nCredit Mutuel  Paris\n0604520816901  ID Internet\n\n586756  Passwords\ngojersio\n\n\n\n\nhttp://boutique.yakimonos.com/list-all-product-stock.php\nyakimono\nkyoto1 \n\n\nPublication Etudiant\nhttp://www.parisetudiant.com/etudiant/ajout/evenement.html\n\nEvene.fr\n\nArt Actuel\n\n\n\n\n\nhsbc Japan\nNOELKEVIN0\n960550\nSecuirty Code\n\n\nHSBC fax HSBC PREMIER\n0033 140 70 35 00\nAmanda Bellanca\n\n\nReference  Opposition carte bleu\n13582997 7janvier \n+3 (3)1 40 70 35 00 \n\n\n\nRouter Fon Details\nProtocole\nPPPoE\nIP\n121.115.104.206\nPasserelle\n218.224.161.72\nServeur DNS\n220.220.248.2\n\n\n\nAccess fon  pass\nsophie237\n\nPLALA\n322zx4528@plala.or.jp\nfcy7gshx3rhfa\n1438\nfcy7gshx3rhfa\n\namazon\nbrookz771@gmail.com\ngojersio\n\n\nnoelkevin01\nelise237\npa\n\n\nLinked In\nnoelkevin @ nym.hush.com\nnuages941..\n\n\nPrint100\nkevinyakimono\nsophie237\n\n\n\nHSBC Champs Elysees Sabrina Walter\n0033 1 40 70 34 47\n\n\nAmazon FR\nbrookz771 gmail\ngojersio\n\n\nkevin4@nym.hush.com\nmerrill238\n\n\n\n\nHSBC BUSiness Direct\n30056   00949   09490028252  66\n\nInternet Business Direct\n00084795286\nlutine\n960550\n\n118479\n\n\nCarte Bleue Code\n4971 4101 2261 6061\n03/13\nYAKIMONO SARL\nM KEVIN NOEL\n\n\n\nhttp://www.yakimonos.com/_document/exhibition/YAKIMONO_Exhibition_Art_Abordable_web_page1.pdf\n\nhttp://www.yakimonos.com/_document/exhibition/YAKIMONO_Exhibition_Art_Abordable_web_page2.pdf\n\nhttp://www.yakimonos.com/_document/exhibition/Yakimono_Exhibition_Photos_Paris_01.pdf\nhttp://www.yakimonos.com/_document/exhibition/Yakimono_Exhibition_Photos_Paris_02.pdf\n\nhttp://www.yakimonos.com/_document/exhibition/YAKIMONO_Exposition_WASHI_YAKI_Dec2011.pdf\n\nhttp://www.yakimonos.com/_document/exhibition/YAKIMONO_festival_ceramique_PARIS_dossier_presse_web4.pdf\n\nhttp://www.yakimonos.com/histoire_Yakimono_japanese.pdf\n\nhttp://www.yakimonos.com/photos_festival_ceramique_paris.pdf\n\n\nhttp://www.yakimonos.com/yakimono_histoire_ceramiques_japonaises.pdf\n\n\nhttp://www.yakimonos.com/_document/exhibition/YAKIMONO_TAKATORI_YAKI_festival_ceramique_paris.pdf\n\nDear Mrs Katsumata,\n\nWe have received your interest for Yakimono ! few months ago.\nAlthough very interesting, it was difficult to start discussion\nbecause we were focused more in developping Paris activities and exhibitions..\n\nNow, as we are more setup in Paris, we have interest to do exhibition in Paris,\nat our gallery space, of Japanese Ceramists and we are looking for new Artists.\n\nPlease find a couple of previous exhibition :\n\nhttp://www.yakimonos.com/_document/exhibition/YAKIMONO_Exhibition_Art_Abordable_web_page1.pdf\nhttp://www.yakimonos.com/_document/exhibition/YAKIMONO_Exhibition_Art_Abordable_web_page2.pdf\nhttp://www.yakimonos.com/_document/exhibition/YAKIMONO_Exposition_WASHI_YAKI_Dec2011.pdf\nhttp://www.yakimonos.com/_document/exhibition/YAKIMONO_festival_ceramique_PARIS_dossier_presse_web4.pdf\nhttp://www.yakimonos.com/histoire_Yakimono_japanese.pdf\n\n\n\nHope you will be happy to discuss with us to promote Japanese Ceramics overseas.\n\nThanks very much for your understanding\nYakimono Team (Kevin)\n\n\nPaypal\nkevin.yakimono  gmail\nelise237\nCB PP*8461CODE 20/03\n\n\nboutique Yakimono\nkevin.yakimono\nelise23\n\n\nCFE\nkevinyakimono\nelise237\n\n\nSARL Yakimono !\nCapital de 25,000 EUROS.\nRCS 530512779\nSIRET 530 612 779 00013\nNAF 4778C\n4 Rue Galvani\n75838 Paris Cedex 17\n\n\n\nYakimono Fax Number\n33 1 74 18 08 37\nkevin.yakimono @ gmail.com\nsophie237\n\nSend a Fax:\nfaxnumber(country code)_@myfax.com\n\nSubject: Name of the person\nBody: Your Name and reference\n\n\nnoelkevin1 hotmail.com\nsophie238\n\n\n\n\nHSBC \nHong Kong\nGOJERSIO\n400122\n\n\n\n\n\nhttps://docs.google.com/uc?export=download&id=YourIndividualID\n\n\n\nTelephone HSBC Premier Phone    \n+ 010  33 1 55 69 74 74\n\nHSBC Paris Premier:\n32367729390 16639\n\nLogin Code: 32367729390   16639\nusername: NOELKEVIN \n\nHSBC Internationnal FRANCE Interent \nNOELKEVIN GOJERSIO\nlutine maryvonne 2006\n\n\n\nReference 7500 euros.\n1q0vkqf\n\n\n\nReference:  \n13582997\n\n1) Courrier de reference: perte.\n2) \n\n\n\nFax pour enregistre mon compte a distance.\n\nHSBC Premier Direct:\n01 40 70 35 00\n\nInstruction\n\nSort Code    Branch number    Account number    RIB code     \n30056     00419     04190023988     28     \n \n IBAN (International Bank Account Number)    BIC Code\n FR76 3005 6004 1904 1900 2398 828     CCFRFRPP\n \n Branch name\n HSBC FR PREMIER IN DIRECT\n M. NOEL KEVIN\n \n \n fax  33140703500 \n \n \njo2onvkn\n\nNOELKEVIN0\n960550\n\n\nyakimonofr @ gmail.com\ntokyoparis37\n\n\nCareer Cross\nkevinhhh3 @ gmail.com\nsophie237\n\n\n\nML Benefits  www.benefits.ml.com\nnoelkevin12\nsophie237\n\nPIN: 767443 237\n\n\nSSID: Social Security Numbers 883924935\nMerrill Account:  IIA 5RD11710\nPerso Number: 2476516023:03 12/10/2011\n\nPhone Number: 1 800 6374015\n\n\nCFE kevinyakimono elise237\n\nE-mail : autoentrepreneur75@ccip.fr Internet :\nwww.entreprises.ccip.fr/web/formalites\n\nT?. : 0 820 012 112 Fax : 01 55 65 48 88 Ouvert au public sans\ninterruption de 9h ?16h, du lundi au vendredi. Ouvert le\nmercredi jusqu'?12h.\n\nDossier ACCRE Exoneration M.  Noel Kevin   - Soci??Yakimono\n  Bienvenue dans votre espace personnel. Dossier n? VX27IXPG\n\n\nSecurite Sociale: 1 80 04 99 237 010 75\n 180049923701075\n \nOcukZsQz.\n\nThelia Yakimono \nUtilisateur : Kevin \nMot de passe : ju3uq84v\n\nPour y acc?er  partie adminsitrative, partie japonaise:\nwww.yakimonos.com/japan/imagevue identifiant : admin123321 mot\nde passe : kenaruvin987\n\n\nPour acc?er au back-office : Lien :\nhttp://boutique.yakimonos.com/administration Utilisateur :\nKevin Mot de passe : ju3uq84v\n\n\n\nBureau Virtuel https://bo.entreprise-facile.com/account/index/0\nkevin.yakimono@gmail.com sophie237\n\nNumero de Fax: 01 41 02 68 73 HSBC\n\nGreffe de tribunal de Paris RCSt 530612779\n\nG7554 0274977 2011B03510\n\nID Card R412046(8) Date of Issue 01-06\n\nBooking Reference Number: KQFQ9\n\nyakimonofr tokyoparis41\n\nNarumi: 336 03 97 00 07\n\nAkiko > >> >06 23 04 89 73\n\nmerci pour ta r?onse rapide mon email ghislain.perisse@axa-\nim.com tel +33 6 44 23 99 44\n\nE Financial Career kevinefinanc elise237\n\nHannae Louizate Numero RIB HSBC numero\n\nFR7630056 00949 09499653160 - 11\n\nFR7630056\n\nGuichet 00949\n\nCompte 09499653160 - 11\n\nBIC/Swift CCFRFRPP\n\n103 AvenuE Champs\n\n1000 Euros Yakimono\n\nDepot Capital Yakimono\n\nelise237\n\n\n\n888fs7557@plala.or.jp\naef7ykzf4ezay\n\n\nPlugoo kevin.yakimono@gmail.com elise237\n\nkevin.yakimono\n\n\n\nTel: 080 4119 4019\n\n\n\n\nEuro Domicialisation\nTel . (33) 1 56 68 91 12\nFax. (33) 1 56 68 91 13 \n\n\n\nAmazon Japan Tomoko tomokoi37 imesnoopy13\nFTP repertoire: 7824_yakimono osozeland31\n7824_develop osozeland23\n\nBDD: 7824_boutique\n\nHSBC Secure Key\nContactez-nous au\n0 810 2 4 6 8 10*\nChoix 0\n\n\n\ncl_rusu@yahoo.com\nstevem994 gmail sophia\n\n\nEtape 1\nHSBC Premier Paris 32367729390    code 16639\n\nEtape 2\nHSBC Internationnal Interent NOELKEVIN GOJERSIO\n\nHSBC PREMIER NOELKEVIN GOJERSIO\n\nHSBC Paris Mrs Amanda BELLANCA RAY Email : ag-pid@hsbc.fr\nTelephone : +33 (0) 1 55 69 74 74\n\n\n\nlutine maryvonne 2006\nCateline\n\n\nD?ail de la carte mise en opposition\n\nNOM DE LA CARTE    NUM?O DE LA CARTE    DATE D'EXPIRATION    COMPTE DE RATTACHEMENT    RAISON DE L'OPPOSITION\nCARTE VISA    4971 6015 9891 2600    01/15    CAV CHEQUE 04190023988    Carte perdue\n\n\n\n\n\n\nGmail kevin.yakimono@gmail.com sophie237\n\nmaryvonne\nlutine\n\n\n1.      Click Start, please type \"inetcpl.cpl\" (without quotation marks) in the Start Search bar and press Enter to open the Internet options window.\n2.      Switch to the Advanced tab.\n3.      Click the Reset Internet Explorer Settings button.\n4.      Click Reset to confirm the operation.\n5.      Click Close when the resetting process finished.\n6.      Uncheck Enable third-party browser extensions option in the Settings box.\n7.      Click Apply, click OK.\n8.      Reboot your PC\n9.      Access SSL-VPN again\n \n\n\nsuzanna.de.oliveira@hsbc.fr\n\njonathan.turner @ tardis-group.com\n\nBNP Team Anything urgent, you can reach: Ruth Cheung +852 2108\n5784 Linda Chan +852 2108 5603 Chloe Thery +852 2108 5575\n\nHappy holidays Franck Launay\n\nbrookm291 gmail.com elise237\n\nbrookn341 gmail.com elise237\n\nHi, Happy New Year! This is my new facebook profile from Tokyo.\n\nCheers Kevin\n\nFacebook Account kevin1@nym.hush.com brooky773 @ gmail.com\nelise237\n\n\nTelephone: 080 4119 4019\n\nFranck Launay je ne suis plus sur de t avoir repondu... avec\nplaisir pour un cafe.. je risque voyager cette semaine.. mais\nje te donne mon phone +852 6891 1036.\n\nRapidShare brooky776@gmail.com sophie237\n\nLabochi Japanese Teaching brook291@gmail.com sophie237\n\nBit Defnder brookn314 @ gmail.com sophie237\n\nID Card\n\nnoelkevin1 @ hotmail.com sophie237\n\nnoelkevin1 @ gmail.com sophie237\n\nHBSC accnt: 083 662569 833\n\n\n\nHushmail \nnewyork975 hush com \nnuages987.. \n\nYou will be asked to\nenter your private desktop access password: 01a58e3c\n\nkevin1  @nym. kevin3 @nym.\n\nkevinlinkedin @nym. kevlogin @nym.\nnoelkevin @nym\n\n\nLinkedin Connection\nnoelkevin @nym.hush.com\nnuages941..\n\n\n\n00167728  Sylvain\n\n\n\nGaijin Pot\nUser Name: pierre237\nPassword: sophie237\nRegistered Email Address: brookn341@gmail.com\n\n\n\nActivate but cannot use it. newyork991 mac hush com nuages987..\n\nWilliam Yau, Morgan Mc Kinley kevinhhh2 @ gmail.com sophie237\n\nRazin Kevinhh3 @ gmail sophie237\n\nGaijin Pot brooky773+gaijinpot@gmail.com hiroko\n\nYahoo Photosansys@yahoo.com sophie237\n\nIinterative Brokers log yakim499 elise237 U944754\n\nAccount Boting IB yaki499 sophie23\n\nAccount U944754 - KevinNoel IB 40806826 Fed Wire 021000089\n\nBloomberg yakim499 elise237\n\n\n\n\n\n\n*************************************\nwww.absolutereturn-alpha.com Username: kevin7@nym.hush.com\nPassword: KN152728\n\nRisk Username: kevin7@nym.hush.com sophie237\n\nNew permanent login brookn341@gmail.com sophie237\n\nkevinh9@mac.hush.com nuages947..\n\nBertrand Bailly bertrand.bailly@robertwalters.co.jp +81-(0)\n3-4570-161\n\n9. Lionel Kaidatzis, Morgan Mac Kinley\nlionel@morganmckinley.co.jp kevinhh8 @ mac.hush.com nuages947..\n\nWilliam Yau kevinn1 @mac.hush.com sophie237 My number is\n+81-80-6638-7773.\n\nAlexander De Giorgio 03-5403-7017\nadegiorgio@morganmckinley.co.jp\n\nbrooklyn378 hush.com enfantdelapatrie36.\n\nLes inrocks brooke778 elise237\n\nKevin France stevem997@gmail.com elise237\n\nasia miles 1526709983 960550\n\nAmex noelkevin elixir23\n\nWhitWall kevin7@nym.hush.com elise237\n\nstevem997@gmail.com\n\nAdresse de l'interface     \n-> https://www.produhost.net Num?o\nclient  14125 Mot de passe  4aNncBFH\n\ntomoko.yakimono  gmail mot de pass: kevinime\n\nyakimono@mac.hush.com nuages947..\n\nyakimonofr@gmail.com paristokyo23\n\nkevin.yakimono@gmail.com nugaes941..\n\nXmarks brooks778 kevin7@nym.hush.com elise237\n\nkevin7@nym.hush.c elise237\n\nPalringo nuages947..\n\nkevinono36@gmail.com nuages947..\n\nEbay brooks778 kevin7@nym.hush.com nuages947..\n\njohn7927 @ gmail.com elise237\n\niphone brookn341@gmail.com   Sophie237   \njordan27 6900 5510 960550\n\ntomokoi nuages947..\n\nkevin23@mac.hush.com nuages947.\n\nANA Miles 4091 kevinh9@mac.hush.com 4340815954\n\nbrookz973 @ gmail . com linkedcontact@nym.hush.com\nnoelkevin@nym.hush.com nuages941..\n\nkevinhh5 @ mac.hush.com nuages947.. 4. Ramin Mellegard-\nramin@nexusjp.com\n\nkevinhh4@hushmail.com   Daniel Weston nuages947.. Not\nactuvatesd\n\nkevinhh3@mac.hush.com     Lyle Andrews nuages947..\n\nkevinhh2@mac.hush.com     Abla Lemzeri HH  Anso MacCade\nnuages941..\n\nkevinhh1@mac.hush.com   Claudia Rusu nuages947.. Arlon Brown,\nDaniel Weston\n\n8. Claudia Rusu kevinh2@mac.hush.com nuages947..\n\nAlan S. Reeve Associate - Global Markets, Financial Services\nPractice ____________________________________ Heidrick &\nStruggles Atago Green Hills MORI Tower 38F 2-5-1 Minato-ku,\nTokyo, 105-6238 tel:   +81 (3) 4520 7810 mob: +81 (90) 7815\n0299 fax:  +81 (3) 4520 7839 Email: areeve@heidrick.com Web:\nwww.heidrick.com ____________________________________\n\nkevinh9@mac.hush.com nuages947..\n\nBertrand Bailly bertrand.bailly@robertwalters.co.jp +81-(0)\n3-4570-161\n\n9. Lionel Kaidatzis, Morgan Mac Kinley\nlionel@morganmckinley.co.jp kevinhh8 @ mac.hush.com nuages947..\n\nWilliam Yau kevinn1 @mac.hush.com sophie237 My number is\n+81-80-6638-7773.\n\nAlexander De Giorgio 03-5403-7017\nadegiorgio@morganmckinley.co.jp\n\nnewyork297@hushmail.com requiem987.. Steven Root, Kaizen\nPartners, Razin Ashraf\n\nCraig Atkinson <craigatk@gmail.com> Charles Rue\n\nFacebook alhjamal@nym.hush.com nuages947..\n\nbrooklyn378 enfantdelapatrie47.\n\nkevinhh3@mac.hush.com nuages947.. Razin Ashraf  Hays Co.jp\n\nkevnormand @ gmail . com sophie34\n\nEvernotes Accounts: tomokoi320874@yahoo.com imesnoopy snoopy\n\nYakimono Account\n\nsteve997 stevem997 poisson27\n\nprenom de mn chien: lutine\n\nWebsite Gestion: https://www.produhost.net 14125 4aNncBFH\n\nWebsites: 7704_yakimono osozeland\n\nanszys.net\n\nAnonymous Software elisedurel hiroko eliotgray@nym.hush.com\n\n\nUnited States 1 (312) 542-6901 Direct dial Europe\n+41-41-726-9500 Direct dial  (Swiss) account U944754\n\nbrooky773@gmail.com sophie237\n\nUsed Only with Gaijin and unficonfidence people\n\n\n\nkevinhh1@mac.hush.com nuages947..\n\nnewyork297 requiem987.. enfantdelapatrie37.\n\nFacebook alhjamal@nym.hush.com nuages947..\n\nbrooklyn378 enfantdelapatrie36.\n\nEvernotes Accounts:\n\ntomokoi320874@yahoo.com imesnoopy snoopy\n\nsteve997 stevem997 poisson27\n\nyakimonofr@gmail.com paristokyo23\n\nprenom de mn chien: lutine\n\nDRI Website Gestion: https://www.produhost.net 14125 4aNncBFH\n\nanszys.net\n\n\ntese\nsiret\n53061277900013\nelise237\n\n\n761.24\n\n\nPour Appeler depuis Iphone:\n\n1. Appeler 006610 2. Code 2540331084 3. Puis # # # trois fois:\n4. Puis numero 33 1 55 69 74 74  (HSBC Business direct)\n\nSylvie\n\nag-businessdirect@hsbc.fr Poue etre appeler chez HSBC Business\nDIrect, envoyer un email et ils nous appellent apres.\n\nPas de compte en Yen, compte en EUROS + Change pour facture.\n\nAttente de reception du dossier.\n\n\n\n\n\nSARL Yakimono !\nCapital de 25,000 EUROS.\nRCS 530512779\nSIRET 530 612 779 00013\n53061277900013\n\nNAF 4778C\n4 Rue Galvani\n75838 Paris Cedex 17\n\nTESE de Bordeaux\nTSA 10101\n\n\nCommerce \nCDD: Site Internet\nTESE:   Payer, heure, RIB, Signe, \n2 semaines, ASSEDIC\n\nScanner: 19 avril, Reel aux accomptes, \nSaisie Compte:\n\nVOTRE_EXPERT Comptable:  0141432390\nVOTRE_EXPERT Comptable:  dalia lafond\nMarc SMADJA\nDirecteur     Tel      33 (0)1 41 43 23 90\nFax     33 (0)1 41 43 23 99\nmsmadja@alephconsultants.com\n\nYakimono admi\nadmin123321\nkenaruvin987\n\nThelia\nkevin\njetaime\n\nCarrefour\nyuko.yakimono@gmail.com\nyakimono\n\ndarty\nkevin.yakimono@gmail.com\nyakimono\n\nRaja\nIdentifiant : yakimono\nmot de passe: SmEXVvUm\n\nFree (3244)\n0148284583\naicheivu\n\nIdentifiant ; 10457789\nCode ; 2798\n\ntelephone FREE 09 51 53 29 43\n\n\nJunko Glass\n06.31.32.86.78.\n09.81.13.67.23.\n\n0631328678\n\nIKEA\nT??hone :0970 808 720 (appel non surtax?\n\nMOT DE PASSE 1YAKIMONO\n\n\nYAKIM FREE Wifi mot de passe\n123456789F\n\n\nSARL Yakimono !\n14 Rue de Langeac, 75015, PARIS\nSIRET 530 612 779 00013\nCode NAF 4778C\n\nTel.  +33 (0)9 51 53 29 43\nFax.  +33 (0)1 74 18 08 37\n\n\n\nmadame Ozawa OVNI\nozawa@ilyfunet.com\n01 47 00 11 33\n\n\n06\n\n\n\n\n\nMr Frederic Gibert\nSCI De la Grande Armee\n35 Avenue Victor Hugo\n75016 Paris\nSIREN 503 165 623\n\n\n- Mr Pierre Brizi  06 84 55 50 63\n- Mr Frederic Gibert 06 73 77 05 02\n\n- Nicolas  06 72 33 69 83\n- Mr Kwon 06 23 03 38 79\n- Mr Jabri 01 56 08 26 61\n           06 25 24 56 34\n\n\n\n\nAdresse Bureau (toujours celle ci a utiliser):\nSARL Yakimono !\n14 Rue Langeac\n75015 Paris\n\nAdresse Siege Sociale:  (Jamais utiliser cette adresse)\n4 Rue Galvani\n75838 Paris Cedex 17\n\n\nAdresse Kevin Noel ?Tokyo\nCP 160-0015 \n28-12, shinjuku gyen, Daikyo cho,  Shinjuku, Tokyo Japon\n\n162-0827\nTokyo, Shinjuku Ku, Wakamiyacho 26\nMyrtle Court Shinjuku WakamiyaCho\nF306\n\n\n\nNumero portable 00818041194019\n\n\n\n19/04/1980\n\nBanque Details:\nHSBC Business Direct\nCompte: 30056   00949   09490028252  66\n\nAdresse: 103 Avenue des Champs Elysees, 75419 Paris Dedex 08\nTel: 08 10 01 21 21\n\n\n\n\nLa poste\n3436\nsouhila.ouachemi@laposte.fr\n\nAffrachissement en ligne\nyuko.yakimono@gmail.com\nyakimono\n\nOffice depot\nidentifi  yakimono\nmot de pass yakimono\n\nMurai Nobuyuki\n0748-82-3635\n\ncontacts.yakimono@gmail.com\nibaraki237\n\nEau de paris\nIdentifiant;yuko.yakimono@gmail.com\nMot de passe ; AqbwsSJw8T\n\n\nSARL Yakimono !\nCapital de 25,000 EUROS.\nSIRET 530 612 779 00013\nCode NAF 4778C\nTel: 09 51 53 29 43\nFAx  33 1 74 180 837\n\nAdresse Bureau (toujours celle ci a utiliser):\nSARL Yakimono !\n14 Rue Langeac\n75015 Paris\n\nAdresse Siege Sociale:  (Jamais utiliser cette adresse, adresse administrative)\n4 Rue Galvani\n75838 Paris Cedex 17\n\nADMINISTRA TION,G?ant M. NOEL K?in\ndemeurant 28-12, daik yocho, shinjuku-ku ShinjukuGyoen, 99 Tok yo\nJapon\n\nNouvelle Adresse Tokyo:\n162-0827\nTokyo, Shinjuku Ku, Wakamiyacho 26\nMyrtle Court Shinjuku WakamiyaCho\nF306\n162-0827\n?????????26???????F306\n\nNum?o de t??hone ; 00 81 80 4119 4019\n\nTampon texte:\n\nSARL Yakimono !\n14 Rue Langeac, 75015 Paris\nSIRET 530612779 00013\ncontact@yakimonos.com\n\n\nYakimono Fax Number:    33 1 74 180 837\nwww.Myfax.com\n\nPour envoyer un Fax,\n\n1. Envoyer un email avec pieces jointes PDF ou Word\n2. Adresse   Exemple Fax: 01 41 43 23 99,   email adresse: 33141432399@myfax.com\n3. Le fax va etre automatiquement envoye au numero +33 (0)1 41 43 23 99, une confirmation sera envoyee\n\n\nBanque Details:\nHSBC Business Direct\nCompte: 30056   00949   0949 002 8252  66\n\nAdresse: 103 Avenue des Champs Elysees, 75419 Paris Dedex 08\nTel: 08 10 01 21 21\n\n\n\n\n\n\n\n\nMr, Kevin Noel\n\n162-0827\n\nTokyo, Shinjuku Ku, Wakamiyacho 26\nMyrtle Court Shinjuku WakamiyaCho\nF306\n\n\n\n\nDARTY\n\nkevin.yakimono@gmail.com\nyakimono\n\n\n\nIkea Details\nhttps://secure.ikea.com/webapp/wcs/stores/servlet/ProtectedUpdateUser\n\nLogin:   kevin.yakimono@gmail.com\n Pass:  1yakimono\n\n\n\nEDF :\nL'indentifiant Internet: yuko.yakimono@gmail.com\nMot de passe : yakimono2011\nQuestion secr?e : Mon lieu de naissance - Tokyo\nR??ence client : 100 1225 763\nEl?tricit?: 3 05 3005 751 001\nIdentifiant compteur : U89 99 90\nEspace client ; https://agence.edfpro.fr/ASPFront/appmanager/WebPro/front?_nfpb=true&_pageLabel=pro_page_authentification\n\n\nFREE (Internet et t??hone)\nNum?o de t??hone ; 09 51 53 29 43\n\nPour acc?er mon compte sur le web\nhttps://adsl.free.fr/suivi/suivi.pl?id=10457789&idt=0e4ff22a1e85f649\nIdentifiant : 0148 28 45 83\n(Ancien Identifiant   : 0142501580)\nMot de passe : aicheivu\n\nR??ence Client\nIdentifiant ; 10457789\nCode ; 2798\n\n\n\nProprietaire:\n\nMr Frederic Gibert\nSCI De la Grande Armee\n35 Avenue Victor Hugo\n75016 Paris\nSIREN 503 165 623\n\n\n\n- Mr Pierre Brizi  06 84 55 50 63\n- Mr Frederic Gibert 06 73 77 05 02\n\nArnaud Nicola?\n\nAK HOME\n40 avenue Hoche\n75008 Paris\nFrance\nMobile : 06 11 97 40 24\narnaud@nicolay.net \n\n\n\n\n2/28/2011 RCS - Extrait Extrait KBIS\nGreffe du Tribunal de Commerce de Paris\n1, quai de la Corse\n75198 PARIS CEDEX 04\nKBIS\nEXTRAIT DU REGISTRE DU COMMERCE ET DES SOCIETES\nau 27f?rier2011\nIDENTIFICA TION\nD?omination Sociale :\nNum?o d'identification :\nNum?o de gestion :\nDate d'immatriculation :\nYA KIMONO!\n530 612 779 R.C.S. PARIS\n2011 B 03510\n17f?rier2011\nRENSEIGNEMENTS RELA TIFS A LA PERSONNE MORA LE\nForme juridique :\nAu capital de :\nSigle :\nAdresse du si?e :\nDomiciliataire :\nActivit? principales de la soci??\nDur? de la soci??:\nDate d'arr??des comptes :\nConstitution - D?? de l'acte\nconstitutif :\nPublication :\nSoci???responsabilit?limit?\n25000 ?\nya ki\n4, rue Galvani 75838 Paris Cede x 17\nC D F - 4 RUE GALVANI 75017 PARIS (423 205 202)\nachat,vente de produits artisanaux non r?lement?.\nJusqu'au 16f?vrier2026\nle 31/12\nAu Greffe du Tribunal de C omm erce de Pa ris le 17f?vrier2011\nnum?o 15782\nJournal L'auvergnat de Paris du 10-02-2011\n:\nsous le\nA DMINISTRA TION\nG?ant M. NO EL K?in\ndemeurant 28-12, daik yocho, shinjuku-ku ShinjukuGyoen, 99 Tok yo\nJapon\nRENSEIGNEMENTS RELA TIFS A L'A CTIVITE ET L'ETA BLISSEMENT\nOrigine du fonds ou de l'activit?:\nActivit?:\nAdresse de l'?ablissement\nprincipal :\nD?ut d'exploitation le :\nMode d'exploitation :\nCr? tion d'un fonds de commerce\nachat, vente de produits artisanaux non r?lement?.\n4, rue Galvani 75838 Paris Cede x 17\n10janvier2011\nExploitation directe\ngreffe-tc-paris.fr/OnLineProduct.php?I? 1/1\n\n\n\nTESE de Bordeaux\nTSA 10101\n\n\n\nL??at des lieux  fait au 28 Avril 2011\n-Bailleur ; SCI de la Grande Arm? repr?ent? par son mandataire Arnaud Nicolay de l?agence AK HOME\n-Adresse ; 14 Rue de Langeac 75015 Paris\n\n-Trois crit?es ; A = Bon ?at , B = ?at d?usage, C = mauvais ?at\n                                                SOL              MUR          PLAFOND\nPi?e sur Rue                        A                   A                      A\nPi?e sur Cours                    A                   A                     A\nCabanon                                 C                   C                    C\n\n- Nombre de clefs remises ; 1\n- Relev?des compteurs EDF; 60325\n\n\n\n\nExpert Comptable:\nVOTRE_EXPERT Comptable:  0141432390\nVOTRE_EXPERT Comptable:  dalia lafond\nMarc SMADJA\nDirecteur Tel      33 (0)1 41 43 23 90\nFax     33 (0)1 41 43 23 99\nmsmadja@alephconsultants.com\n\n\n\n\n\n\n\n",
			"file": "/D/Dropbox/_text/email1.txt",
			"file_size": 134292,
			"file_write_time": 131925455463687279,
			"settings":
			{
				"buffer_size": 127650,
				"line_ending": "Windows"
			}
		},
		{
			"file": "/D/Dropbox/_text/coding.txt",
			"settings":
			{
				"buffer_size": 277050,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "ztodo_list.txt",
			"settings":
			{
				"buffer_size": 3952,
				"line_ending": "Unix"
			}
		},
		{
			"contents": "Proba calibration :\n  actual proba == Model probabiliy.\n\n  Find Kaiso that \n    Actual proba == Model probability +- error\n\n    A set of range s1, s2, s3, ....sn  \n    Actual probability\n\n\n\n\n\n\n\n\n#########################################################################\n\naccumulate experience : 経験を積む\nmigaite: improve\njiko keihatsu : self-improvement\nkizukitai : to build\nkajika suru : visualize\nKeiei-jin ni tsutaeru : tell management.\nteiryoki :  quantitative.\nkeii-jin : Management Team\njakuten / iiten : good point\n\nOn one hand : 一方では\nOn other hand : 一方で, sono atode\n\n\n2)#### Rakuten, which role\n   Principal Data Scientist, \n   Project no kouken, kikai gakushuu no riyou\n\n   3-tsu no project :\n     1 Search Recommender system\n     2 Data processing : NLP\n     3 Scoring model : user data, score model.\n\n\n3) #### Jakuten / Tsuyuoi ten ?\n  nihongo ha mada tarinai desu\n  joujou ni joutatsu shite imasu.\n\n\n4)#### Naze Rakuten wo detai ?\n  Recruiter kara, \n  Career no tame, Axa to Axa group wo kyoumi ga aru.\n  Izen no Hoken gaisha to Big Data \n  wo ikasu koto ga arimasu.\n\n\n5)#### Manager toshite, Nani ga dekimasu ?\n   ING de assistant manager toshite,\n   financial engineering team wo kanri shite.\n   Modelling no kaizen no tame,\n\n   on other hand, kinyu system development.\n\n   Shin shouhin no kaihatsu no tame,\n      actuary to hataraita.\n\n   ooha na keiken, manager toshite, bukka ni keiken wo tsutaete, \n\n\n6)##### Hoka no bumon to, communication process dou shimasu ka ?\n   Kaisha no houshin, yari kata wo benkyou shimasu.\n\n\n7) ############### Naze  Axa wo kyoumi ga arimasu ka ?\n  Moto moto, Izen on kinyu no keiken wo ikashitai desu.\n\n  Nagai aida ni, Axa Group wo kyoumi ga arimaru.\n  Axa Group ha Nihon de, Gaikuoku de career ga kanou ga arimasu.\n\n  Kinyou kaisha to Hoken gaisha deha arimasen.\n  Big Data ha ok desuga, Business ha \"beginner\", \n  Business keiken ga nai, hanashi nikui desu.\n\n  Hoken no pricing model wo keiken ga arimashita.\n  Actuary to hatarita kara,\n\n\n8) ############### dona project ?\nProject kouken ni shinagara,  izen no keiken wo ikashitai desu.\nShoshitara, project no sakusei.\n\n\n9) ############# Manager to Specialist no path   ?\n10 nen kan, Kinyuu to Hoken Gaisha to Big Data ga arimasuka, \nsenior manager to tame, manager toshite, keiken no share shi yasui to omoimasu.\nData Senryaku ni kouken shimasu.\n\nGenzai, specialist level ga takai to omoimasu, amari shinpo dekinai.\nDaigaku de benkyou igai, shinpo ga dekinai to omoimasu.\n\n\n\n2 tsu noo bubun ni wakeru koto gadekimasu.\n  Project no senryaku\n  Project no jitsu no gitjutsu no riyou : Deep Learning, Jitsu model.\n\n\n10) #### Big data system  no riyou ?\n   Senmon desu.\n   Search system no tsukuru tameni :\n      Kafka, Spark, Hadoop system.\n\n    \n11) #### API system wo tsukuru\n\n\n\n\n13) ####   \n\n\n\n\n\n\n\n\n\n\n##### Question to Company :   ###########################################\n  Zama na request\n\n1) Gutani teki dona Project ni sanka  shinakya ?\n\n2) Tatoeba, project no output ha\n  model mataha API system ですか？\n\n3) Team no yakimu wari\n\n4) Data senryaku\n\n \n  Team deha, Sugakusha mataha Actuary no shushin ha irashaimasuka ?\n\n\n\n\n\n\n\nYoku mirareru machigai wa, jiko shōkai o motomerareta toki ni \njiko PR o shite shimau case desu. Futatsu no chigai wa nani ka to iu to, jiko shōkai wa `aisatsu' to `komyunikēshon no kikkake-tsukuri' de, jiko PR wa `nōryoku ya iyoku no apīru'desu. \n\nMensetsu-kan kara sureba, jiko shōkai o motomete iru no ni,\n tsuyomi, sukiru, chishiki, kachikan, iyoku nado o hanasa rete wa tōtotsu-sa ni konwaku shite shimaimasu. `Shitsumon no ito o rikai shiteinai noda na' to komyunikēshonsukiru o utagawa reru koto ni mo nari kanemasen. Jiko shōkai to shite hanasu koto to, jiko PR to shite hanasu koto wa wakete kangaemashou.\n\n\n\n\n\nShūkatsu no mensetsude wa jiko PR ya shibō dōki wa kanarazu kika reru shitsumon'nanode, hotondo subete no gakusei-san ga junbi shite kimasu. Shikashi, mensetsu ga hajimatte ichiban saisho ni `kantan ni jiko shōkai o shite kudasai' to iwa reta toki ni, junbi fusoku de awatete shimau gakusei-san ga takusan irasshaimasu. Jiko shōkai to wa jiko PR to wa dō chigau nodeshou ka? Nani o hanashitara yoi nodeshou ka? Korera no gimon o kaiketsu subeku, jiko shōkai to jiko PR no chigai to jiko shōkai de hanasubeki naiyō ni tsuite go setsumei shite ikimasu. Jiko shōkai o shite kudasai to iwa rete mo awatenai yō ni, shikkari jiko shōkai no naiyō o haaku shite ikimashou. Mokuji `jiko shōkai' to `jiko PR' no chigai entorīshīto ga aru ni mo kakawarazu, mensetsu de jiko shōkai o jisshi suru riyū mensetsu de jiko shōkai ni yōsuru jikan no meyasu mensetsu no jiko shōkai ni kanarazu hitsuyōna jōhō mensetsu de yoku aru damena jiko shōkai no reibun mensetsu de tasha to sa o tsukeru, miryoku-tekina jiko shōkai no reibun mensetsu de umaku jiko shōkai o suru kotsu matome\n\n\n\n####################################################################\n部下を持ったことはありますか。\n  Hai, 2 persons wo motte imasu.\n\n\n\n・部下の指導において、重要であると考えることは何ですか。\n・翻訳業務には対応できますか。\n・通訳業務には対応できますか。\n\n・今後は、専門職としてのスキルを磨いてゆきたいですか。それとも、マネジメントを行ってみたいですか。\n\n・複数の部門との調整を行うにはどのような手段を使いますか。\n・自己啓発のために行っていることはありますか。\n・リスク管理のキャリアを築きたいと考えたのはどうしてですか。\n・ITのどのような言語を使用することができますか。\n\n・当社における大きなリスクは何であると考えますか。\n・事業保険、医療保険、死亡保険、年金保険のどの保険についても基礎的な商品知識はありますか。\n\n・リスクを可視化するにはどのような手法を使いますか。\n・リスクを表すにおいて、定量的リスク指標のなかで、一番重要であると思う指標は何ですか。\n\n・定性的リスクを経営陣に伝えるには、どのような手法を利用しますか。\n\n・苦手な業務は何ですか。\n\n\n\n\n\n—————————————————————————-----------------------------------------\n\n· Have you ever had a subordinate?\n· What do you think is important in guidance of subordinates?\n· Can you handle translation work?\n· Can you handle interpreting work?\n· Do you want to develop your professional skills in the future? Or would you like to do management?\n· What measures will you use to coordinate with multiple departments?\n· Do you have something to do for self-development?\n· Why did you want to build a career in risk management?\n· Which languages ​​like IT can you use?\n\n· What do you think is a major risk in our company?\n· Do you have any basic product knowledge about insurance such as business insurance, medical insurance, death insurance, annuity insurance?\n· What kind of method is used to visualize risk?\n• What are the most important indicators of quantitative risk indicators in representing risk?\n· What sort of method is used to convey qualitative risk to management?\n· What is a weak business?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Sir,\n\nAm working at Rakuten Tokyo .as Principal Data Science.\nHave some interest at Indeed by having a top notch engineering reputation \n(also a friend working there).\n\nMy specialties are :\n   Quantitative Finance (modelling and al., stats)\n   Japanese NLP.\n   Fintech \n   Search Ranking Algo / Recommender system.\n   User data analysis. \n   Can speakr Japanese fluently , 10 work years exp. (finance as quant \\, mainly)\n\nAm not looking actively but happy to discuss if one role may fit.\nMy github is \nhttps://github.com/arita37\n   \n\n\n\n\n############################################################################\n############################################################################\nHello, \n\nI am principal Data Scientist at Rakuten , \nworking on large data analysis (ML prediction, classification, ...) for Japanese\nretail.\n\nI have strong interest in Cogent Lab activity due to my background in Finance, and \ncurrent activity in Data Science.\n\nI believe my technical profile and deep knowledge of business (finance, retail) can match Cogent Lab activity.\n\nFor example of projects where I can contribute :\n   Japanese retail business (forecast, recommender system, search)\n   Asset Management : Low frequency\n\n\n\n\n\n\n\n\n",
			"file": "/D/Dropbox/_text/interview3.txt",
			"file_size": 8829,
			"file_write_time": 131925219376305946,
			"settings":
			{
				"buffer_size": 7593,
				"line_ending": "Windows"
			}
		},
		{
			"file": "/D/Dropbox/inter_prep.txt",
			"settings":
			{
				"buffer_size": 4546,
				"encoding": "UTF-8 with BOM",
				"line_ending": "Windows"
			}
		},
		{
			"contents": "\n\n\nA bit pretentious title but we can see few trends coming out in this area.\n\nCommoditization of AI is already in the pipelines, the cost lower and lower every day.\n\nWith the achievements of Deep Learning into image recognition, voice recognition,..., a clear trend is drawing. This is the automation of human basics senses : seeing, listening, speaking by ML type algorithms, mostly transforming raw input data into numerical data that can be processed by other ML algorithms.\n\nThe company which benefit the most are the ones who receive significant amount of raw data on a daily basis : Intermet companies.\n\nBy open sourcing their research and implementation, they sacrificed Intellectual Property to the development of ML itself...  They believe the cost of research is too high, open source is a way to do stimulus\nand they are protected by the scale of their own data.\n\nThus, TensorFlow, Pytorch was born from previous research based framework such as Torch and Theano.\n\n\n\nAnother field which is emerging is the generation process:  generate actual raw data (ie images) from ML internal representation. Recognition and Generation processes are dual processes since both rely on the internal ML representation (ie  P(X/y)  vs  P(y/X)  )\n\nThe true question is how can we represent complex raw data into a numerical form comprehensible by Machines. \nMore, how can the machine learn the representation through algorithmic processing\n\nCurrent answer is let's use the gradient in a probabilistic way (ie Stochastic Gradient Descent).\nThis is called the connectionnist, intuitionnist way.\n\n\n\nComputing resources needed for ML generation is much higher, \nso the field is accelerated by another trend : AI specialized hardware.\nFew examples :  Nervanna, Graphcore, TPU,..., all are developing specialized hardware to accelerate\nML type computations.\n\nThis is the key of ML development, how much efficient TeraFlops is available per algorithm.\nOn one hand, research makes the algorithms more efficient, less Teraflops to get convergence.\nOn other hand, hardware research makes the hardware compute more efficiently.\n\n\n\nIn the middle of research battle for better ML algorithms, lies the Natural Language Processing\nor now Understanding. Very active topic because having the way to process automatically\nall human language ressources allows Machine to learn by themselves...\nIt looks simple but take the example of DeePL company which is using 5 PetaFlops computer\nto train their translation models.\nhttps://en.wikipedia.org/wiki/DeepL_Translator\n\n\n\nMaybe the future of AI trends lies in one picture .\n\n\n\n\n\n\nThis picture shows what Human reasoning is doing from simple recognition\nto multi-steps planning.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n##################################################################################\n\n\n・部下を持ったことはありますか。\n・部下の指導において、重要であると考えることは何ですか。\n・翻訳業務には対応できますか。\n・通訳業務には対応できますか。\n・今後は、専門職としてのスキルを磨いてゆきたいですか。それとも、マネジメントを行ってみたいですか。\n\n\n・複数の部門との調整を行うにはどのような手段を使いますか。\n・自己啓発のために行っていることはありますか。\n・リスク管理のキャリアを築きたいと考えたのはどうしてですか。\n・ITのどのような言語を使用することができますか。\n\n・当社における大きなリスクは何であると考えますか。\n・事業保険、医療保険、死亡保険、年金保険のどの保険についても基礎的な商品知識はありますか。\n・リスクを可視化するにはどのような手法を使いますか。\n・リスクを表すにおいて、定量的リスク指標のなかで、一番重要であると思う指標は何ですか。\n・定性的リスクを経営陣に伝えるには、どのような手法を利用しますか。\n・苦手な業務は何ですか。\n\n\n\n\n—————————————————————————\n\n· Have you ever had a subordinate?\n· What do you think is important in guidance of subordinates?\n· Can you handle translation work?\n· Can you handle interpreting work?\n· Do you want to develop your professional skills in the future? Or would you like to do management?\n· What measures will you use to coordinate with multiple departments?\n· Do you have something to do for self-development?\n· Why did you want to build a career in risk management?\n· Which languages ​​like IT can you use?\n\n· What do you think is a major risk in our company?\n· Do you have any basic product knowledge about insurance such as business insurance, medical insurance, death insurance, annuity insurance?\n· What kind of method is used to visualize risk?\n• What are the most important indicators of quantitative risk indicators in representing risk?\n· What sort of method is used to convey qualitative risk to management?\n· What is a weak business?\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Sir,\n\nAm working at Rakuten Tokyo .as Principal Data Science.\nHave some interest at Indeed by having a top notch engineering reputation \n(also a friend working there).\n\nMy specialties are :\n   Quantitative Finance (modelling and al., stats)\n   Japanese NLP.\n   Fintech \n   Search Ranking Algo / Recommender system.\n   User data analysis. \n   Can speakr Japanese fluently , 10 work years exp. (finance as quant \\, mainly)\n\nAm not looking actively but happy to discuss if one role may fit.\nMy github is \nhttps://github.com/arita37\n   \n\n\n\n\n############################################################################\n############################################################################\nHello, \n\nI am principal Data Scientist at Rakuten , \nworking on large data analysis (ML prediction, classification, ...) for Japanese\nretail.\n\nI have strong interest in Cogent Lab activity due to my background in Finance, and \ncurrent activity in Data Science.\n\nI believe my technical profile and deep knowledge of business (finance, retail) can match Cogent Lab activity.\n\nFor example of projects where I can contribute :\n   Japanese retail business (forecast, recommender system, search)\n   Asset Management : Low frequency\n\n\n\n\n\n\n\n\n\n\n############################################################################\n############################################################################\n\n\nStackOVerflow :\nnoelkev0@gmail.com (used Sep 28)\n\n\n\npycharm\nmini conda\nevevrything\nprocess auto startu p microsfot\nsftp winscp\nMoba Xterm\nCon Emu Pack  Command Line\nAOMEIBackupper\nhttps://s3-us-west-2.amazonaws.com/github-raku/aomeisoBackupperFull.exe\n\n\n\n\n\n\n\n\n\n###########\n\nFTP \n52.26.181.200\nlogin : ubuntu\nuse oregon private key\n\nhttp://52.26.181.200:8888/tree#notebooks\naws\naccesss key\nAKIAIGDRLS6LA3ZTUIWA\n\n\nsecret\n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\n\npass\nmJMnzDKz}Xyw\n\n\n\n\n##################################################################################\nThank you for your order! (Order no. 57510669)\nYour purchased products\n\n1 x EmEditor \n\nregistration key:\nDVAZZ-285SF-WB3UQ-KBBP5-KNMNH\n\nPartition Master EaseUS\n\nXplorer 2\nEditPad Pro\nChrome, Firefox,  Save offline, Pera Pera\nFileLocator\nEverything\nTree size Professionnal\nAnaconda 2\nWinpython\nVisual Studio 2017\nAoemei Backupper\nhttps://cyberduck.io/    Google Drive / Amazon S3 computation, Best\nmoutainduck\nhttp://www.quickaccesspopup.com/\n    http://www.quickaccesspopup.com/how-do-i-enable-total-commander-support-in-quick-access-popup/\n\n[xplorer2 lite (v2.5.0.4)]\n; http://www.xyplorer.com/free.php\n; NOTE: enable \"Always open new tabs in a single window\" in Tools -> Advanced ->  Single Window Mode\n; source: Roland Toth\nAppPath=C:\\_app\\xplorer64\\xplorer2_lite.exe \nCommandLine=/M %Path%\nNewTabSwitch=\n\n\n\n\n\n#### Edipad Pro  ################################################################################################################\n    License name: Kevin Noel\n  Contact person:    Contact email: kevin.yakimono@gmail.com\n EditPad User ID: epp-318a173\n  Licensed users: 1\nDate of purchase: 2 April 2015\n\nYour license is valid for EditPad Pro versions 7.x.x on the Microsoft Windows platform.\n\nIf any of this information is incorrect, please contact sales@editpadpro.com at \n\nTo download the full version of EditPad Pro, please visit http://www.editpadpro.com/download.html where you will be asked for the contact email and user id mentioned above.  After providing those, your fully licensed copy of EditPad Pro will be generated instantly, ready for download.\n\nWhen a free minor upgrade is released, simply download the full version again as explained above, \nand install it on top of the version you already have. \n We will notify you of new versions via our monthly newsletter, to which you can subscribe at http://www.editpadpro.com/maillist.html \n\n\n\n############# Orders    #######################################################\nThank You For Your Order\nOrder ID: ZAB170222-2969-57119\nCharges will appear on your bill as: FS *xplorer2\nxplorer² professional\nJPY3,505\n\n\nYour registration key is:\n\n66|3.ZAB170222-2969-57119|X2.2|1|22.02.17|0|Kevin_Noel|noelkev0@gma\nil.com|W0uJyNM334/G+O7OaldeChI/zUYsT0lNqhgx3V9wymjdTuu+8Tr2LiTZtqjZ\nO0P4vVLzPCQw4cvwYrFKNU5e9uxs3Lolo2zI0gAPGbihpTNrlTggH5pkyx/glERREHz\ngB3cNvUB6BWI=\n\nYour registration reference# is: X2.2-7C47DC42\nPlease keep these details safe for future use!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n######   Equivalent \n/project27/ \n/project27/linux_project27\n\n\n###############################################################################################\n### Startup Loader      #######################################################################\n%load_ext autoreload\n%autoreload\nimport os, sys; CFG= {'plat': sys.platform[:3]+\"-\"+os.path.expanduser('~').split(\"\\\\\")[-1].split(\"/\")[-1], \"ver\": sys.version_info.major}\nDIRCWD= { 'win-asus1' : 'D:/_devs/Python01/project27/', 'win,unerry' : 'G:/_devs/project27/' , 'lin-noel': '/home/noel/project27/', 'lin-ubuntu': '/home/ubuntu/project27/' }[CFG['plat']]\nprint( CFG, DIRCWD, str(os)[13:])\nos.chdir(DIRCWD); sys.path.append(DIRCWD + '/aapackage' if CFG[\"ver\"] == 2  else  sys.path.append(DIRCWD + '/aapackage3')  ); # sys.path.append(DIRCWD + '/linux/aapackage')\nexec(compile(open(DIRCWD + '/aapackage/allmodule.py').read(), DIRCWD + '/aapackage/allmodule.py', 'exec'))   \n#      execfile( DIRCWD + '/aapackage/allmodule.py')\n\n\ndef execfile(filepath, globals=None, locals=None):\n    if globals is None:   globals = {}\n    globals.update({ \"__file__\": filepath,  \"__name__\": \"__main__\", })\n    with open(filepath, 'rb') as file:\n        exec(compile(file.read(), filepath, 'exec'), globals, locals)\n\n\n\n\n################################################################################################################\n###### Bash Command ############################################################################################\nNever Use  Slash /   at folder writing\nrm -rf mydir      remove all the directory without notice\nls    list current directory\npwd    current directory \ncp -r      /home/noel/anaconda2/pkgs/       /home/noel/\n\n\n####### Linux Screen attachment \nscreen -r 25555                  #### Attach session\nscreen -X -S   26655  quit       #### Kill session\nscreen       ### New session\nCtrl+A+D    ##Quit sesssion\n\n\n#### File Editing\nexport VISUAL=nano\n\ncrontab -e\n\ngrep bbiz   /var/log/syslog\n\n/home/noel/project27/scheduler/cmd_line/bbiz_run.sh\n\n\ntar -zcvf /home/noel/archive_vm_homenoel.tar.gz    /home/noel/   ####Compress Folder\n\n\nchmod +x bbiz_run.sh    #### W\nsudo ln -s /home/noel/project27/scheduler/cmd_line/bbiz_run.sh   /usr/local/bin/\n\n\nchmod +x /usr/local/bin/bbiz_run.sh \n\n\n### Backup Folder\nsudo tar -zcvf /home/noel/archive_vm_anaconda.tar.gz    /home/ubuntu/anaconda3\n\n\n\n\n\n\n\n\n\n\n##############################################################################################################\n######  AWS Oregon GPU #######################################################################################\nIP :    52.26.181.200\nSpot Instnance 54.69.65.45\n\nwhoami   :  ## user\nwhich python \nsu - ubuntu    #change to ubuntu\nsource activate sandbox\n\n\ndf command - Shows the amount of disk space used and available on Linux file systems.\ndu command - Display the amount of disk space used by the specified files and for each subdirectory.\nbtrfs fi df /device/ - Show disk space usage information for a btrfs based mount point/file system. Read more\n\n\nnetstat -tulpn \n#### Check if GPU is fine\n nvidia-smi \n\n\n\n#############################################################################################################\n##################### AWS SSH ###############################################################################\nOther Linux  :  No problem just the name of SSH\nubuntu@ExternalIPAdress\n\n\n###Convert Amazon PEM to Putty PPK\nhttps://linuxacademy.com/howtoguides/posts/show/topic/17385-use-putty-to-access-ec2-linux-instances-via-ssh-from-windows\n\n##### use PPK to connect\nD:\\_devs\\aws\\keypairs\\oregon\n\nputty -ssh    ubuntu@52.26.181.200  22\n\"putty.exe\" -load \"EC2_oregon\"\n\n\n\nCredentials File and Profiles\nInstead of keeping credentials in environment variables,\nyou can now put credentials into a single file that’s in a central location. The default location is this:\n\n~/.aws/credentials (Linux/Mac)\n%USERPROFILE%.awscredentials  (Windows)\n\n\n[default]\naws_access_key_id = ACCESS_KEY\naws_secret_access_key = SECRET_KEY\naws_session_token = TOKEN\nC:/Users/asus1/.aws/.awscredentials  \n\n\nThe AWS credentials file – located at ~/.aws/credentials on Linux, macOS, or Unix, or at C:\\Users\\USERNAME \\.aws\\credentials on Windows. This file can contain multiple named profiles in addition to a default profile.\n\n#Amazon keys\n# os.environ[\"AWS_ACCESS_KEY_ID\"] =     'AKIAJDE3GSLR5FCRIXIQ'\n# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = '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'\n\n\n\n############################################################################################################\n####Jupyter notebook  ######################################################################################\nnohup jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser &>> /home/ubuntu/project27/logfile_server.txt\n\n\n### CRONTAB -E\n@reboot sleep 5 &&  nohup  /home/ubuntu/anaconda3/bin/jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser  &>> /home/ubuntu/project27/logfile_jupyter_server.txt\n\nsu ubuntu -c \"/usr/bin/jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser  &>> /home/ubuntu/project27/logfile_server.txt\"\nsu <username> -c \"/usr/bin/ipython notebook --no-browser --profile <profilename> &\"\n\n\n@reboot sleep 5 && su ubuntu -c \"nohup  /home/ubuntu/anaconda3/bin/jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser  &>> /home/ubuntu/project27/logfile_jupyter_server.txt\"\n\n\n\n\nnetstat -tulpn   ###List of notebook running           \n\nkill pid  ###Kill\n\nhome/noel/project27/log_server.txt   ####Log \n\njupyter notebook password sophie237\n\n\n### to see the token and URL of jupyter notebook  ########################################################\njupyter notebook list\n\n\n####Kill Jupyter   #########\nnetstat -tulpn\n\n\n\n\n#############################################################################################################\n#### Conda Environnment    ##################################################################################\n\n#### NLP environnment  #############\nconda create --name tf_gpu_13\nconda install --yes -c conda-forge pip\n\nconda install --yes -c anaconda gensim \nhttps://pypi.python.org/pypi/fasttext\nconda install spacy\nhttps://github.com/facebookresearch\nhttps://github.com/facebookresearch/faiss\n\n\ngit clone https://github.com/facebookresearch/faiss.git    github/faiss\ncd github/faiss\n# Move the file makefile.inc  into main directory and\nsudo apt-get install libopenblas-base\n# change makefile.inc for main\n\n\nconda create --verbose --name python2   -f \"D:\\_devs\\Python01\\project27\\__config\\condaenv\\condaenv_win-asus1-7_python2_base.yml\" \n\n\nconda create --verbose --name python2  \n\n\n\n\n\n\n\n\n#### Batch Install\nconda install  -n tf_gpu_12  --no-deps --no-update-deps --verbose  --yes    regex   \n\npip install --upgrade --no-deps --force-reinstall <packagename>\n\ngit clone https://github.com/facebookresearch/faiss.git    linux_project27/mlearning/\n\n\n\nconda install --no-deps --no-update-deps --verbose  --yes   -n root   mkl=11.3.3=1\n\n\nconda uninstall --force --verbose  --yes -n root cffi=1.10.0=py27_0\n\n\nconda install --no-deps --no-update-deps --verbose  --yes   -n root   cffi=1.60.0=py27_0\n\n\n\nmini-conda\n  --->  gui_py2\n  --->  gui_py3\n  --->  python2\n  --->  python3\n\n\n\n\n\n\n\n#!/usr/bin/env bash\n\ncd ~\nwget http://repo.continuum.io/archive/Anaconda2-4.0.0-Linux-x86_64.sh\nbash Anaconda2-4.0.0-Linux-x86_64.sh -b\necho 'PATH=\"/home/ubuntu/anaconda2/bin:$PATH\"' >> .bashrc\n. .bashrc\n\njupyter notebook --generate-config\n\nkey=$(python -c \"from notebook.auth import passwd; print(passwd())\")\n\ncd ~\nmkdir certs\ncd certs\ncertdir=$(pwd)\nopenssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout mycert.key -out mycert.pem\n\ncd ~\nsed -i \"1 a\\\nc = get_config()\\\\\nc.NotebookApp.certfile = u'$certdir/mycert.pem'\\\\\nc.NotebookApp.keyfile = u'$certdir/mycert.key'\\\\\nc.NotebookApp.ip = '*'\\\\\nc.NotebookApp.open_browser = False\\\\\nc.NotebookApp.password = u'$key'\\\\\nc.NotebookApp.port = 8888\" .jupyter/jupyter_notebook_config.py\n\n\n\ntmux new -s nb\nmkdir notebook\ncd notebook\njupyter notebook\n\n\nAmazon EC2 automatically detects the public DNS name of your instance and then populates Public DNS for you. It also detects the name of the key pair that you specified when you launched the instance. Complete the following, and then choose Launch SSH Client.\n\nIn User name, enter the user name to log in to your instance.\n\nTip\nFor Amazon Linux, the user name is ec2-user. For RHEL5, the user name is either root or ec2-user. For Ubuntu, the user name is ubuntu. For Fedora, the user name is either fedora or ec2-user. For SUSE Linux, the user name is either root or ec2-user. Otherwise, if ec2-user and root don't work, check with your AMI provider.\nIn Private key path, enter the fully qualified path to your private key (.pem) file, including the key pair name; for example:\n\nC:\\KeyPairs\\my-key-pair.pem\n\n(Optional) Choose Store in browser cache to store the location of the private key in your browser cache. This enables Amazon EC2 to detect the location of the private key in subsequent browser sessions, until you clear your browser's cache.\n##########################################################################################################################\n#########################################################################################################################\n\n\n\n####Python  Environnemnt\n############################################################################################################\nDIRCWD set in Ubuntu :\n/root/.bashrc      No\n/etc/profile       No\n/etc/environment   Ok, works for Jupyter in crontab -e   HERE FOR CRONTAB -E Launch\n/home/ubuntu/.bashrc   Not works\n\n\n/root/.bash_history\n/home/ubuntu/.bash_history\n\n\n\n\nexport  CONFIGMY_ROOT_FILE=\"/home/ubuntu/project27/__config/CONFIGMY_ROOT_FILE.py\"\n\n\nLC_ALL=C fgrep -Irsl --exclude-dir={\\*ubuntu\\*}   'DIRCWD=' /\n\n\nDIRCWD=\"/home/ubuntu/project27/\"\nCONFIGMY_ROOT_FILE=\"/home/ubuntu/project27/__config/CONFIGMY_ROOT_FILE.py\"\n\nPATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\"\n\n\n\n\n\n\n\n\n\n###################################################################################################\nOriginal Answer\nYou should set it in /etc/environment.\n\nTry sudo YOUR_TEXT_EDITOR /etc/environment (make sure to create a backup first).\n\nFor more information: EnvironmentVariables\n\n\nSystem-wide environment variables\nEnvironment variable settings that affect the system as a whole (rather then just a particular user) \nshould not be placed in any of the many system-level scripts \nthat get executed when the system or the desktop session are loaded, but into\n\n\nsudo nano /etc/environment\n\n/etc/environment - \nThis file is specifically meant for system-wide environment variable settings. \nIt is not a script file, but rather consists of assignment expressions, one per line. \nSpecifically, this file stores the system-wide locale and path settings.\n\n\nNot recommended:\n/etc/profile - \nThis file gets executed whenever a bash login shell is entered (e.g. when logging in from the console or over ssh), as well as by the DisplayManager when the desktop session loads. This is probably the file you will get referred to when asking veteran UNIX system administrators about environment variables. In Ubuntu, however, this file does little more then invoke the /etc/bash.bashrc file.\n\n/etc/bash.bashrc - This is the system-wide version of the ~/.bashrc file. \nUbuntu is configured by default to execute this file whenever a user enters a shell or the desktop environment.\n\n\n./bashrc  only for local user\n\n\n\n\n\n\n\n\n\n#### Python 2.7\nhttp://conda-test.pydata.org/docs/faq.html\n\nconda create -n python2 python=2.7 anaconda           source activate python2\nconda create --name sandbox_py2  --clone python2      source activate py2_sandbox\n\nconda create --name automl  --clone root\n\n\nconda create --name  tf_gpu_13\n\n\n\n##Python 3.6\nconda create --name tf_gpu_12  --clone root       source activate tf_cpu_12\nconda create --name tf_cpu_12  --clone root       source activate tf_gpu_12  # GPU TensorFlow\n   \nconda create --name sandbox  --clone root         source activate sandbox    \n#  Can install anything, only for sandbox install of critical \n\nconda install -c conda-forge pip\n\n\n\n#############Package  ######################################################################################\n#### Installed witout updating dependencies.\n####### CONDA :   ##################################\nhttps://conda.io/docs/troubleshooting.html#fix-broken-conda\n\n\n\n####Build Same CONDA from File:\nhttps://conda.io/docs/user-guide/tasks/manage-environments.html#building-identical-conda-environments\n\nconda list --explicit > spec-file.txt     #Export current environnment\n\nconda create --name myenv --file spec-file.txt     # Create Env using a file\n\n\n\n####### Packages    #########################################################################################\nconda config --add channels conda-forge\nconda install -c  conda-forge   pygmo      --no-update-dependencies \n\nconda install -c conda-forge qt==5.6.2\nconda install -c conda-forge partd==0.3.8\n\n\n##### Forecast model\nconda install -c conda-forge pystan=2.15.0.1\n\n\n####only linux for python 2.7\nconda install -c conda-forge fbprophet=0.1.1  ####only linux for python 2.7\n\n\nManaging conda and anaconda        ########################################################################\n\nconda info                Verify conda is installed, check version #\nconda update conda        Update conda package and environment manager to current version\nconda update anaconda     Update the anaconda meta package (the library of packages ready to install with conda command)\n\n\nManaging packages, including Python ########################################################################\n\nconda list   View list of packages and versions installed in active environment\nconda search beautiful-soup Search for a package to see if it is available to\nconda install       conda install -n bunnies beautiful-so up Install a new package\n\n\nconda install -c pandas bottleneck Install a package from a specific channel \n\n\nRemove packages, environments, or channels\nconda remove --name bunnies beautifulsoup  Remove one package from any named  environment\nconda remove beautiful-soup                Remove one package from the active environment\nconda remove --name bunnies beautiful- soup astroid          Remove multiple packages from any environment\nconda remove --name snakes --all                             Remove an environment\n\n\n###### EC2 Linux Python Package Install  ##########################################################\nPYGMO       conda install -c willemolding pygmo=1.1.6\nDEAP        conda install -c mq deap=1.1.0\nCelery task   conda install -c conda-forge celery=3.1.23\nconda install -c conda-forge ipyparallel=5.2.0\n\nconda install -c conda-forge tpot=0.6.4\nconda install -c conda-forge urllib3=1.18.1\nconda install -c conda-forge tabulate=0.7.7 \n\nconda install -c anaconda bcolz=1.0.0\nconda install -c anaconda scikit-learn=0.18.1\n\n\npip install catboost  : #category analyzer for classification\n\n\n\n\n#Error in IPython Network Need to install QT4 on Command Line\nsudo apt-get install -y python-qt4\n\n\n\n####Tensor Layer  ########################################################################\npip install git+https://github.com/zsdonghao/tensorlayer.git     --no-dependencies\n\n\nHowever, if you want to modify or extend TensorLayer, \nyou can download the repository from Github and install it as follow.\ngit clone --depth=50 --branch=master https://github.com/rhiever/tpot.git   github/rhiever/tpot\ncd to the root of the git tree\npip install -e .\n\nThis command will run the setup.py to install TensorLayer. \nThe -e reflects editable, then you can edit the source code in tensorlayer folder, \nand import the edited TensorLayer.\n\n\n\n##### Install from git\ngit clone --depth=50 --branch=master https://github.com/rhiever/tpot.git   github/rhiever/tpot\ncd github/tpot\npip install -e .\n\n\n\n##### Install from Travis  Clean #########################################################\nconda create --name myenv --file spec-file.txt   python=2.7 anaconda     \n\n\nTravis Build Files extract the pip \n\n\n\n####\ngit clone https://github.com/facebookresearch/fastText.git     github/fastext\n$ git clone https://github.com/facebookresearch/fastText.git\n$ cd github/fastext\n$ make\n\n\n\npip install tpot  --no-dependencies\n\n\n\n\n#### Jupyter Notebook Cache\nhttps://github.com/rossant/ipycache\n\n\n\n\n\n\n##### Fast Text : Gen Sim   ##############################################################\nFast Text PyFast Text\nhttps://github.com/vrasneur/pyfasttext/tree/master/test\n\n\n\n\n\n$ cat test.ini\n[First Section]\nvar = value\nkey = item\n\n[Second Section]\nothervar = othervalue\notherkey = otheritem\nAnd then:\n\nfrom ConfigParser import ConfigParser\nconfig = ConfigParser().read('test.ini'); CFG_ = {s:dict(config.items(s)) for s in config.sections()}\n\nd = {line.strip().split(' = ') for line in file(filename)}\nd = {line.strip().split(' = ') for line in open(\"config.txt\", mode='r')}\n\n\n\n#### System Variables == os.environ  Windows\nsetx DIRCWD \"D:/_devs/Python01/project27/\"   /M\nECHO  %DIRCWD%\n\n\n#### System Variables == os.environ  Ubuntu\nnano $HOME/.bashrc              #  \nsource $HOME/.bashrc            #  Reload file\n#python dircwd path\nexport DIRCWD=/home/ubuntu/project27/\n\n\nnano   ./.bashrc\nsource ./.bashrc                           #  Reload file\nexport DIRCWD=/home/ubuntu/project27/\n\n\nnano /etc/profile                   #  Reload file\nsource /etc/profile  \nexport DIRCWD=/home/ubuntu/project27/\n\n\n\nhttps://www.dabapps.com/blog/python-tools-local-continuous-integration/\n\n\n\n\n\n\n#####TPOT  ####################################################################################\ngit clone --depth=50 --branch=master https://github.com/zsdonghao/tensorlayer.git   project27/github\ncd project27/github\n\nnumpy 1.12.1\nscipy 0.19.1\nsklearn 0.18.2\ndeap==1.0\n\n\n76.67s$ source ./ci/.travis_install.sh\n39.25s$ bash ./ci/.travis_test.sh\n\nxgboost 0.6 \nupdate_checker 0.16 \ntqdm 4.14.0\n\n\n\n\n###############################################################################################\n### ML Box : Auto ML  #########################################################################\nconda install -c conda-forge xgboost    --no-dependencies\n\npip install mlbox --no-dependencies\n\n\n\n\n### Auto SK Learn   ###########################################################################\nInstall into conda using Travis YAML file and execute it.\n\n\nsource activate autosklearn\ncd /home/ubuntu/automl/autosklearn\npython   run_test.py\n\n\n\n\n\n#####################################################################################################################\ngit clone git://github.com/SpringSource/spring-data-graph-examples.git\n\ngit clone --depth=5 --branch=master https://github.com/automl/auto-sklearn.git automl/auto-sklearn\n\n\nconda install --yes gcc swig\nconda install --yes libgcc\nsudo apt-get install build-essential swig\nsudo apt-get install build-essential gcc\n\ncurl https://cdn.rawgit.com/automl/auto-sklearn/7d33420a644dd3b1e0db26664d01d856a7ca5fb2/requirements.txt   | xargs -n 1 -L 1 pip install \npip install xmltodict requests\npip install git+https://github.com/renatopp/liac-arff\npip install git+https://github.com/openml/openml-python@0b9009b0436fda77d9f7c701bd116aff4158d5e1 --no-deps\npip install auto-sklearn   --no-dependencies\n\nhttps://travis-ci.org/automl/auto-sklearn/jobs/241098164/config\n\n\npip install smac                              #Build with gcc\n\npip uninstall pyrfr \npip uninstall auto-sklearn\nCC=/home/ubuntu/anaconda3/envs/sandbox/bin/gcc pip install pyrfr auto-sklearn --no-cache-dir   --no-dependencies\n\n\nhttps://github.com/automl/auto-sklearn/issues/308\n\n\n\npip install auto-sklearn   --no-dependencies\ncurl https://rawgit.com/automl/auto-sklearn/v.0.2.0/requirements.txt | xargs -n 1 -L 1 pip install\n\nCC=/home/ubuntu/anaconda3/envs/sandbox/bin/gcc pip install pyrfr auto-sklearn   --no-cache-dir   --no-dependencies\n\n\n\n### Force installed\ncurl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install --no-cache-dir --force-reinstall -I --no-deps --upgrade\n\n\npip install autosklearn --no-cache-dir --force-reinstall -I --no-deps --upgrade\n\npip install pyrfr==0.4.0\n\n\n\n\n#####################################################################################################################\nAuto-Sklearn returns an ensemble of models.\nYou can use automl.show_models() to look at the ensemble.\nIn general, I recommend to read the paper on auto-sklearn to get an understanding what it does:\nEfficient and Robust Automated Machine Learning at NIPS'15\n\n\nimport autosklearn.classification ; import sklearn.cross_validation\nimport sklearn.datasets           ; import sklearn.metrics\ndigits = sklearn.datasets.load_digits()\nX = digits.data  ;     y = digits.target\nX_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X,y,random_state=1)\nautoml = autosklearn.classification.AutoSklearnClassifier()\nautoml.fit(X_train, y_train)\ny_hat = automl.predict(X_test)\nprint(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_hat))\n#####################################################################################################################\n\n\n\n\n\nhttps://automl.github.io/auto-sklearn/stable/installation.html\nconda install -c conda-forge  lockfile\nconda install -c conda-forge  six\npip install  scikit-learn==0.18.1\n\n\n#####SMAC install  : Bayesian OPtimization  #################\nhttps://automl.github.io/SMAC3/stable/manual.html\n\n\n\n\n\n\n\n######Tensor Layer in Editable mode   ##################################################################################\npip install -e /path/to/package --no-use-wheel\n\n\nEditable Mode\nDownload the TensorLayer folder from Github.\nBefore editing the TensorLayer .py file.\nIf your script and TensorLayer folder are in the same folder, when you edit the .py inside TensorLayer folder, your script can access the new features.\nIf your script and TensorLayer folder are not in the same folder, you need to run the following command in the folder contains setup.py before you edit .py inside TensorLayer folder.\npip install -e .\n\n\n\n\n\n#### Create Temp environnment for dependencies management  #####################################\nconda install conda-execute --channel=conda-forge\n\nhttp://www.zib.de/miltenberger/ICMS_2016_PySCIPOpt.slides.html#/5\n\n\n\n####### Regression test\nsource activate sandbox\npython   /home/ubuntu/project27/ztest/test_regression_py2.py --title kevin\n\n\n\n#### conda environnment  ######################################################################\nconda info --envs  \n   root   *  /home/noel/anaconda2\n\n\n#Clone previous envs\nconda create --name tensorflow2  --clone root\n\n\n#### Activate\n source activate tensorflow2\n source deactivate tensorflow\n source activate root\n\n\n####   BUGGY be careful\nconda list --revisions\nconda install --revision   63    ###Roll Back\n\n\n\n#### Remove\nsource activate root\nconda remove --prefix tensorflow  --all\nrm -rf /home/noel/anaconda2/envs/tensorflow\n\n\nIf issues delete MANUALLY in anaconda/Pkgs\n\n\n\n\n\n\n\n####################################################################################################\n#### TensorFlow Install  ###########################################################################\nconda info --envs     #  root   *  /home/noel/anaconda2\n\nconda create --name tf_gp13  --clone tf_gp12\n\n#Clone previous envs\nconda create --name tensorflow2  --clone root\n\n\n#### Activate\nsource activate tensorflow2\nsource deactivate tensorflow\n\n\n#### \nconda list --revisions\nconda install --revision   63    ###Roll Back\n\n\n\n#### Remove\nsource activate root\nconda remove --prefix tensorflow  --all\nrm -rf /home/noel/anaconda2/envs/tensorflow\n\n\nIf issues delete MANUALLY in anaconda/Pkgs\n\n\n######  TensorFlow \nactivate tensorflow\n\n\n### Grid LSTM\nconda install  -c jjhelmus tensorflow-gpu=1.0.1\n\nconda install  --force  -c jjhelmus tensorflow-gpu=1.0.1\nconda install --force\n\n### Install from google Binaries  BIG ISSUES\n###=  Issues with PIP Never installed\n###  pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl\n\n\n#### Disable CUDA  ######################################################################\nCUDA_VISIBLE_DEVICES=\"\"\n\n\n\n#############Tensor   Flow   ############################################################\nCPU Optimized : default one\nGPU Optimized:   source activate tf_gpu_12\nCPU Optimized:  tf_cpu_12\nsource activate tf_gpu_12\n\n\n#### Install specific version of GPU  BUILD ##############################################\nconda install -c jjh_cio_testing   tensorflow-gpu=1.2.1=py36cuda8.0cudnn5.1_0\n\n\n##### Test Code \nimport tensorflow as tf; print(tf); hello = tf.constant('Hello, TensorFlow!');  sess = tf.Session();  print(sess.run(hello))\n\n\n\n########### via PIP specific version #####################################################\n### pip DOES NOT work always use conda\n## pip install tensorflow-gpu==1.3.0\nconda create --name tf_gpu_13\nconda install --yes -c conda-forge pip\nconda install --yes -c conda-forge tensorflow==1.3.0\n\n\n\n\n\n\n\n######## Deep Learning training  #########################################################\npython   /home/noel/jupyter/project/grid_lstm/train.py  --model  gridlstm  --save_dir  /home/noel/jupyter/project/grid_lstm/save_gridlstm\n\npython   /home/noel/jupyter/project/grid_lstm/train.py  --num_epochs 70   --num_layers 4   --model  gridlstm  --save_dir  /home/noel/jupyter/project/grid_lstm/save_gridlstm_4\n\npython   /home/noel/jupyter/project/grid_lstm/train.py  --num_epochs 70   --num_layers 4   --model  lstm  --save_dir  /home/noel/jupyter/project/grid_lstm/save_lstm_4\n\npython   /home/noel/jupyter/project/grid_lstm/train.py  --num_epochs 1   --num_layers 1   --model  gridlstm  --save_dir  /home/noel/jupyter/project/grid_lstm/save_gridlstm_4\n\n\n\nNamespace(batch_size=50, data_dir='/home/noel/jupyter/project/grid_lstm/data/tinyshakespeare/', decay_rate=0.97, grad_clip=5.0, learning_rate=0.002\n, model='gridlstm', num_epochs=50, num_layers=2, rnn_size=128, save_dir='/home/noel/jupyter/project/grid_lstm/save_gridlstm', save_every=1000, seq_\nlength=50)\n\n##########################################################################################\n\n\n\n\n\n\n\n\n##########################################################################################\n########  TensorFlow with Cuda packages ##################################################\n\n# This is shorthened version of blog post \n#  http://ksopyla.com/2017/02/tensorflow-gpu-virtualenv-python3/\n\n# update packages\nsudo apt-get update\nsudo apt-get upgrade\n\n#Add the ppa repo for NVIDIA graphics driver\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\n\n#Install the recommended driver (currently nvidia-378)\nsudo ubuntu-drivers autoinstall\nsudo reboot\n\n#check if drivers were installed\nnvidia-smi\n\n################ Instal CUDA Toolkit 8.0 for x64 Ubuntu 16.04 \nwget -O cuda_8_linux.run https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda_8.0.61_375.26_linux-run\nsudo chmod +x cuda_8_linux.run\n./cuda_8.0.61_375.26_linux.run\n\n./cuda_8_linux.run\n\n\n#Do you accept the previously read EULA?\n#accept\n#Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 367.48?\n#n (we installed drivers previously)\n#Install the CUDA 8.0 Toolkit?\n#y\n#Enter Toolkit Location:\n#/usr/local/cuda-8.0 (enter)\n#Do you wish to run the installation with ‚sudo’?\n#y\n#Do you want to install a symbolic link at /usr/local/cuda?\n#y \n#Install the CUDA 8.0 Samples?\n#y \n#Enter CUDA Samples Location:\n#enter \n\n# Install cuDNN\n# go to website and download cudnn-8 https://developer.nvidia.com/cudnn\ntar -zxvf cudnn-8.0-linux-x64-v5.1.tgz \n\n# copy libs to /usr/local/cuda folder\nsudo cp -P cuda/include/cudnn.h /usr/local/cuda/include\nsudo cp -P cuda/lib64/libcudnn* /usr/local/cuda/lib64\nsudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*\n\n# isntall python 3 and virtual env\nsudo apt install python3-pip\nsudo apt install python3-venv\n\n# create virtual environment for tensorflow\npython3 -m venv tfenv\nsource tfenv/bin/activate\n\n# Instal tensorflow package with gpu support\n(tfenv)$ pip install tensorflow-gpu\n\n\n#or CPU version\n(tfenv)$ pip install tensorflow\n\n\n# check installation, run simple python scipt from console\n$ python\n\nimport tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally\ntf_session = tf.Session()\nx = tf.constant(1)\ny = tf.constant(1)\nprint(tf_session.run(x + y))\n\n\n\nfacundoq commented 4 days ago\nI think you should add that CUDA_HOME should be set and LD_LIBRARY_PATH modified for TF to find the libraries.\n\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\"\nexport CUDA_HOME=/usr/local/cuda\nYou can add those lines to ~/.bashrc so that they are executed each time you open as shell.\n\n\n##### parition\nsudo pvcreate /dev/sda3  # to make the partition available for LVM\n\n\nhttp://downloads.sourceforge.net/gparted/gparted-live-0.29.0-1-amd64.iso\n\n\n\n\n\n\n#### Anaconda Python 2 and Python 3 version #####################################################################################\nI also despise the virtual environment switch that Anaconda tries to force on us.\n I prefer to have both executables always instantly available from the command line. \nI'm pretty sure I had this working on a Windows machine once:\n\nInstall Anaconda2 and Anaconda3 to the C:\\ drive as \"C:\\Anaconda2\\\" and \"C:\\Anaconda3\\\" respectively.\nEdit your \"Path\" environment variable (Control Panel -> System and Security -> System -> Advanced system settings -\n> Environment Variables) and make sure that \"C:\\Anaconda2;C:\\Anaconda2\\Scripts;C:\\Anaconda2\\Library\\bin\" is in front of \"C:\\Anaconda3;C:\\Anaconda3\\Scripts;C:\\Anaconda3\\Library\\bin\".\nCopy and rename the file \"C:\\Anaconda3\\python.exe\" to \"C:\\Anaconda3\\python3.exe\".\nCopy and rename the file \"C:\\Anaconda3\\Scripts\\conda.exe\" to \"C:\\Anaconda3\\Scripts\\conda3.exe\"\nCopy and rename any other scripts you might use in \"C:\\Anaconda3\\Scripts\\\", such as \"pip.exe\" to \"pip3.exe\", etc.\nNow, when you type \"python\" or \"conda\" at the command line you will get the python2 version, and when you type \"python3\" or \"conda3\", etc. at the command line you will get the python3 version.\n\n\n##############  Python 2 and 3 compatibility\nhttp://python-future.org/compatible_idioms.html\n\n\n\n\n\n#################################################################################################\n####Spyder SSH     ##############################################################################\n## Type   %connect_info   in Jupyter to get the SSH\n{\n  \"stdin_port\": 39893, \n  \"ip\": \"127.0.0.1\", \n  \"control_port\": 58886, \n  \"hb_port\": 56808, \n  \"signature_scheme\": \"hmac-sha256\", \n  \"key\": \"d4aff2c9-ae8e-484a-a133-285f3961b53f\", \n  \"kernel_name\": \"\", \n  \"shell_port\": 38804, \n  \"transport\": \"tcp\", \n  \"iopub_port\": 37865\n}\n\n\n\n#####################################################################################################\nAmazon Costs\nEC2-Other :  0.15 USD / Day  due to SnapShot Maintaining cost\n    0.05 per GB-month of data stored   12Go :  0.80 USD / Month\n\n    EC2 - EBS Snapshot (Cost for storage of snapshots)\n    EC2 ? CloudWatch (cost for detailed monitoring, custom-metrics, and API access over the free tier (1M requests)).\n    EC2 - Elastic IP - Idle IPs, Additional IPs, IP Remaps.\n\n\n\n\n#####################################################################################################\n####VMare, local linux virtual machine  #############################################################\n3 interpreters\n\n/usr/bin/python3.5\n\n/home/noel/anaconda27/bin\n\npass: sophie237\n\ndeeplearning\ndeeplearning\n\n\nLXDE\n Ctl+Alt+F1 and login as root to access Shell at login\n\n\nsophie37\n\n\n\n########Local Virtual Machine VMaware ###################################################################\n####  Resize VM ware partition to bigger size.  #########################################################\nand download gparted iso file\n\nchange .vmx file to add\n\nF2 at start of VM\nchange start to CD ROM\n\n\nin Gparted\ndelete SWAP linux partition\nMerge of the partition\nRecreate\nSwap linux parition at end\n\nRestart\n\n\nUsing Gparted from a Live CD:\n\nSelect the swap partition\nIn the Partition menu, click on \"swapoff\"\nDelete the swap partition\nRecreate swap at the end of Unallocated (faster than moving it)\n\nOptional: Turn swap back on\nResize sda5 as desired\n\n\n### Virutal box\nsophie237\n\n\n###############################################################################################\n###############################################################################################\n\n\n\n\n\n\n\n\n\n###############################################################################################\n######   Spyder Shorcut\nG:\\_devs\\Python01\\Anaconda27\\pythonw.exe \"D:/_devs/Python01/project27/zspyder_session/spyder_launch.py\"    \"D:\\_devs\\project27\\unerry_devs.session.tar\"\n\nD:\\_devs\\project27\\\n\n\n####### Linux Screen attachment #################################################################\nscreen -r 25555                  #### Attach session\n\nscreen -X -S   26655  quit       #### Kill session\n\nscreen       ### New session\n\nCtrl+A+D    ##Quite sesssion\n\n\n\n#### File Editing\nexport VISUAL=nano\n\ncrontab -e\n\ngrep bbiz   /var/log/syslog\n\n\n\n/home/noel/project27/scheduler/cmd_line/bbiz_run.sh\n\n\n\n\ntar -zcvf /home/noel/archive_vm_homenoel.tar.gz    /home/noel/\n\n\n\nchmod +x bbiz_run.sh \nsudo ln -s /home/noel/project27/scheduler/cmd_line/bbiz_run.sh   /usr/local/bin/\n\n\n\nchmod +x /usr/local/bin/bbiz_run.sh \n\n\n\n#### Kuraya Message    ##################################################################################################\n#########################################################################################################################\n\n1) Change Under noel User\n\n\n2) To start server :\n\nsudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   runserver 0.0.0.0:80    &>> /home/noel/project27/log/logfile_bbiz_server.txt\n\n\nsudo -E  /home/noel/bbiz_server_run\n\n\n\n\n3) To re-start server:\n   Restart the VM\n\n\n\n\npyminifier -o   \"D:\\_devs\\google_cloud\\home\\noel\\project27\\geoapp\\geoproject\\django_app\\view_mini.py\"   --obfuscate    \"D:/_devs/google_cloud/home/noel/project27/geoapp/geoproject/django_app/view.py\" \n\n\n\n\nsudo -E /home/noel/anaconda2/bin/python　-OO -m py_compile  /home/noel/project27/scheduler/bbiz_batch_check.py 　　\n\n\n\n\n\nsudo -E /home/noel/anaconda2/bin/python　 -m compileall  -l  /home/noel/project27/scheduler/bbiz_batch_check.py 　\n\n\n\n5) 後で\nsudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_check.pyc --action status\n\ncheck_bbiz_batch.txt  をおねがいします。\n\n\n\n\n\n\n#####################################################################################################################################\nこのアクシオンをおねがいします\n\n1) Check File を入れて\n　　　/home/noel/project27/scheduler/\n\n\n2) Run\nsudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_check.pyc --action reset_all_cache_becareful\n\nsudo -E  /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_bquery.py\n\n\n3)  Server VM restart\n\n\n4) 後で\nsudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_check.pyc --action status\n\n/home/noel/project27/scheduler/check_bbiz_batch.txt  をおねがいします。\n\n\n\n\nsudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_check.pyc --action restore_1day\n\n\n\nsudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_check.pyc --action backup\n\n\n\n\n\n\n\n\n#########################################################################################################   \n####Launch Batch      ###################################################################################\n###Test if the batch is working:\nsudo  /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_bquery.py   --exit  25  &>> /home/noel/project27/scheduler/logfile_bbiz_batch.txt\n\n\n\n##### Crontab Batch\ncrontab -e\n\n0 16 * * * sudo  /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_bquery.py --project_id \"test-beaconbank-biz\"   &>> /home/noel/project27/scheduler/logfile_bbiz_batch.txt\n\n\n\"test-beaconbank-biz\"\n\n\nsudo -E /home/noel/biz_server/server/python  /home/noel/biz_server/launch/manage.py   runserver 0.0.0.0:80  \n\n\n\n\nln -s /home/noel/anaconda2/bin   \n\nln -s /home/noel/project27/geoapp/geoproject  /home/noel/biz_server/project/project27\n\nln -s  /home/noel/project27/data/count_table/    /home/noel/biz_server/data\n\nln -s  /home/noel/project27/    /home/noel/biz_server/details\n\n\n\nsudo -E  /home/noel/bbiz_server_run\n\ndos2unix /home/noel/bbiz_server_run\n\n\n#########################################################################################################################\n##### Prod Server\n  timestamp server\n  whitenoise is activated ---> Static Files must be updated by collectstatic\n\n\n1)  Modify the HTML and .js script files\n    fusioncharts   --->  kevinisthebest\n\n\n2)   Move files to whitenoise folder\n         sudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   collectstatic\n\n\n\n####Launch Batch      ##################################################################################################\n###Test if the batch is working:\nsudo  /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_bquery.py  --project_id \"test-beaconbank-biz\" --exit  25\n\n\ncrontab -e\n\n0 16 * * * sudo  /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_bquery.py --project_id \"test-beaconbank-biz\"   &>> /home/noel/project27/scheduler/logfile_bbiz_batch.txt\n\n\n\n###  Test Pages\nCV page with empty values  and no empy values\n\nCV\nhttps://t-biz.beaconbank.jp/apps/2170005/beacon_groups/5370001?duration=last_365days\n\nConversion page \n\n\n\n####Launch Batch      ########################################################################\n\n###Test if the batch is working:\nsudo  /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_bquery.py  --project_id \"test-beaconbank-biz\" --exit  25\n\n\ncrontab -e\n\n0 16 * * * sudo  /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_bquery.py --project_id \"test-beaconbank-biz\"   &>> /home/noel/project27/scheduler/logfile_bbiz_batch.txt\n\n\n###########################################################################################################\n\n\n\n\n\n#### DEBUG Mode\n DJANGo_DEBUG=1 sudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   runserver 0.0.0.0:8089\n\n### No Debug Mode\n sudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   runserver 0.0.0.0:8000\n\n\n\n###### Launch BBiz Server\n###  COMPRESS=5 activate  JS Compression\n screen \n COMPRESS=5  sudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   runserver 0.0.0.0:80    &>> /home/noel/project27/log/logfile_bbiz_server.txt\n\n\n##### Check Email\nsudo tail -f /var/mail/noel\n\n\n\n\nhttp://104.198.117.174:8889/notebooks/jupyter/Untitled.ipynb?kernel_name=python2#\n\n\n\n\n##################Batch Crontab ######################################################################\n#####################\nhttp://blog.appliedinformaticsinc.com/managing-cron-jobs-with-python-crontab/\n!!!!!  Crontab uses root login to access : Python Folder will be changed\n\n\n##### Setup in Server with Command Line\nipython\n\nfrom crontab import CronTab; cron = CronTab('noel');\njob  = cron.new(command='sudo  /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_bquery.py   &>> /home/noel/project27/scheduler/logfile_bbiz_batch.txt', comment='bbiz_01')\njob.hour.on(15);  job.enable()\ncron.write()\n\nfor job in cron: print job\n\n\n#### Check Crontab Log \ngrep python /var/log/syslog\n\n\n###  Remove specific cron job(s)\nOpen the cron file and delete the cron(s) that you want to remove\ncrontab -e\neach line represent a cron job. You can remove any cron by using ctrl+k then save and exit\nshift + Z : save exit\n\n\n\n\n\n\n###################################################################################################################\n######## Command For Django Management ############################################################################\nsudo /home/noel/anaconda2/bin/python     /home/noel/project27/scheduler/cmd_line/django_service.py  restart\n\n\n\nto run django application go to folder cmd_line and write sudo ./bash_cmd/django_run.sh\n\n\n##Launch Django\nsudo /home/noel/project27/scheduler/cmd_line/django_run.sh\n\n\n\nsudo /home/noel/anaconda2/bin/python   /home/noel/project27/scheduler/cmd_line/django_service.py restart\n\nsudo /home/noel/anaconda2/bin/python   /home/noel/project27/scheduler/cmd_line/django_service.py stop\n\n\n\n\n\n#### Bash  move script  to /usr/bin    #################################################################\nsudo cp /home/noel/project27/scheduler/cmd_line/bash_cmd/*        /usr/bin/\n\n\n\nsudo  /home/noel/anaconda2/bin/python  /home/noel/project27/scheduler/bbiz_batch_bquery.py   &>> /home/noel/project27/scheduler/logfile_bbiz_batch.txt\n\n\n\n\n##### Crontab -e : working in Jupytere\n0 15 * * * sudo /home/noel/anaconda2/bin/python /home/noel/project27/scheduler/bbiz_batch_bquery.py   &>> /home/noel/project27/scheduler/logfile_bbiz_batch.txt # bbiz_01\n\n0 4 * * * sudo /home/noel/anaconda2/bin/python /home/noel/project27/scheduler/cmd_line/django_service.py restart # restart-django-service\n0 5 * * * sudo /home/noel/anaconda2/bin/python /home/noel/project27/scheduler/cmd_line/django_check.py check # check-django-service\n\n\n\n\n### Scehduler\nfor d in cron.log: print d[‘pid’] + ” – ” + d[‘date’]\n\n\nfor job in cron: cron.remove( job )\n\n\nhttps://stackoverflow.com/questions/26835235/google-cloud-compute-vm-instances\n\n\n\n#####Job Scheduler\nhttp://blog.appliedinformaticsinc.com/managing-cron-jobs-with-python-crontab/\n\n\n\n\n####### Copy VM : Don't forget to open put the \nbiz-analytics\nhttp-server, http-servers, https-server\n104.198.94.24 \nSSH\n\n\n\n\n##### Identification:\n'LOGNAME': 'noel', 'USER', 'linux2'   \n\nPCLOC=  'win,asus1'  if os.path.expanduser('~').find('asus1') >-1  and sys.platform.find('lin')>-1 else  'win,unerry' if sys.platform.find('win')> -1 else  'lin,gcloud' if os.environ['HOME'].find('noel')>-1  else 'lin, virtualbox'\nDIRCWD= if PCLOC=='win,asus' else   'G:/_devs/project27/' if PCLOC=='win,unerry'  else  '/home/noel/' if PCLOC=='lin,gcloud' else '/media/sf_projec27'\n\n\nHOME= 'D:/_devs/Python01/project27/'  if os.path.expanduser('~').find('asus1') >-1  and sys.platform.find('win')>-1 else  'G:/_devs/google_cloud/home/noel/project27/' if sys.platform.find('win')> -1 else  '/home/noel/project27/' if os.environ['HOME'].find('noel')>-1  else '/media/sf_projec27'\n\n\n\n\n\n###################################################################################################\n######  Cloud SQL #################################################################################\nhttps://cloud.google.com/sql/docs/mysql/connect-admin-proxy\n\n# At first, type the following command to run cloud_sql_proxy on background.\n# ./cloud_sql_proxy -instances=test-beaconbank-biz:asia-northeast1:biz-db01=tcp:3306 &\n\n# And, you can connect to SQL Server with the following.\n# mysql -u bizbb -p --host 127.0.0.1\n\n# project=413736133783 \n\n\n####### Install in Linux Proxy :   ##############################################################\nsudo wget https://dl.google.com/cloudsql/cloud_sql_proxy.linux.amd64\nsudo mv cloud_sql_proxy.linux.amd64 cloud_sql_proxy\nsudo chmod +x cloud_sql_proxy\n\n#In bash Command line\nsudo ./cloud_sql_proxy -instances=test-beaconbank-biz:asia-northeast1:biz-db01=tcp:3306 &\n\nmysql -u bizbb -p KPhgZtW7sUpX --host 127.0.0.1\n\n\nlogin/password\n\n\n\n\n##### USage in Windows platform    ############################################################\n0) https://cloud.google.com/sql/docs/mysql/connect-admin-proxy\n\n1) Download Win Client: https://dl.google.com/cloudsql/cloud_sql_proxy_x64.exe a\n\n2) cd G:\\_devs\\google_cloud\\_cloud_sql\\cloud_sql_proxy_x64.exe\n   cloud_sql_proxy_x64 -instances=test-beaconbank-biz:asia-northeast1:biz-db01=tcp:3306 &\n\n\n####Start Client session:        \nmysql -u <USERNAME> -p --host 127.0.0.1\n\nmysql -u bizbb -p KPhgZtW7sUpX --host 127.0.0.1\n\n\n\n\n\n##################################################################################################\n##################################################################################################\nhttps://unerry.docbase.io/posts/215426?list=%2F&q=\n\nInfra Docbase\nelise237\n\nTEST環境情報\n\nプロジェクトID: test-beaconbank-biz\nドメイン: t-biz.beaconbank.jp\n\nサービスアカウント用 JSON ファイル\n Key_JSON_for_GCE_test-biz\n\nLB: 130.211.24.62\nWEB01(Redis): エフェメラルIP(可変)\nWEB02: エフェメラルIP(可変)\n\nDBユーザ: beaconbank\nDBパスワード: 8gRs1T4H\n\nCORE_DBユーザ: bizbb\nCORE_DBパスワード: KPhgZtW7sUpX\n\nログの退避先: gs://test-biz-documents\n※サーバ内部ではlogrotateさせていて、\n※cronで毎朝2時にnginx, application, redisのログをCloudStorageに投げるようになっています。\n\n※Cloud SQLに接続方法はsystemdに登録されたCloud SQL Proxyを使用しています。\n　各インスタンス内からmysql -u [USER] -p -h 127.0.0.1で接続できます。\n\n※GCPは同N/W上であればインスタンス名で接続できるので、redisはインスタンス名をhostとして接続する\n##################################################################################################\n##################################################################################################\n\n\n\n\n#####Schema of database #########################################################################\nss= '''\nSELECT table_name, column_name    FROM information_schema.columns \nWHERE table_name  in ( \n    SELECT table_name \n    FROM information_schema.tables \n    WHERE table_type = 'BASE TABLE'  AND table_schema NOT IN  ('pg_catalog', 'information_schema')\n); \n'''\n\ndf= pd.read_sql(ss, engine2)\n\n\n\n\n###### Cloud SQL Connect #######################################################################\nengine2= sql.create_engine('mysql+mysqlconnector://bizbb:KPhgZtW7sUpX@104.198.113.129:3306/information_schema')\n\n\n\n###### PhP MyAdmin #############################################################################\nengine_2= sql.create_engine('mysql+mysqlconnector://root:atbms_4649@133.242.234.94:3306/atbms')\n\n\n\n\n\n\n\n\n###############################################################################################\n2017-04\n\nhttps://t-biz-analytics.beaconbank.jp/page_bi/a011/?pagename=a011&account_id=95651&application_id=5563&startdate=20170522&enddate=20170528&uurid=9ac9b780b81e4cf7b73fcef482e15db353e535d959266eb488f6403fcd9c053030a819397c10fd8304273d76b6a8c0fa\n\n\n\n\n###############################################################################################\n##############################################################################################\ndb = MySQLdb.connect( host='127.0.0.1', user=CLOUDSQL_USER, passwd=CLOUDSQL_PASSWORD)\n\nbizbb\nbiz_analytcis\n\n\n\n#############################################################################################\nfrom sqlalchemy import create_engine\nengine = create_engine('mysql+pymysql://USER:PASSWORD@127.0.0.1/DATABASE')\n\n\n\n\n\n\n\n###########################################################################################\n######  TensorFlow \nactivate tensorflow\n\n\n### Grid LSTM\nconda install  -c jjhelmus tensorflow-gpu=1.0.1\n\nconda install  --force  -c jjhelmus tensorflow-gpu=1.0.1\nconda install --force\n\n### Install from google Binaries\n###=  Issues with PIP Never installed\n###  pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl\n\n\n\n# Python\nimport tensorflow as tf; print(tf)\nhello = tf.constant('Hello, TensorFlow!')\nsess = tf.Session()\nprint(sess.run(hello))\n\n\n###### Jupyter\nsource activate tensorflow2\njupyter notebook --ip=0.0.0.0 --port=8888 --no-browser &\n\n\n### to see the token and URL of jupyter notebook\njupyter notebook list\n\n\n\n## Type   %connect_info   in Jupyter to get the SSH\n{\n  \"stdin_port\": 39893, \n  \"ip\": \"127.0.0.1\", \n  \"control_port\": 58886, \n  \"hb_port\": 56808, \n  \"signature_scheme\": \"hmac-sha256\", \n  \"key\": \"d4aff2c9-ae8e-484a-a133-285f3961b53f\", \n  \"kernel_name\": \"\", \n  \"shell_port\": 38804, \n  \"transport\": \"tcp\", \n  \"iopub_port\": 37865\n}\n\n\n#### Disable CUDA\nCUDA_VISIBLE_DEVICES=\"\"\n\n\n\n\n######## Deep Learning training\npython   /home/noel/jupyter/project/grid_lstm/train.py  --model  gridlstm  --save_dir  /home/noel/jupyter/project/grid_lstm/save_gridlstm\n\n\npython   /home/noel/jupyter/project/grid_lstm/train.py  --num_epochs 70   --num_layers 4   --model  gridlstm  --save_dir  /home/noel/jupyter/project/grid_lstm/save_gridlstm_4\n\n\npython   /home/noel/jupyter/project/grid_lstm/train.py  --num_epochs 70   --num_layers 4   --model  lstm  --save_dir  /home/noel/jupyter/project/grid_lstm/save_lstm_4\n\n\npython   /home/noel/jupyter/project/grid_lstm/train.py  --num_epochs 1   --num_layers 1   --model  gridlstm  --save_dir  /home/noel/jupyter/project/grid_lstm/save_gridlstm_4\n\n\n\nNamespace(batch_size=50, data_dir='/home/noel/jupyter/project/grid_lstm/data/tinyshakespeare/', decay_rate=0.97, grad_clip=5.0, learning_rate=0.002\n, model='gridlstm', num_epochs=50, num_layers=2, rnn_size=128, save_dir='/home/noel/jupyter/project/grid_lstm/save_gridlstm', save_every=1000, seq_\nlength=50)\n\n###########################################################################################\n###########################################################################################\n\n\n\n\n###########################################################################################\n###########################################################################################\n\n\n\n\n\n\n\n\n\n\n\n##### Test Values / URL:\n\n##### Lauchn test server:\n###  http://104.198.94.24:85/p\n\n\n\n\n##### Connected to Big Query    ##################################\ndfstat:\n\n\n\ndfstat_haishin:  haishin_view\n\n\n\n####  dfstat_homon:\nn_haishin              int64\nn_haishin_user         int64\nn_contentview          int64\nn_contentview_user     int64\nn_yanai                int64\nn_yagai                int64\nn_ya_fumei             int64\nn_koukai               int64\nn_hikoukai             int64\nn_public_fumei         int64\nn_hanoulog             int64\nn_homon                int64\n\n\n\n\n##### dfstat_conv:   # Cv1 ---> CV2  ############################\ndate           object\napp_id         int64\ndatestr        object\ndatestr2       object\naccount_id     int64\ncvgroup1       object\ncvgroup2       object\ncv_pct1        int32\ncv_pct2        int32\n\n\n\n\n###############################################################\nid\t        INTEGER\t\t\ngroup_id\tINTEGER\tNULLABLE\t\nbeacon_id\tINTEGER\tNULLABLE\t\nuse_from\tDATE\tNULLABLE\t\nuse_to\tDATE\tNULLABLE\t\ndau_price\tINTEGER\tNULLABLE\t\ndaily_price\tINTEGER\tNULLABLE\t\nprice_type\tINTEGER\tNULLABLE\t\ndeleted\tINTEGER\tNULLABLE\t\n\nbeacon_prices\n\n\n\n\n\n\n##################################################################################################################################\n##################################################################################################################################\n\nA01-1_管理ビーコン一覧.jpg\n/page_bi/a011/?pagename=a011&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=\n\n\nA04-2_個別ビーコンプッシュ情報1.jpg\n/page_bi/a042_jouhou1/?pagename=a042_jouhou1&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=\n\n\nA06-1_分析3.jpg\n/page_bi/a061_bunseki3/?pagename=a061_bunseki3&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=\n\n\nA06-1_分析1.jpg \n/page_bi/a061_bunseki1/?pagename=a061_bunseki1&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=\n\n\n\nA06-1_分析2.jpg\n/page_bi/a061_bunseki2/?pagename=a061_bunseki2&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=\n\n\n\na042_jouhou3.html\nA04-2_個別ビーコンプッシュ情報3.jpg\n/page_bi/a042_jouhou3/?pagename=a042_jouhou3&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=\n\n\n\na027_area.html\nA02-7_個別ビーコングループ情報1＜エリア＞.jpg\n/page_bi/a027_area/?pagename=a027_area&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=\n\n\na027_cv.html\nA02-7_個別ビーコングループ情報1＜CV＞.jpg \n/page_bi/a027_cv/?pagename=a027_cv&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=\n\n\n\na027_cva.html\nA02-7_個別ビーコングループ情報1＜CVA＞.jpg  \n/page_bi/a027_cva/?pagename=a027_cva&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=\n##################################################################################################################################\n##################################################################################################################################\n\n\n\n\n\n\n##################################################################################################################################\n##################################################################################################################################\n\n### PROD Static Folder  , but, cannot write access to static_root/gg  ---\n---> Need to put in other folders\n### Folder used for Compress files  django comrpress\nProd Static:    /home/noel/project27/geoapp/static_root\nDjango Compress :      /home/noel/project27/geoapp/static_root/cache\nDev Static :  home\\project27\\geoapp\\geoproject\\static\\gg\\\n\nDjango Cache  : (Django managed cached): home\\project27\\jango_cache\nKevin Cache  : (Django managed cached): home\\project27\\cache\n\nKevin Data  : (Django managed cached): home\\project27\\data/\n\n\n\n\n#####Enable DEBUG Mode, Compress mode\nDEBUG=1  COMPRESS=5  sudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   runserver 0.0.0.0:8000 \n\n\nIssue with Compressor:  Need to laucnh 2 times the server\n\n\n\n#### STATIC_ROOT is useless during development, it's only required for deployment.\n\nWhile in development, STATIC_ROOT does nothing. You even don't need to set it. Django looks for static files inside each app's directory (myProject/appName/static) and serves them automatically.\nThis is the magic done by manage.py runserver when DEBUG=True.\n\n#### Deployment\n\nWhen your project goes live, things differ. Most likely you will serve dynamic content using Django and static files will be served by Nginx. Why? Because Nginx is incredibly efficient and will reduce the workload off Django.\nThis is where STATIC_ROOT becomes handy, as Nginx doesn't know anything about your django project and doesn't know where to find static files.\nSo you set STATIC_ROOT = '/some/folder/' and tell Nginx to look for static files in /some/folder/. Then you run manage.py collectstatic and Django will copy static files from all the apps you have to /some/folder/.\n\n### Extra directories for static files\n\nSTATICFILES_DIRS is used to include additional directories for collectstatic to look for. For example, by default, Django doesn't recognize /myProject/static/. So you can include it yourself.\nExample\nSTATIC_URL = '/static/'\n\nif not DEBUG: \n    STATIC_ROOT = '/home/django/www-data/site.com/static/'\n\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, 'static/'),\n]\n\n\n\n\n\n<h2>行動アナリティクス</h2>\n\n.....\n\n\n<div style=\"height: 1200px; width=100%; min-width: 1024px;\"> \n\n<iframe  >\n\n</div>\n\n\n\npagename=a061_bunseki3\n\n\n:\nこんにちは、\nおすすめは　ありがとうございました。\nしかし、PowerBIは　JS restrictionがあったら、\n<DIV > tag ほうがいいとおもいます\n\n\nPageLayoutは　Design 設定ですから、　変わらない,\n\n\nこのペ－ジのテストしました: \n\n<div style=\"height: 1200px; width=100%; min-width: 1024px;\"> \n\n<iframe    style=\"width: 100%;min-width: 1024px;height: 100%;\" scrolling=\"no\" seamless=\"seamless\" frameborder=\"0\">\n\n</div>\n\n下にテストがみられます:\nsimpleですから、調整しやすいです.\nよろしくお願いします\n\n\n\n<div style=\"width:80%; height:100%; margin:0 auto; float: left;  min-width: 1024px;\">\n\n  <iframe style=\"position:absolute;top:0;left:0;width:100%; height:100%;\"\n</div>\n\n\n\nhtml,body        {height:100%;}\n.wrapper         {width:80%;height:100%;margin:0 auto;background:#CCC}\n.h_iframe        {position:relative;}\n.h_iframe .ratio {display:block;width:100%;height:auto;}\n.h_iframe iframe {position:absolute;top:0;left:0;width:100%; height:100%;}\n\n\n\n\nhttp://apps.socib.es/Leaflet.TimeDimension/examples/example12.html\n\n\n######################################\n\n\n\n\n別のテストをしました\nSimple <div> の　tag は　layoutができました :\n\n<div style=\"text-align: left;height: 500px;float: left;\">\n  \n  <iframe ></iframe>\n  \n</div>\n\nPageLayoutが Deignから、決められました,\n変わりません.\n\n\n\n\n##########################################################################################\n<div class=\"intrinsic-container\">\n  <iframe src=\"allowfullscreen\"></iframe>\n</div>\n\n\n\n<style>\n.intrinsic-container {\n  position: relative;\n  height: 0;\n  overflow: hidden;\n}\n \n/* 16x9 Aspect Ratio */\n.intrinsic-container-16x9 {\n  padding-bottom: 56.25%;\n}\n \n/* 4x3 Aspect Ratio */\n.intrinsic-container-4x3 {\n  padding-bottom: 75%;\n}\n \n.intrinsic-container iframe {\n  position: absolute;\n  top:0;\n  left: 0;\n  width: 100%;\n  height: 100%;\n}\n</style>\n\n##########################################################################################\nIntgのアカウント test5@example.com pass: testtest に変わりました。よろしくお願いします。\n\n\n\n\n\n\n\n\n\n\n\n############################################################\nvar $iframes = $( \"iframe\" );\n\n$iframes.each(function () {\n  $( this ).data( \"ratio\", this.height / this.width )\n    .removeAttr( \"width\" )\n    .removeAttr( \"height\" );\n});\n \n\n$( window ).resize( function () {\n  $iframes.each( function() {\n    var width = $( this ).parent().width();\n    var height = $( this ).parent().height();\n    $( this ).width( width )\n      .height( height );\n  });\n\n}).resize();\n\n\n\n\n\n\n\n\n\n\n\n\n\n##########################################################################################\nhttp://104.198.117.174:8000/page_bi/a061_bunseki3/\n?pagename=a061_bunseki3&account_id=95651&application_id=5563&startdate=20170505&enddate=20170511&uurid=e99b97733e506c2a241407107d7b680af4c03d6e4d8536091881654e010193270ccc7e0a990bd4c83eb9b5b99e9f05d0\n\n\n\n<div style=\"height: 1200px; width=100%; min-width: 1024px;\"> \n<iframe src=\"http://104.198.117.174:8000/page_bi/a061_bunseki3/?pagename=a061_bunseki3&account_id=95651&application_id=5563&startdate=20170505&enddate=20170511&uurid=e99b97733e506c2a241407107d7b680af4c03d6e4d8536091881654e010193270ccc7e0a990bd4c83eb9b5b99e9f05d0\" style=\"width: 100%;min-width: 1024px;height: 100%;\" scrolling=\"no\" seamless=\"seamless\" frameborder=\"0\"></iframe>\n</div>\n\n\n\n\n<div class=\"container\">\n  <iframe src=\"//www.youtube.com/embed/KMYrIi_Mt8A\" allowfullscreen></iframe>\n</div>\n\n\n\n\n\n\n\n#############################################################################################\n###  https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs\nOpen SSL certificates\n\nCountry Name (2 letter code) [AU]:US\nState or Province Name (full name) [Some-State]:New York\nLocality Name (eg, city) []:Brooklyn\nOrganization Name (eg, company) [Internet Widgits Pty Ltd]:Example Brooklyn Company\nOrganizational Unit Name (eg, section) []:Technology Division\nCommon Name (e.g. server FQDN or YOUR name) []:examplebrooklyn.com\nEmail Address []:\n\n\n\n\n###### URL map details   ############################################\nhttps://cloud.google.com/compute/docs/load-balancing/http/url-map\n\n#####  Load Balancer,  1 USD,  0.025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n##########################################################################\nHello,\n\nBI Pages have been published since last week.\n\nPages can be checked  from the website directly, \nhere below urls :\n\nTexts have been added and basic layout have been added.\nThis is possible that some adjustments might be needed,\nin that case, could you kindly send summary by email this week ?\n(since it takes T+3-4days to adjust the pages, depending on schedule)\n\nPages urls are here :\n(Login: id: test1@test.com, pass: testtest)\n\nA01-1_管理ビーコン一覧\t\nhttp://13.112.171.13/apps/1/beacon_groups\n\nA06-1_分析3\t\nhttp://13.112.171.13/apps/1/analytics/enduser\n\nA06-1_分析1\t\nhttp://13.112.171.13/apps/1/analytics\n\nA04-1_ビーコンプッシュ一覧\t\nhttp://13.112.171.13/apps/1/beacon_pushes\n\nA04-2_個別ビーコンプッシュ情報1\t\nhttp://13.112.171.13/apps/1/beacon_pushes/2\n\nA04-2_個別ビーコンプッシュ情報3\t\nhttp://13.112.171.13/apps/1/beacon_pushes/2/evaluation\n\nA06-1_分析2\t\nhttp://13.112.171.13/apps/1/analytics/app_dna\n\nA02-7_個別ビーコングループ情報3\t\nhttp://13.112.171.13/apps/1/beacon_groups/2/area_heat_map\n\nA02-7_個別ビーコングループ情報4＜CV&CVA＞\t\nhttp://13.112.171.13/apps/1/beacon_groups/2/cv_map\n######################################################################################################\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n########################################################################################################\nAct 4: Hello admin\nOne of Django’s unique features is that it comes with a custom administration that allows users to view, edit and create records. To see it in action, create a new superuser with permission to edit all records.\n\n$ python manage.py createsuperuser\n  noel\n  noelkev0\n  sophie237\n\n sudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   createsuperuser\n\n\n\nGcloud on BizBank:\n    Open http traffic + Check on IP Adress\n    Tag of VM (http-srver) and Tag of Firewall rule should be the same.\n\n\nNeed to add internal Gcloud VM IP in Django : 10.146.0.6\n\n\n\n\n\nThis address \nhttp://104.198.117.174/page_A011?application_id=&startdate=20170101&enddate=20170101.....\n\n\nIn Google Network Setting, allow Http Requests. with IP Config\n\n\n\n\n\n##############\nBig JSON, Static JSON  ---->  Generate JSScript Library JSON   ---> Use table for rendering\n\n\n\n##### Fast Hash to encode datetime:\nhttps://www.npmjs.com/package/xxhashjs  : Javascript\nhttps://pypi.python.org/pypi/xxhash/    : Python\n\nhash(\"MMDDYYYY+sfdf\")  !=  then break\n\n\n\n\n\n\n####### Pandas Eval for fast evaluation:\ndf.eval(\"\"\"\n   ....: c = a + b\n   ....: d = a + b + c\n   ....: a = 1\"\"\", inplace=False)\n\n\n\nIn [42]: df = pd.DataFrame(np.random.randn(5, 2), columns=list('ab'))\n\nIn [43]: newcol = np.random.randn(len(df))\n\nIn [44]: df.eval('b + @newcol')\n\n\n\nIn [66]: df.query('strings == \"a\" and nums == 1')\nOut[66]: \nEmpty DataFrame\nColumns: [nums, strings]\nIndex: []\n\n\n\n\n\n\n\n\n##### Security Process:  \nhttp://stackoverflow.com/questions/298772/django-template-variables-and-javascript\n\n\n\n\n########## SSL Cerificates   #####################################################\nhttps://simpleisbetterthancomplex.com/tutorial/2016/05/11/how-to-setup-ssl-certificate-on-nginx-for-django-application.html\n\n\n#### Generate Certificates :\n\nWith Shell Access\nWe recommend that most people with shell access use the Certbot ACME client. It can automate certificate issuance and installation with no downtime. It also has expert modes for people who don’t want autoconfiguration. It’s easy to use, works on many operating systems, and has great documentation. \nVisit the Certbot site to get customized instructions for your operating system and web server.\nIf Certbot does not meet your needs, or you’d like to try something else, \nthere are many more ACME clients to choose from. Once you’ve chosen ACME client software, \nsee the documentation for that client to proceed.\nIf you’re experimenting with different ACME clients, use our staging environment to avoid hitting rate limits.\n\n\n\n\nUsually CSR openssl configuration contains by default the details as follows below:\nCommon Name (the domain name certificate should be issued for)\nCountry\nState (or province)\nLocality (or city)\nOrganization\nOrganizational Unit (Department)\nE-mail address\nTo generate the CSR code run the following code in your server terminal:\n\nopenssl req -new -newkey rsa:2048 -nodes -keyout simpleacademy.key -out simpleacademy.csr\n\n\nGrab the contents of the file simpleacademy.csr and paste it into the activation page:\n\n\n\n\nNow you will need two files to activate the server :\nsimple_academy_cert_chain.crt\nsimpleacademy.key (the key you genered while creating the CSR)\n\n\n\n\n\n################# Javascript details   ####################################################################\nSHA384 Hex is used for the transmission of UURID.\n\n今週は　Testは　GCPですから、GCPのserverを見られるのは　いつようです.\nしょして、これから、　Krayが GCPのWeb serverを利用ください.\n\nTo make it simple, one possibility is to use inside the UURID.\nAlthough this is far from ideal situation that we need to acknowledge, \nCertificate would be much better but quite heavy in this situation.\n1)\n  uurid with template :\n  \"ServerIPadress_pagename_accountid_appid_YYYYMMDDHH\"\n  35.189.149.154_a1014_25665_55552_2017010112\" \n\n\n2) Alternatively, we can use this for the client side, \n   although this is far from ideal situation.\n   Certificate would be much better.\n\n\n<script>\n   ifrm = document.createElement(\"iframe\"); \n   var url1=  url1 + '&details='+ window.location.hostname\n   ifrm.setAttribute(\"src\", url1);\n    document.body.appendChild(ifrm); \n</script>\n\n\n\nfunction createIFrame() {\n    var ref = document.referrer;\n    ifrm = document.createElement(\"iframe\"); \n    ifrm.setAttribute(\"src\", \"http://www.nba.com/?referrer=\"+ref); \n    ifrm.style.width = 640+\"px\"; \n    ifrm.style.height = 480+\"px\"; \n    document.body.appendChild(ifrm); \n} \n\ncreateIFrame();\n\n\nvar x = location.origin;\n\n\n\n\n\n######### Summary:  ##############################\n本日の話の点のまとめ:\n\nもし　確認質問/質問/修正があったら、　ここに　入れてください。\n\n1)  Method 1 の決められた:\n    UURID :  using SHA384 Hex の方法\n    \"ServerIPadress_pagename_accountid_appid_YYYYMMDDHH\"\n    \"35.189.149.154_a1014_25665_55552_2017010112\"\n\n\n2)  Hashの確認:\n   (Kray san)のServerIp (Kray san)\n     \n    Hashの確認,お互いに　計算して、Slackに出します。\n　　  例:  \"35.189.149.154_a1014_25665_55552_2017010112\"\n\n\n3)  HTTPSの確認: (Kevin)\n  　　\n\nよろしくお願いします。\n\n\n35.189.149.154 \n\n\n\nss=  \"35.189.149.154_a1014_25665_55552_2017010112\"\nSHA384 Hex: \n'0622c4aba8b26200026282b5755bdea95a586982e3d81df4f339110b125c3ee12807a2b18fa541fba7b2f2f8c3a0cd45'\n\n\n\n\"35.189.149.154_a1014_25665_55552_2017010112\"\n\n\n\n\n#############\n\n\n\n\n\n\n\n\n\n\n### Server Limit:\n220.221.95.138       35.189.149.154         10.146.0.2\n\n\n### tcp: 8080\npip install django-sslserver\n\n\n\n#### HTTPS server :  Check at Home:\nhttps://github.com/teddziuba/django-sslserver\n\n$ pip install django-sslserver\n\n\nINSTALLED_APPS = (...\n\"sslserver\",\n...\n)\n\n\n\n###Need to generate Certificate : Private Key / Public Key\nhttps://www.sslforfree.com/create?domains=104.198.117.174\n\n\n\n\n\n5) A06-1_分析1.jpg       (with no map at 1st)\n\n6) A04-2_個別ビーコンプッシュ情報3.jpg  (with  no map at 1st)\n\n7) A02-7_個別ビーコングループ情報1＜エリア＞.jpg    (with no map at 1st)\n\n8) A02-7_個別ビーコングループ情報1＜CV＞.jpg      (with no map at 1st)\n\n9) A02-7_個別ビーコングループ情報1＜CVA＞.jpg      (with no map at 1st)\n\n\nhttp://104.198.117.174:8000/page_bi/a011/?pagei=a011&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=s5f5f54s5f5sd5fs\n\n\n\npagei=a011&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=s5f5f54s5f5sd5fs#\n\n\n\"35.189.149.154_a011_95651_5563_2017042712\"\n\n\n\n\nimport hashlib\nuurid2= hashlib.sha384(ss).hexdigest()\nss=  \"35.189.149.154_a011_95651_5563_2017042712\"\nhashlib.sha384(ss).hexdigest()\n\n\n\n\n########### Linux Ubuntu 14.0でこれは　です:   #######################################################\n\n昨日:\n>>> ss= \"35.189.149.154_a1014_25665_55552_2017010112\"\n'0622c4aba8b26200026282b5755bdea95a586982e3d81df4f339110b125c3ee12807a2b18fa541fba7b2f2f8c3a0cd45'\n\n\n今日:\n>>> ss=  \"35.189.149.154_a011_95651_5563_2017042712\"\n'0011a0de3b26bd138f12788ba3310ea878eddcdf1a1a95e36722014ea91580186994701316e320454c61a588314cd4c8'\n\n\n同じです.\n\n\nhttp://104.198.117.174:8000/page_bi/a011/?pagei=a011&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101&uurid=0011a0de3b26bd138f12788ba3310ea878eddcdf1a1a95e36722014ea91580186994701316e320454c61a588314cd4c8\n\n\n\n#### Specs of Pages :   ############################################################\nhttps://docs.google.com/document/d/1VsXa2qcvM7F8pgTwWdx3gBdw1vHoSoPXg9KFmjPArf8/edit\n\n\n\n##### CSS tags ######################################################################\n####\nboostrap.min.css\n\"Hiragino Kaku Gothic ProN\", \"Yu Gothic\", YuGothic, Verdana, Meiryo, sans-serif\n\nRed Color :\n\"color\": \"E55165\"\n\n\n\n<style>\n.rTable { display: table; width: 100%; } .rTableRow { display: table-row; } .rTableHeading { display: table-header-group; background-color: #ddd; } .rTableCell, .rTableHead { display: table-cell; padding: 3px 10px; border: 1px solid #999999; } .rTableHeading { display: table-header-group; background-color: #ddd; font-weight: bold; } .rTableFoot { display: table-footer-group; font-weight: bold; background-color: #ddd; } .rTableBody { display: table-row-group; }\n\n\n.h4class { font-family: \"Hiragino Kaku Gothic ProN\", \"Yu Gothic\", YuGothic, Verdana, Meiryo, sans-serif ;     font-size: 16px; font-weight: 600; }\n\n</style>\n\n\n<h4 class=\"h4class\">リ－ビタ－ 比率</h4>\n\n\n\n\nFinished  1\n\nPage    a011.html\nPage    a061_bunseki3.html\nPage    a42_jouhou1.html\nPage    a061_bunseki1.html\nPage    a061_bunseki2.html\n\n\n\n\n\n\n#####  Details \nfont-family:\"ヒラギノ角ゴ Pro W3\", \"Hiragino Kaku Gothic Pro\",Osaka, \"メイリオ\", Meiryo, \"ＭＳ Ｐゴシック\", \"MS PGothic\", sans-serif;\n\n\n\n\n\n\nvar lineChartOptions={\n  \"chart\": { \"caption\": \"Daily Visits\", \"linethickness\": \"1\", \"showvalues\": \"0\",\"formatnumberscale\": \"0\", \"anchorradius\": \"2\",\n  \"divlinecolor\": \"666666\", \"divlinealpha\": \"30\", \"divlineisdashed\": \"1\", \"labelstep\": \"2\", \"bgcolor\": \"FFFFFF\",\n  \"showalternatehgridcolor\": \"0\", \"labelpadding\": \"10\", \"canvasborderthickness\": \"1\", \"legendiconscale\": \"1.5\",\n  \"legendshadow\": \"0\", \"legendborderalpha\": \"0\", \"canvasborderalpha\": \"50\", \"numvdivlines\": \"5\", \"vdivlinealpha\": \"20\",\n  \"showborder\": \"0\", \n\n\"anchorradius\": \"4\",  \"anchorborderthickness\": \"2\",\n\n\n\n### Pink Color\nEA7584\n\n\n\n########################################################################################################################\n##### Prod Server\n  timestamp server\n  whitenoise is activated ---> Static Files must be updated by collectstatic\n    sudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   collectstatic\n\n\n\n\n\n\n####  Dev\n  Remove whitenoise when doing devs\n\n\nDJANGO_DEBUG=12 sudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   runserver 0.0.0.0:8000\n\n\n\n\n\n\nml{font-size:10px;-webkit-tap-highlight-color:rgba(0,0,0,0)}body{f\n\n\n\n\n#### Refactoring :\n\n   \n#####################################\n  <body>\n  <div class=\"container\">\n    <div align='middle'>\n\n\n<iframe width=\"1024x\" height=\"230px\"   scrolling=\"no\"    style=\"\" src=\"graph_test2.html\" frameborder=\"0\" allowFullScreen=\"False\"></iframe>\n\n\n<iframe width=\"1024x\" height=\"230px\"   scrolling=\"no\"    style=\"\" src=\"graph_test2.html\" frameborder=\"0\" allowFullScreen=\"False\"></iframe>\n\n\n<iframe width=\"1024x\" height=\"230px\"   scrolling=\"no\"    style=\"\" src=\"http://104.198.117.174:8000/page_bi/graph_test2/?pagei=a011&account_id=95651&application_id=5563&startdate=20170101&enddate=20170101\" frameborder=\"0\" allowFullScreen=\"False\"></iframe>\n\n\n\n\nIp Adress from Kray  ipadress 153.156.78.132   Kray IP\n\n\n##################################################################################\nUnerry Ip Adresss : 122.208.202.84\nAsus Ip Adress :  220.221.95.138\n\n\nUnerry G, 3G :    153.156.78.132\nPortalPoint, 5G : 122.208.202.84\n\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/visualsandbox.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/visualhostcore.min.js\"></script>\nvisualsandbox.min.js:1\n\n\ne88f171229927ce6b10947d7b8dc87d10405ccde8bc0abb0501ef032a22bc1a738dc7ab0f62a843663803b7a507c1ba0\n\n\n@uchijima ,  :\nお疲れさまです.\n\n以下の話しについて:\nServer SSL certificateのファイルは　ありませんか?\n( Certificate file も Certificate key file ) ? (edited)\nよろしく\n\n\n\n\n\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/visualsandbox.minimal.externals.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/visualssandboxcore.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/utility.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/data.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/globalize.min.js\" defer=\"\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/globalize.culture.en-us.js\" defer=\"\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/localytics.min.js\" defer=\"\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/powerbiportal.dependencies.externals.bundle.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/powerbiportal.dependencies.bundle.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/powerbiportal.common.bundle.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/powerbiportal.explore.bundle.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/powerbiportal.addons.bundle.min.js\"></script>\n<script type=\"text/javascript\" src=\"../../static/gg/powerbi/powerbiportal.web.bundle.min.js\"></script>\n<script src=\"../../static/gg/powerbi/ai.0.js\"></script>\n\n<script>\n    var powerBIAccessToken = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6InowMzl6ZHNGdWl6cEJmQlZLMVRuMjVRSFlPMCIsImtpZCI6InowMzl6ZHNGdWl6cEJmQlZLMVRuMjVRSFlPMCJ9.eyJhdWQiOiJodHRwczovL2FuYWx5c2lzLndpbmRvd3MubmV0L3Bvd2VyYmkvYXBpIiwiaXNzIjoiaHR0cHM6Ly9zdHMud2luZG93cy5uZXQvY2VmNzFjMDItNzRjYS00MWY0LTk5NjUtYTRhNDdhMmQ0MTliLyIsImlhdCI6MTQ5MzY5MTA3OCwibmJmIjoxNDkzNjkxMDc4LCJleHAiOjE0OTM2OTQ5NzgsImFjciI6IjEiLCJhaW8iOiJBU1FBMi84REFBQUFaZld0cStOcXhHaUkrYk9yei9idjdwT0J6cFpUSG1KbUxUaVNHT3ZmUlBNPSIsImFtciI6WyJwd2QiXSwiYXBwaWQiOiI4NzFjMDEwZi01ZTYxLTRmYjEtODNhYy05ODYxMGE3ZTkxMTAiLCJhcHBpZGFjciI6IjIiLCJlX2V4cCI6MjYyODAwLCJmYW1pbHlfbmFtZSI6IktldmluIiwiZ2l2ZW5fbmFtZSI6Ik5vZWwiLCJpcGFkZHIiOiIxNTMuMTU2Ljc4LjEzMiIsIm5hbWUiOiJOb2VsIEtldmluIiwib2lkIjoiOGQyNzEyMGEtZTAzMC00ZmJmLWJkNDgtNjNmOGNiOWYwYjllIiwicGxhdGYiOiIzIiwicHVpZCI6IjEwMDNCRkZEOUQ3Q0EzODIiLCJzY3AiOiJ1c2VyX2ltcGVyc29uYXRpb24iLCJzdWIiOiJJajR0TjFCLU9VNy0wNlFxR2t4dVVwN1FYVW1YN3hVVS00dXNjWGEzQkhRIiwidGlkIjoiY2VmNzFjMDItNzRjYS00MWY0LTk5NjUtYTRhNDdhMmQ0MTliIiwidW5pcXVlX25hbWUiOiJub2VsQHVuZXJyeS5jby5qcCIsInVwbiI6Im5vZWxAdW5lcnJ5LmNvLmpwIiwidmVyIjoiMS4wIn0.kqeBJlqqzmsznqVJzNV7UTqA5UhcWoT2bqtfA_Xz5Cbd_cGtC0SsqJOmEjXOlLyv3DK5qeVca1t3JRq6fQJOpgvZt4vaGLjrT_EDGnkeS-PxmBvTb7YfkshrVO7c0UlfYSh2o7q52zD3d-Q5RGgAwIawKDjluQqJ1g2BF6joOoeg8T-l2FV96qJb2wjWWIl9PN11Zrk-8WTJuVz-cBlD17AVc2fidyl30yTA2SVJE-fwnKAEHuv_IKwMO5_O5foDrd9s4o51XZFdT0JfCCGFhYZdY57Lq9O5NhOUDb8VxmUjsZQqZwbMnuLTW5HsSMZULRebRJXCCI1UItFJrE7l5w';\n    var powerBIAccessTokenExpiry = '';\n    var baseUrl = window.location.protocol + \"//\" + window.location.host;\n    var powerbi = {\n        session : {\n            userInfo: {\n                name:  '',\n                givenName: '',\n                surname: '',\n                puid: '1003BFFD9D7CA382',\n                uoid: '8d27120a-e030-4fbf-bd48-63f8cb9f0b9e',\n                alternateEmail: ''\n            }\n        }\n    };\n    powerbi.telemetrySamplingRules = { appInsights: [{ purpose: \"CriticalError\", sampleRate: 1 },{ purpose: \"CustomerAction\", sampleRate: 1 },{ purpose: \"Verbose\", sampleRate: 1 }], localytics: [{ purpose: \"CriticalError\", sampleRate: 1 },{ purpose: \"CustomerAction\", sampleRate: 1 },{ purpose: \"Verbose\", sampleRate: 0 }], perf: [{ purpose: \"CriticalError\", sampleRate: 1 },{ purpose: \"CustomerAction\", sampleRate: 1 },{ purpose: \"Verbose\", sampleRate: 1 }] };\n    powerbi.build = '13.0.1700.2008';\n    powerbi.buildDetails = '13.0.1700.2008 ((PowerBI_2017_04_4).170429-2002)';\n    powerbi.common = {};\n    powerbi.common.cultureInfo = 'en-US';\n    powerbi.common.unmappedCultureInfo = 'en-US';\n    powerbi.common.isCurrentContextRtl = 'False';\n    powerbi.common.disableMap = 'False';\n    powerbi.customVisualsUrl = 'https://visuals.azureedge.net/;https://visuals2.azureedge.net/;https://extendcustomvisual.blob.core.windows.net/';\n    powerbi.visualCDNBlobContainerUrl = 'prod';\n    var clusterUri =  'https://wabi-japan-east-redirect.analysis.windows.net';\n    var apiUri =  'https://api.powerbi.com';\n    var tenantId = 'cef71c02-74ca-41f4-9965-a4a47a2d419b';\n    var previousTenantId =  '';\n    var appInsightsV2InstrKey = '00406067-1af3-44c5-a2c1-4a57dd50194c';\n    var localyticsInstrKey = 'd481bcc9809fe5c23d780ae-ff4d768c-3469-11e4-a38d-009c5fda0a25';\n    var telemetrySessionId =  '6e417ef7-1929-4adc-8530-ef0f408869cf';\n    var featureSwitches = (function () { var adminAuditingEnabled = true, adminCapacityEnabled = false, allUpSaveReport = true, altTextForVisual = false, analyzeInExcelEnabled = true, analyzeInExcelSovereignFormatEnabled = false, anonymousEmbeddingEnabled = true, approvedResourcesDisabled = false, appsEnabled = false, appStoreCdnOverride = false, appTemplatesEnabled = false, autoPausedSyncService = false, axisControlImprovements = true, azureUsageAndBillingAppEnabled = false, bingAdsAppEnabled = false, binnedLineSampling = false, breadcrumbNavigationEnabled = true, builtInContentProvidersDisabled = false, clientUsageMetricsEnabled = false, closeAccountEnabled = true, cloudRlsImpersonationEnabled = true, cloudRlsRoleMembershipEnabled = true, clusteringEnabled = false, conceptualModelEnabled = false, csvContentProviderEnabled = true, customFontFamily = true, customVisuals = false, customVisualsUseStaticSandbox = false, dashboardEmailSubscription = false, dashboardEmbedEnabled = true, dataClassificationEnabled = true, datasetDownloadPbix = true, datetimeMinMaxSupported = true, devToolsNewVisual = true, devToolsVisualSettings = true, directQueryScheduledRefresh = false, donutChartLabelPercentEnabled = true, downloadReportEnabled = true, dynamicMessageEnabled = true, emailSubscriptionEnabled = true, embedFullFidelityWorkbooks = true, enableExportDataNewDialog = true, enterpriseGatewayEnabled = true, enterpriseGatewayETLEnabled = true, esriEnabled = true, excelWorkbooksInContentPackEnabled = true, exportReportToPowerPointEnabled = true, exportVisualToExcelEnabled = true, favoritesEnabled = true, ffxlChartSelectionEnabled = true, ffxlLocalFilesEnabled = true, forecastEnabled = true, frontLoadReportEmbedEnabled = true, fullFidelityExcelEnabled = true, granularTenantControls = true, groupCapacity = false, hierarchyAuthoringEnabled = false, hierarchyDragDrop = false, highVolume = false, homeDashboardEnabled = true, importPbiviz = true, inFocusEditEnabled = false, insightsStoreEnabled = true, insightsSyncServiceEnabled = true, isSovereignCloud = false, listViewEnabled = true, matrixWordWrap = true, microsoftOrgAppEnabled = false, multipleODataPredicates = false, negatedTuplesFiltering = false, numericSlicerEnabled = false, o365PowerBIEnabled = true, oneGBUploadFileSizeEnabled = true, orgAppsEnabled = true, paasDynamicRoutingEnabled = true, permissionCenterEnabled = false, pivotTableVisualEnabled = false, preferHigherDataVolume = true, previewConceptualModel = true, previewDefaultOptIn = false, psaAccountManagerAppEnabled = false, psaPracticeManagerAppEnabled = false, psaResourceManagerAppEnabled = false, pseudoLocEnabled = false, qnaSupportOnPremEnabled = true, readOnlyGroupEnabled = true, realTimeASAEnabled = false, realTimePubNubEnabled = true, relativeDateSlicer = false, reportEmbedEditingEnabled = true, reportMeasures = true, responsiveVisualEnabled = false, saasMarketplace = true, salesforceAndOneDriveCredentialsEnabled = true, sandboxVisualsEnabled = true, scriptVisualAnonymousEmbeddingEnabled = false, scriptVisualAuthoringEnabled = false, scriptVisualEnabled = true, scriptVisualLaunchExternalIDEEnabled = false, selectiveModelRefresh = false, selectiveRefreshEnabled = true, serviceAppsEnabled = false, sharePointDocumentLibrariesEnabled = true, sharePointEmbedEnabled = true, showNonUserEntitiesEnabled = false, socialSharingEnabled = true, sparkAppEnabled = true, staticExportReportEnabled = false, stringMinMax = true, tablixWordWrap = true, targetedDataViewParse = false, templateAppUpgradeEnabled = false, templatePublishFlightingWorkAroundEnabled = false, testClientSwitchesForSafeDeployment = false, textboxFontColorEnabled = true, tuplesFiltering = true, useBackendFSEnabled = true, userNotificationsEnabled = true, visualContainerTileConfig = false, vsoVnextAppEnabled = false, withinDXT = false; return { adminAuditingEnabled: function () { return adminAuditingEnabled; }, adminCapacityEnabled: function () { return adminCapacityEnabled; }, allUpSaveReport: function () { return allUpSaveReport; }, altTextForVisual: function () { return altTextForVisual; }, analyzeInExcelEnabled: function () { return analyzeInExcelEnabled; }, analyzeInExcelSovereignFormatEnabled: function () { return analyzeInExcelSovereignFormatEnabled; }, anonymousEmbeddingEnabled: function () { return anonymousEmbeddingEnabled; }, approvedResourcesDisabled: function () { return approvedResourcesDisabled; }, appsEnabled: function () { return appsEnabled; }, appStoreCdnOverride: function () { return appStoreCdnOverride; }, appTemplatesEnabled: function () { return appTemplatesEnabled; }, autoPausedSyncService: function () { return autoPausedSyncService; }, axisControlImprovements: function () { return axisControlImprovements; }, azureUsageAndBillingAppEnabled: function () { return azureUsageAndBillingAppEnabled; }, bingAdsAppEnabled: function () { return bingAdsAppEnabled; }, binnedLineSampling: function () { return binnedLineSampling; }, breadcrumbNavigationEnabled: function () { return breadcrumbNavigationEnabled; }, builtInContentProvidersDisabled: function () { return builtInContentProvidersDisabled; }, clientUsageMetricsEnabled: function () { return clientUsageMetricsEnabled; }, closeAccountEnabled: function () { return closeAccountEnabled; }, cloudRlsImpersonationEnabled: function () { return cloudRlsImpersonationEnabled; }, cloudRlsRoleMembershipEnabled: function () { return cloudRlsRoleMembershipEnabled; }, clusteringEnabled: function () { return clusteringEnabled; }, conceptualModelEnabled: function () { return conceptualModelEnabled; }, csvContentProviderEnabled: function () { return csvContentProviderEnabled; }, customFontFamily: function () { return customFontFamily; }, customVisuals: function () { return customVisuals; }, customVisualsUseStaticSandbox: function () { return customVisualsUseStaticSandbox; }, dashboardEmailSubscription: function () { return dashboardEmailSubscription; }, dashboardEmbedEnabled: function () { return dashboardEmbedEnabled; }, dataClassificationEnabled: function () { return dataClassificationEnabled; }, datasetDownloadPbix: function () { return datasetDownloadPbix; }, datetimeMinMaxSupported: function () { return datetimeMinMaxSupported; }, devToolsNewVisual: function () { return devToolsNewVisual; }, devToolsVisualSettings: function () { return devToolsVisualSettings; }, directQueryScheduledRefresh: function () { return directQueryScheduledRefresh; }, donutChartLabelPercentEnabled: function () { return donutChartLabelPercentEnabled; }, downloadReportEnabled: function () { return downloadReportEnabled; }, dynamicMessageEnabled: function () { return dynamicMessageEnabled; }, emailSubscriptionEnabled: function () { return emailSubscriptionEnabled; }, embedFullFidelityWorkbooks: function () { return embedFullFidelityWorkbooks; }, enableExportDataNewDialog: function () { return enableExportDataNewDialog; }, enterpriseGatewayEnabled: function () { return enterpriseGatewayEnabled; }, enterpriseGatewayETLEnabled: function () { return enterpriseGatewayETLEnabled; }, esriEnabled: function () { return esriEnabled; }, excelWorkbooksInContentPackEnabled: function () { return excelWorkbooksInContentPackEnabled; }, exportReportToPowerPointEnabled: function () { return exportReportToPowerPointEnabled; }, exportVisualToExcelEnabled: function () { return exportVisualToExcelEnabled; }, favoritesEnabled: function () { return favoritesEnabled; }, ffxlChartSelectionEnabled: function () { return ffxlChartSelectionEnabled; }, ffxlLocalFilesEnabled: function () { return ffxlLocalFilesEnabled; }, forecastEnabled: function () { return forecastEnabled; }, frontLoadReportEmbedEnabled: function () { return frontLoadReportEmbedEnabled; }, fullFidelityExcelEnabled: function () { return fullFidelityExcelEnabled; }, granularTenantControls: function () { return granularTenantControls; }, groupCapacity: function () { return groupCapacity; }, hierarchyAuthoringEnabled: function () { return hierarchyAuthoringEnabled; }, hierarchyDragDrop: function () { return hierarchyDragDrop; }, highVolume: function () { return highVolume; }, homeDashboardEnabled: function () { return homeDashboardEnabled; }, importPbiviz: function () { return importPbiviz; }, inFocusEditEnabled: function () { return inFocusEditEnabled; }, insightsStoreEnabled: function () { return insightsStoreEnabled; }, insightsSyncServiceEnabled: function () { return insightsSyncServiceEnabled; }, isSovereignCloud: function () { return isSovereignCloud; }, listViewEnabled: function () { return listViewEnabled; }, matrixWordWrap: function () { return matrixWordWrap; }, microsoftOrgAppEnabled: function () { return microsoftOrgAppEnabled; }, multipleODataPredicates: function () { return multipleODataPredicates; }, negatedTuplesFiltering: function () { return negatedTuplesFiltering; }, numericSlicerEnabled: function () { return numericSlicerEnabled; }, o365PowerBIEnabled: function () { return o365PowerBIEnabled; }, oneGBUploadFileSizeEnabled: function () { return oneGBUploadFileSizeEnabled; }, orgAppsEnabled: function () { return orgAppsEnabled; }, paasDynamicRoutingEnabled: function () { return paasDynamicRoutingEnabled; }, permissionCenterEnabled: function () { return permissionCenterEnabled; }, pivotTableVisualEnabled: function () { return pivotTableVisualEnabled; }, preferHigherDataVolume: function () { return preferHigherDataVolume; }, previewConceptualModel: function () { return previewConceptualModel; }, previewDefaultOptIn: function () { return previewDefaultOptIn; }, psaAccountManagerAppEnabled: function () { return psaAccountManagerAppEnabled; }, psaPracticeManagerAppEnabled: function () { return psaPracticeManagerAppEnabled; }, psaResourceManagerAppEnabled: function () { return psaResourceManagerAppEnabled; }, pseudoLocEnabled: function () { return pseudoLocEnabled; }, qnaSupportOnPremEnabled: function () { return qnaSupportOnPremEnabled; }, readOnlyGroupEnabled: function () { return readOnlyGroupEnabled; }, realTimeASAEnabled: function () { return realTimeASAEnabled; }, realTimePubNubEnabled: function () { return realTimePubNubEnabled; }, relativeDateSlicer: function () { return relativeDateSlicer; }, reportEmbedEditingEnabled: function () { return reportEmbedEditingEnabled; }, reportMeasures: function () { return reportMeasures; }, responsiveVisualEnabled: function () { return responsiveVisualEnabled; }, saasMarketplace: function () { return saasMarketplace; }, salesforceAndOneDriveCredentialsEnabled: function () { return salesforceAndOneDriveCredentialsEnabled; }, sandboxVisualsEnabled: function () { return sandboxVisualsEnabled; }, scriptVisualAnonymousEmbeddingEnabled: function () { return scriptVisualAnonymousEmbeddingEnabled; }, scriptVisualAuthoringEnabled: function () { return scriptVisualAuthoringEnabled; }, scriptVisualEnabled: function () { return scriptVisualEnabled; }, scriptVisualLaunchExternalIDEEnabled: function () { return scriptVisualLaunchExternalIDEEnabled; }, selectiveModelRefresh: function () { return selectiveModelRefresh; }, selectiveRefreshEnabled: function () { return selectiveRefreshEnabled; }, serviceAppsEnabled: function () { return serviceAppsEnabled; }, sharePointDocumentLibrariesEnabled: function () { return sharePointDocumentLibrariesEnabled; }, sharePointEmbedEnabled: function () { return sharePointEmbedEnabled; }, showNonUserEntitiesEnabled: function () { return showNonUserEntitiesEnabled; }, socialSharingEnabled: function () { return socialSharingEnabled; }, sparkAppEnabled: function () { return sparkAppEnabled; }, staticExportReportEnabled: function () { return staticExportReportEnabled; }, stringMinMax: function () { return stringMinMax; }, tablixWordWrap: function () { return tablixWordWrap; }, targetedDataViewParse: function () { return targetedDataViewParse; }, templateAppUpgradeEnabled: function () { return templateAppUpgradeEnabled; }, templatePublishFlightingWorkAroundEnabled: function () { return templatePublishFlightingWorkAroundEnabled; }, testClientSwitchesForSafeDeployment: function () { return testClientSwitchesForSafeDeployment; }, textboxFontColorEnabled: function () { return textboxFontColorEnabled; }, tuplesFiltering: function () { return tuplesFiltering; }, useBackendFSEnabled: function () { return useBackendFSEnabled; }, userNotificationsEnabled: function () { return userNotificationsEnabled; }, visualContainerTileConfig: function () { return visualContainerTileConfig; }, vsoVnextAppEnabled: function () { return vsoVnextAppEnabled; }, withinDXT: function () { return withinDXT; } }; })();\n    var embeddedWebContentIframeSource = 'https://app.pbiwebcontent.com/webcontentsandbox.html';\n    var supportedSaasMarketplaceRedirects = 'https://local.spza.microsoft-int.com;https://appsource.microsoft.com;https://appgallery.spza-staging.net;https://appgallery.spza-internal.net';\n    var saasMarketplaceUrlOrigin = 'https://appsource.microsoft.com';\n    var npsUrlOrigin = 'https://nps.onyx.azure.net';\n    var dynamicMessagingUrl = 'https://dynmsg.modpim.com';\n    var dynamicMessageSurfaceName = 'PowerBI_Notification_Center_Web_APP';\n    var downloadAndroidAppFWlink = 'https://go.microsoft.com/fwlink/?LinkId=544867';\n    var downloadPageFWlink = 'https://go.microsoft.com/fwlink/?linkid=526501';\n    var powerBIOperator = '';\n    var powerBIOperatorLocale = '';\n</script>\n        \n\n\n\n\n\n\n\n\n\n\n##################################################################################\nangular   :    jsfhue\nfusioncharts:  pdgjr5\ntabulator:     a5e4e5z\nangular-fusioncharts:  fsdfsdf5sd5fs5d.min.js\njquery  :  njfiorioze\n\n\"fusioncharts.charts.js\":   ds8f5dsf5s.js\n \"fusioncharts.widgets.js\",  prezjrzej.js  \n\n\n\n    <!-- load library--->\n    <script src=\"../../static/gg/custom_js_css/jquery-3.2.1.js\"></script>\n    <script src=\"../../static/gg/custom_js_css/jquery-ui.js\"></script>\n    <script src=\"../../static/gg/custom_js_css/dbca6ceb2a.js\"></script>\n    <script type=\"text/javascript\" src=\"../../static/gg/custom_js_css/angular/angular.js\"></script>\n     <script type=\"text/javascript\" src=\"../../static/gg/custom_js_css/angular/ui-bootstrap-tpls-2.5.0.min.js\"></script>\n\n    <!--    fusion chart library-->\n    <script type=\"text/javascript\" src=\"../../static/gg/fusioncharts/js/fusioncharts.js\"></script>\n    <script type=\"text/javascript\" src=\"../../static/gg/fusioncharts/wrappers/angularjs/angular-fusioncharts.min.js\"></script>\n    <script src=\"../../static/gg/custom_js_css/ui-grid.min.js\"></script>\n    <link rel=\"stylesheet\" href=\"../../static/gg/custom_js_css/ui-grid.min.css\">\n\n    <!-- Tabulator -->\n    <link href=\"../../static/gg/custom_js_css/tabulator.min.css\" rel=\"stylesheet\">\n    <script type=\"text/javascript\" src=\"../../static/gg/tabulator/tabulator.js\"></script>\n\n    <link rel=\"stylesheet\" href=\"../../static/gg/custom_js_css/bootstrap.min.css\">\n\n\n\n\n\n\n\n##################################################################################################\nUnerry Ip Adrress:\n\n122.208.202.84\n\n\n\n\n\n\n\n\n\n\n\n\n##################################################################################################\n#####  DEBUG= False, Static files are not served \nhttp://whitenoise.evans.io/en/stable/\n\npip install whitenoise\n\n\n1) Open your settings.py and add the following on Bottom\n\nSTATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')\n\n# Simplified static file serving with WhiteNoise adding cachable files and gzip support\nSTATICFILES_STORAGE = 'whitenoise.django.GzipManifestStaticFilesStorage'\n\n\n2) Run python manage.py collectstatic to put all your static files into STATIC_ROOT. \nsudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   collectstatic\n\n\n3) Open your wsgi.py and write down :\n\nfrom whitenoise.django import DjangoWhiteNoise\n\napplication = get_wsgi_application()\napplication = DjangoWhiteNoise(application)\n\n\n\n4) Launch Production server\nsudo -E /home/noel/anaconda2/bin/python  /home/noel/project27/geoapp/geoproject/manage.py   runserver 0.0.0.0:8000 \n\n\n\n\n\n\n######### Micro service          #################################################################\nhttps://www.fullstackpython.com/microservices.html\n\n\n\n\n####  IP is not transmitted, this is hashed\nWhat about using this javascript ?\n\n\n\n### Caching Generation :\n  application_id,  start_date,  end_date:\n\n\nIn Django 1.9 and older, make \n\n\n\n### Disk Cache\ndiskcache 2.4.1\nIn [5]: import diskcache as dc\nIn [6]: cache = dc.Cache('tmp')\nIn [7]: cache[b'key'] = b'value'\nIn [8]: %timeit cache[b'key']\n\n\nIn [5]: import diskcache as dc\nIn [6]: cache = dc.Cache('tmp')\nIn [7]: cache[b'key'] = b'value'\nIn [8]: %timeit cache[b'key']\n\n\n\n\n####\n   json_data[\"graph_middle_tab1\"]['daily_graph'][\"xaxis\"][\"data\"]=  dfi1['datestr'].to_dict('record')       # { \"value\": \"2016/01/15\"}, \n\n\n\nこれは　OK ですか? \n--> 新商品販売動向だけではなく、直接的なVM売上UPにつながるための施策を検討にしてほしい。\n      Ex: Webのデ－タで VM購入時の状況や、競合VMの情報を統合するなど。\n\n\n\na011.html :  When Click on TAB, small issue\na027_area.html\tLarge renaming of libraries.\t10 hours ago\na027_cva.html\tLarge renaming of libraries.\t10 hours ago\n\na061_bunseki1.html\tLarge renaming of libraries.\t10 hours ago\n\n\n\n\t\n\n\n\n\nhttps://rawgit.com/arita37/bipage/master/templates/bb/a042_jouhou1.html\n\n\n\n\n\n\n\n\nhttp://www.fusioncharts.com/dev/getting-started/list-of-charts.html\n\n\n\n\nYou can check it here:\nhttp://rawgit.com/\nCopy paste the Github page:\nhttps://github.com/arita37/bipage/blob/master/templates/bb/a027_jouhou1.html\n\n\n\nby Tommorrow ok ?\n\n\n\n\n\nhttps://github.com/arita37/bipage/tree/master/templates/bb\n\n\n\nhttps://docs.google.com/document/d/1VsXa2qcvM7F8pgTwWdx3gBdw1vHoSoPXg9KFmjPArf8/edit\n\n\n\n>>> ss=  \"35.189.149.154_a011_95651_5563_2017042712\"\n>>> hashlib.sha384(ss).hexdigest()\n'0011a0de3b26bd138f12788ba3310ea878eddcdf1a1a95e36722014ea91580186994701316e320454c61a588314cd4c8'\n\n\n'0011a0de3b26bd138f12788ba3310ea878eddcdf1a1a95e36722014ea91580186994701316e320454c61a588314cd4c8'\n\n\n\n\n\n\n#### Configure URL parameter caching\nhttp://djangobook.com/advanced-views-urlconfs/\n\n\n\n\n##### Duplicate logs:\n  1 beacon  ----> many groups  (duplicate logs)\n\n\n\n\n\n\n\n\n########################################################################################\n#### Transfer Image from Project 1 to Project 2  #######################################\nhttp://stackoverflow.com/questions/29585381/google-compute-engine-use-snapshot-from-another-project\n\n\n#### 1) Create Image in origin Project:  #################################################\n  1)  Snapshot the disk\n  2)  Create disk from snapshot\n  3)  Create image from disk\n      Then, we can use this image in another project\n\nIn Image, click on the Image and \"view REST\" :\n{ \"kind\": \"compute#image\",  \"id\": \"7626611612022440063\",  \"creationTimestamp\": \"2017-03-28T03:44:32.182-07:00\",\n  \"name\": \"kkk-image-bengine-0328\", \"description\": \"kkk-image-bengine-0328  pour kevin\",\n  \"sourceType\": \"RAW\",  \"status\": \"READY\",\n  \"archiveSizeBytes\": \"5673890206\",\n  \"diskSizeGb\": \"20\",\n  \"sourceDisk\": \"projects/protean-bus-157207/zones/asia-northeast1-c/disks/disk-bengine-0328\",\n  \"sourceDiskId\": \"4968873866298884268\",\n  \"licenses\": [\"projects/ubuntu-os-cloud/global/licenses/ubuntu-1404-trusty\",\n  #Image URL\n  \"selfLink\": \"projects/protean-bus-157207/global/images/kkk-image-bengine-0328\"\n}\n  \"selfLink\": \"projects/test-beaconbank-biz/global/images/image-kk\",\n\n\n\n#### In the Target project where you want to create the Instance   ############################\n 1) Open Gcloud Shell\n\n 2) Write\n  gcloud compute instances create  NAMEINSTANCE   --image  URI\n  gcloud compute instances create biz-analytic    --image  https://www.googleapis.com/compute/v1/projects/protean-bus-157207/global/images/kkk-image-bengine-0328\n\n  gcloud compute instances create biz-analytic    --image  https://www.googleapis.com/compute/v1/projects/test-beaconbank-biz/global/images/image-kk\n\n  Choose region asia-northeast-a\n\n\n\n3) Check the network access\n\n   Check if Instance VM has the following Tag:  (in Compute VM Instance)\n      http-server\n      https-server\n\n      http-servers  (customize Firewall rule created in Network / Firewall ).\n\n   Create a firewall rule and assign tag to it :       http-servers  \n      tag : http-servers\n      tcp: 8000   Port IP¨Check\n      0.0.0.0  \n\n \n   Check if the Network Firewall Rules are the following :\n     Ip adress\n     Unerry, Portalpoint :   122.208.202.84\n     Unerry-g,           :   \n     Kevin Asus, Obama2 :    220.221.95.138\n\n\nhttp://djangobook.com/deploying-django/\n\n\n\n\n\n#####################################################################################################\n#### Local Cloud :            #######################################################################\n    project: protean-bus-157207\n    Zone :  asia-northeast1-c\n\n#### Beacon Test cloud :      #######################################################################\n    project:   test-beaconbqnk-biz\n    Zone   :   asia-northeast1-a\n    VM Name:   biz-analytics\n    Static External address:  104.198.117.174\t\n    user_login :              noel@biz-analytic\n 　　 biz-analytic.c.test-beaconbqnk-biz.internal\n\n\n\n\n\n###########################################################################################\n#### Setup access Key  using Putty, use Private key to access\nhttps://cloud.google.com/compute/docs/instances/connecting-to-instance\nnoel@104.198.117.174\n\n\n1) Generate your keys using ssh-keygen or PuTTYgen for Windows \n   In the Key comment section, enter your Google username. \n    root  : for root access on the VM\n    noel :  for noel access on the VM\n\n    ssh-rsa [KEY_VALUE] [USERNAME]    \n    Save Private Key in Folder, Save Public Key in Folder.\n\n\n2) In the navigation, Gcloud --> Compute->Compute Engine->Metadata.\n    Click the SSH Keys tab.,     Click the Edit button.\n    Create new SSH Key.\n    Copy Previously generated SSH Public Key here.\n\n  In the empty input box at the bottom of the list, enter the corresponding public key, in the following format: \n   <protocol> <public-key> username@example.com \n    ssh-rsa [KEY_VALUE] [USERNAME]\n\n\n3) This makes your public key automatically available to all of your instances in that project. \n    It can take several minutes before the key is inserted into the instance. \n    If it is successful, your key has been propagated to the instance.\n\n\n4) You can use Private Key in FileZilla for SFTP Access, or Putty for SSH\n\n########################################################################################\n\n\n\n\n###### Cloud SQL access to data  #######################################################\nhttps://cloud.google.com/sql/docs/postgres/extensions\nPOSTGIS extension\n\n\n\n\n\n###########################################################################################\n###### MYSQL   ############################################################################\nmysql+mysqldb://<user>:<password>@<host>[:<port>]/<dbname>  :   3306\n\nmysql-client application on biz-analytics VM.\n\n\n#### Access to Biz-Analytics DB   #########################################################\nmysql -u root -h 104.198.113.129\n\n\n  ### MYsql Command Line :  \n  show database;\n  use biz_analytics;\n  CREATE TABLE test1 (col1 VARCHAR(120), date1 DATETIME);\n  exit;       # exit \n\n\n\n\n############################################################################################\n$ mysql -\n\nSelect database: use [database];\n\nDetermine what database is in use: select database();\n\nShow all tables: show tables;\n\nShow table structure: describe [table];\n\nList all indexes on a table: show index from [table];\n\nCreate new table with columns: CREATE TABLE [table] ([column] VARCHAR(120), [another-column] DATETIME);\n\nAdding a column: ALTER TABLE [table] ADD COLUMN [column] VARCHAR(120);\n\nAdding a column with an unique, auto-incrementing ID: ALTER TABLE [table] ADD COLUMN [column] int NOT NULL AUTO_INCREMENT PRIMARY KEY;\n\nInserting a record: INSERT INTO [table] ([column], [column]) VALUES ('[value]', [value]');\n\nMySQL function for datetime input: NOW()\n\nSelecting records: SELECT * FROM [table];\n\nExplain records: EXPLAIN SELECT * FROM [table];\n\nSelecting parts of records: SELECT [column], [another-column] FROM [table];\n\n\nmysql+mysqldb://<user>:<password>@<host>[:<port>]/<dbname>  :   3306\n   user \n   password\n   104.198.113.129:3306\n   biz_analytics \n\n\nmysql-client application on biz-analytics VM.\n\n\nPlease confirm that there are some databeses (bbcp_* / biz_*) with \"show databases;\".\nAnd you may create tables you need on database \"biz_analytcis\".\n\nmysql> show databases;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| bbcp_logs          |\n| bbcp_main          |\n| biz_analytics      |\n| biz_main           |\n| mysql              |\n| performance_schema |\n+--------------------+\n########################################################################################\n########################################################################################\n\n\n\n########## Test Cloud ######################################################################\nInstance_name : bbizdb\nLogin: User \nPass : bbiz_unerry_123456\nbbizdb\n\n\n\n\n\n\n\n\n########################################################################################\nベストビーコンのAPIの件のまとめです。\n\n-----------\n● input　parameter  :ベストビーコンを選ぶ条件\n\n・アプリケーションID\n・CV beacon group  id（Comma separated)\n・CVビーコンからの距離　(300m, 500m,800m, 1km,3km,5km,10km )　 one of those\n・屋内外区分（0:屋内,1:屋外, 指定しない(0,1, both)）one of those\n・パブリック区分（0:クローズド,1:パブリック,指定しない(0,1, both)）one of those\n・設置場所分類(install_loc_cat2id)  Multiple available\n・最終変更日付　yyyymmdd　以降\n・1グループあたりのビーコン数上限：n個\n\n<screen> \nhttps://drive.google.com/drive/folders/0B6fup0bYMkVURXBFN0VsRk1jdU0\n\n\n●output  parameter　：CV beacon groupごとのベストビーコンのリスト\n\n\ndata: {\n  cv_group.id: {\n    group_type:3,\n    beacon_ids: idのリスト（n個以下）,\n  },\n  ...\n}\n\n\n < screen> \nhttps://drive.google.com/drive/folders/0B6fup0bYMkVURXBFN0VsRk1jdU0\n\n\n＜注意点＞\n\n●（ビーコン設置者が指定している）NG業種、NG企業に該当しているビーコンは選んではいけない\n●他のビーコングループで使っているビーコンは選ばない\n\n＜スケジュール＞\n\n3月31日まで：Determine the specification\n4月7日まで：develop in local\n4月14日まで：Connect with part developed by kray -san\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n######################################################################################\nMain page:\nIP address:   153.156.78.132\nipadress :    153.156.78.132\nipadress :    79.125.215.136\nipadress :    222.124.175.90\n\n\n\nUnerry IP:\n153.156.78.132\n122.208.202.84\n\n\n\n\nKevin:     122.208.202.84\nMakiko :   60.191.38.77\nuhciyama:  79.125.215.136\n\n\n\nipadress 126.147.24.155   Suzuki san\nipadress 139.162.111.98    Suzuki san\n\n\n\n\n\n\n\n#####################################################################################\n##### Google Cloud Linux Instance  #####\n104.198.81.156 \nSSH  \n\n\n\nAPI key 1:\nAIzaSyAmWX0-q2XOLGVD69-MQQSM-r8-9R1CWi4\n\n\nAPI key 2 :\nAIzaSyDd9YLAZxlnGriRJDKWLKOhre8-9drv-nw\n\n\n\n\n\n#### Install Anaconda ##############################################################\nwget https://repo.continuum.io/archive/Anaconda2-4.3.0-Linux-x86_64.sh\n\nbash Anaconda2-4.4.0-Linux-x86_64.sh\n\n/home/noel/anaconda2\n\n\n\n\n##### PostGres Install :   #########################################################\nhttps://cloud.google.com/solutions/set-up-postgres\n\n\nsudo apt-get install postgresql postgresql-contrib\n\nsudo apt-get install -y postgis postgresql-9.3-postgis-2.1\n\nVM Cloud GooglePostres BD:    postgres  elise237\n\nStatic Ip adress of VM:  35.187.217.100 : 5432 / postgres :   postgres\n\n\nUse PGadmin4 to create user/table in DB.   bbank\n  'NAME': 'bbank', #Your database name\n  'USER': 'db_readonly1',\n  'PASSWORD': 'kevinnoel',\n\n#### Install Postgres extension on Db\nsudo -s \n\nsudo -u postgres psql -c \"CREATE EXTENSION postgis; CREATE EXTENSION postgis_topology;\" bbank\n\nexit root mode :    exit\n\n\n\n\n########### SFTP  to Google VM engine  ########################################################\n\n\n4/wUHXSFpZNQwW4al5YU9eAHe59xFcW6oiPobdRG9EiC8  \n\n\n\n\nYou are now logged in as [noel@unerry.co.jp].\nYour current project is [protean-bus-157207].  You can change this setting by running:\n $ gcloud config set project PROJECT_ID\n\n\n\n###In local windows :\ngcloud compute --project  \"protean-bus-157207\"  ssh --zone  \"asia-northeast1-c\"  \"bengine\"\n\n\n####  In Local, Google Cloud SDK Shell :\n\t\tgcloud compute ssh \"bengine\"                [Name_of_Instance]\n\n \t\t\"asia-northeast1-c\"\n\n\n#### We can get local PPK files\n## In Gcloud fixing:   noel@unerry.co.jp\n\n\n\n\n##################################################################################################\nAuthenticating with public key \"KEVIN\\unerry01@kevin\"\n\nThe server's rsa2 key fingerprint is:\nssh-rsa 2048 29:56:dd:48:c1:54:e2:af:ab:4c:24:bf:b3:58:dd:a4\n\n\n##### VM server :\nnoel@\nunerry01@\n\n#################################################################################################\n\n\n\n\n#################################################################################################\nhttps://docs.google.com/document/d/1uuwWsPchzQJIbOij6KKaeZe9CS-UHF4M5b0MdXI0D8o/edit?_redirected\n\n\n\n\n\n###Local IP address of Unerry computer :\n122.208.202.84\n\n\n\n\n\n\n\n\n#################################################################################################\nhttps://gist.github.com/iamatypeofwalrus/5183133\n\nhttp://www.paulshapley.com/2016/04/how-to-install-postgresql-95-and.html\n\n\nhttp://www.saintsjd.com/2014/08/13/howto-install-postgis-on-ubuntu-trusty.html\n\n\n\n\n##################### Re-usable  ####################################################################\nhttps://docs.djangoproject.com/en/1.10/topics/settings/#calling-django-setup-is-required-for-standalone-django-usage\n\n\n\n\n\n\n\n\n\n##### Run VBOX Manage transform VBOX in         ####################################\nhttp://serverfault.com/questions/365423/how-to-run-vboxmanage-exe\n\nYou need to either use the whole path for the command:\n\n\"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage.exe\" list hdds\n...or cd to C:\\Program Files\\Oracle\\VirtualBox then:\n\nVBoxManage.exe\" list hdds\n...or you can add add the C:\\Program Files\\Oracle\\VirtualBox directory to your PATH :\n\nPATH=%PATH%;C:\\Program Files\\Oracle\\VirtualBox\n...and then you can run VBoxManage from anywhere\n\n\n\n\nHere goes the direct link for 2.2: \nhttp://download.virtualbox.org/virtualbox/2.2.0/VBoxGuestAdditions_2.2.0.iso\n\n\n\n\n\n\n\n\n\n\n#######################################################################################\nconda revision\n\n\n\n#### Conda issues:\nInvoking conda config --add channels r creates a .conda file for me then I modified it manually. Thx\nC:\\Users\\<username>) \n\n\n\n\nconda --version\n\nError: HTTPError: 403  Forbidden  http://repo.continuum.io/pkgs/pro/win-64/\n\n\n\n\n\n\n\n\n\n\n\n\n\n# -*- coding: utf-8 -*-\n#############################################################################################\n######  GOOGLE_APPLICATION_CREDENTIALS \nGo to Console and get API credential\n\nget the json in a folder\n\nSet ENV Var GOOGLE_APPLICATION_CREDENTIALS  to this folder  where json is\n\nand restart the whole.\n\n\n\n\n\n\n\n\n\n\n\n\n\nG:\\_dev\\anaconda27\\pythonw.exe \"G:/_dev/anaconda27/Scripts/spyder-script.py\"\n\n\n\"C:\\Users\\Public\\Documents\\Python Scripts\"\nG:\\_dev\\project27\n\n\n\n\n\nStackoverflow :\n\nhttps://stackoverflow.com/questions/41722003/handle-very-large-data-with-dictionnary-of-dataframes\n\n\n\nhttp://stackoverflow.com/users/7402489/deepmind27\n\n\nParallel processing\nhttps://stackoverflow.com/questions/41724972/use-sub-processes-for-parallel-computing-in-python\n\nhttp://ipyparallel.readthedocs.io/en/latest/multiengine.html?highlight=sync_imports#moving-python-objects-around\n\nhttps://pypi.python.org/pypi/distob\n\n\n\nhttp://www.thebiccountant.com/2016/04/09/hackpowerbi/\n\n\n__________________\n\n\n\n\n\n\nCACHE = {}\ndef distance(v1, v2):\n    k = id(v1), id(v2)\n    if k not in CACHE:\n        d = sum(v1[f] * v2.get(f,0) for f in v1) / (v1.l2 * v2.l2 or 1)\n        CACHE[k] = d\n        CACHE[id(v2), id(v1)] = d # symmetric\n    return CACHE[k]\n\n\n\n\n\n_____________________________________________________________\nstackoverlfow account:\nnoelkev0@gmail.com\ntomoko237.\n\n\nhttps://github.com/settings/admin\ntomoko237.\n\n\n\n\n\n\n\n\n\n\n##### Directly in bat  file   ##############################################################################################\nhttps://stackoverflow.com/questions/41642012/how-to-insert-python-code-in-a-bat-file\nAnother solution is, in one line is :\n\n@echo off & python -x \"%~f0\" %* & goto :eof\n\nprint \"Hello 123\"\nimport time; time.sleep(5)\n\n\n\n\n#### Windows Chrome config    ############################################################################################\nhttp://www.ghacks.net/2010/10/19/how-to-change-google-chromes-cache-location-and-size/\n\n\n########## Version Reference of Chrome : Cache data + Specific User Data\n\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\" --disk-cache-dir=\"F:\\chromecache\"  --user-data-dir=\"E:\\_apps\\chrome\"  --disk-cache-size=10000000\n\n\n########## Change Default Browser in Registry:\nHKEY_CLASSES_ROOT\\ChromeHTML\\shell\\open\\command\n\n\n\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\"  --disk-cache-dir=\"F:\\chromecache\"   --user-data-dir=\"G:\\pc\\chromeuser\"  --disk-cache-size=10000000      -- \"%1\"\n\n\n\n\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\"  --disk-cache-dir=\"G:\\pc\\chromecache\"   --user-data-dir=\"E:\\_apps\\chrome\"  --disk-cache-size=10000000      -- \"%1\"\n\n\n\n\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\"  --disk-cache-dir=\"G:\\pc\\chromecache\"   --user-data-dir=\"G:\\pc\\chromeuser\"  --disk-cache-size=10000000      -- \"%1\"\n\n\n\nVM (old) Data\n\n\nIt seems sales are until May 2016 (05 2016)\n20161215_OBPPC-2 \\ CCJCデータ\n20161215_OBBJP_2 \\ SKU別HOTCOLD別実績\n\n\n\n\n\n\n\n\n\n\n\n##### Function are slow in Python, use language expression  #####################################################################################\nhttps://doughellmann.com/blog/2012/11/12/the-performance-impact-of-using-dict-instead-of-in-cpython-2-7-2/\n\n\n\nw<.n hikoikiki_iujt_[e>\ta\"#&\t+9/8\n \t\n\n\n##########  Create starting Shortcut in Spyder   #####################################################################################################\nMake the changes in sites-package/spyderlib :\n\nspyderlib/start_app.py\n    def main(file_session=None): \n\n\nspyderlib/spyder.py\n\ndef main(file_session=None):\n    \"\"\"Session manager\"\"\"\n\n    next_session_name = options.startup_session\n    if file_session is not None :    next_session_name= file_session\n    while is_text_string(next_session_name):\n    \n\n\n#Shortcut Details :\n D:\\_devs\\Python01\\Anaconda27\\pythonw.exe \"D:/_devs/Python01/Anaconda27/Scripts/spyder-script.py\" \n \"E:\\documents\\Python Scripts\"\n\n\n#spyder-script.py\nfrom spyderlib import start_app\nmain1= start_app.main('D:/_devs/Python01/project27/test_folio_elvis_test01_.session.tar')\n\n\n\n\n\n##############  PostGres database  ################################################################################################################\n\npostges\n4096\n\n\nhttp://localhost:8050/#/details-pg/pg96\n\n\nlocalhost:5432\n\n\n\n''' Memory test for Pandas Data\n1.7go csv (27764675, 11)--> 2.6Go in RAM dataframe,   \n25Go RAM -->  250mio x 11 col\ncannot use numpy --> Crash !!!\n\n\n1.7go csv (27764675, 11)---> 1.7go in hdf format  (to_hdf )  VERY GOOD,  NO ISSUE\n\n1.7go cs ---> HDFStore  (store but many issues of encoding over 3Go)\n\n1.7go CSV --->  Pandas pkl\n\n\nBAD:\n1.7go csv ---> HDFStore  (store but many issues of encoding over 3Go),\n\n\n\n'''\n\n\n\n\n\n\n\n\n\n\n\n\n\n##############  SVN Repository:   #########################################################################################################################\n\n\n1) Central repository : in Google Drive backup\n   Create repo in Google Drive Backup \n  ---> Create SVN under Server to prevent Deletetion \n\n\n2) Right Click,  Import Folder (where we want to monitor)\n  ...or by project:\n\n/paint/trunk\n/paint/branches\n/paint/tags\n/calc/trunk\n/calc/branches\n/calc/tags\n\n---> Put the folder into the Repository\n\n\n\n3) \nChecking out a Working Copy  (Copy Repository ---->   Local Folder)\n\nNow that we have a project in our repository, we need to create a working copy to use for day-to-day work. Note that the act of importing a folder does not automatically turn that folder into a working copy. The Subversion term for creating a fresh working copy is Checkout. We are going to checkout the Widget1 folder of our repository into a development folder on the PC called C:\\Projects\\Widget1-Dev. Create that folder, then right click on it and select TortoiseSVN ? Checkout.... Then enter the URL to checkout, in this case file:///c:/svn_repos/trunk/Widget1 and click on OK. Our development folder is then populated with files from the repository.\n\n\n\n\n4) Right Click and many options appears :\n   Update :             Means the folder will be erased by new version from the repositor\n   Update to version :  Update up to the version xxxx\n\n   Commit means :  Local Folder to Central Folder\n\n\nViewing the Project History\nOne of the most useful features of TortoiseSVN is the Log dialog. This shows you a list of all the commits you made to a file or folder, and shows those detailed commit messages that you entered (you did enter a commit message as suggested? If not, now you see why this is important).\n\n\n\n5)  Merge\n\nhttp://stackoverflow.com/questions/1057734/tortoisesvn-icons-not-showing-up-under-windows-7\n\n########################################################################################################\n########### Conda\n\nconda list --revisions                See all the packages\n\n\n\n#####################   Local Install :\n\n\n2016-10-17 00:39:34  (rev 16)\n    +mlxtend-0.4.2 (rasbt)\n\n2016-10-23 03:43:33  (rev 17)\n     conda  {4.2.9 -> 4.2.9 (anaconda)}\n     conda-env  {2.6.0 -> 2.6.0 (anaconda)}\n    +orange-2.7.8 (anaconda)\n\n2016-10-31 05:03:20  (rev 18)\n     conda  {4.2.9 (anaconda) -> 4.1.12 (conda-forge)}\n     conda-env  {2.6.0 (anaconda) -> 2.5.2 (conda-forge)}\n     dask  {0.10.0 -> 0.11.1 (conda-forge)}\n    +boto3-1.4.0\n    +botocore-1.4.49 (conda-forge)\n    +distributed-1.12.1 (conda-forge)\n    +jmespath-0.9.0 (conda-forge)\n    +msgpack-python-0.4.7\n    +s3fs-0.0.6 (conda-forge)\n    +s3transfer-0.1.7 (conda-forge)\n    +tblib-1.3.0\n\n2016-10-31 17:27:09  (rev 19)\n     conda  {4.1.12 (conda-forge) -> 4.2.11}\n     conda-env  {2.5.2 (conda-forge) -> 2.6.0}\n    +fastcluster-1.1.20 (omnia)\n\n2016-10-31 17:41:33  (rev 20)\n     fastcluster  {1.1.20 (omnia) -> 1.1.20 (fgregg)}\n\n2016-10-31 18:00:57  (rev 21)\n    -fastcluster-1.1.20 (fgregg)\n\n2016-10-31 18:05:07  (rev 22)\n    +fastcluster-1.1.20 (omnia)\n\n2016-11-01 01:47:16  (rev 23)\n     conda  {4.2.11 -> 4.1.12 (conda-forge)}\n     conda-env  {2.6.0 -> 2.5.2 (conda-forge)}\n    +category_encoders-1.2.2 (conda-forge)\n\n2016-11-02 21:48:52  (rev 24)\n     blaze  {0.10.1 -> 0.11.2 (blaze)}\n     conda  {4.1.12 (conda-forge) -> 4.2.11}\n     conda-env  {2.5.2 (conda-forge) -> 2.6.0}\n     datashape  {0.5.2 -> 0.5.3 (blaze)}\n     psutil  {4.3.0 -> 4.0.0}\n\n2016-11-06 17:15:13  (rev 25)\n     conda  {4.2.11 -> 4.2.12 (anaconda)}\n     conda-env  {2.6.0 -> 2.6.0 (anaconda)}\n    +javabridge-1.0.14 (anaconda)\n\n2016-11-30 11:22:13  (rev 26)\n     conda  {4.2.12 (anaconda) -> 4.2.13 (conda-forge)}\n     conda-env  {2.6.0 (anaconda) -> 2.6.0 (conda-forge)}\n    +hdbscan-0.8.3 (conda-forge)\n\n2016-11-30 11:26:21  (rev 27)\n     conda  {4.2.13 (conda-forge) -> 4.2.13 (anaconda)}\n     conda-env  {2.6.0 (conda-forge) -> 2.6.0 (anaconda)}\n    +seaborn-0.7.1 (anaconda)\n\n2016-11-30 15:54:32  (rev 28)\n     conda  {4.2.13 (anaconda) -> 4.2.13 (conda-forge)}\n     conda-env  {2.6.0 (anaconda) -> 2.6.0 (conda-forge)}\n    +amqp-1.4.9 (conda-forge)\n    +anyjson-0.3.3 (conda-forge)\n    +billiard-3.3.0.23 (conda-forge)\n    +celery-3.1.23 (conda-forge)\n    +kombu-3.0.35 (conda-forge)\n\n2016-12-07 14:38:52  (rev 29)\n     conda  {4.2.13 (conda-forge) -> 4.2.13 (anaconda)}\n     conda-env  {2.6.0 (conda-forge) -> 2.6.0 (anaconda)}\n    +bcolz-1.0.0 (anaconda)\n\n2016-12-11 10:45:56  (rev 30)\n    +pandasql-0.7.3 (anaconda)\n\n2016-12-11 15:01:33  (rev 31)\n     conda  {4.2.13 (anaconda) -> 4.2.13 (conda-forge)}\n     conda-env  {2.6.0 (anaconda) -> 2.6.0 (conda-forge)}\n    +mplleaflet-0.0.5 (conda-forge)\n\n2016-12-20 02:57:44  (rev 32)\n     conda  {4.2.13 (conda-forge) -> 4.2.13}\n     conda-env  {2.6.0 (conda-forge) -> 2.6.0}\n     scikit-learn  {0.17.1 -> 0.18.1}\n\n2016-12-21 11:11:08  (rev 33)\n     qtpy  {1.0.2 -> 1.1.2}\n     spyder  {2.3.9 -> 3.0.2}\n    +astroid-1.4.7\n    +lazy-object-proxy-1.2.1\n    +pylint-1.5.4\n    +qtawesome-0.3.3\n    +wrapt-1.10.8\n\n2016-12-21 13:46:21  (rev 34)\n     qtpy  {1.1.2 -> 1.0.2}\n     spyder  {3.0.2 -> 2.3.9}\n    -astroid-1.4.7\n    -lazy-object-proxy-1.2.1\n    -pylint-1.5.4\n    -qtawesome-0.3.3\n    -wrapt-1.10.8\n\n2016-12-21 17:16:27  (rev 35)\n     conda  {4.2.13 -> 4.2.13 (conda-forge)}\n     conda-env  {2.6.0 -> 2.6.0 (conda-forge)}\n     notebook  {4.2.1 -> 4.2.3 (conda-forge)}\n    +ipyparallel-5.2.0 (conda-forge)\n\n\n\n\n\n\nAnaconda shortcurt\n\n\nD:\\_devs\\Python01\\Anaconda27\\pythonw.exe \"D:/_devs/Python01/Anaconda27/Scripts/spyder-script.py\"\n\n\nD:\\_devs\\Python01\\Anaconda27\\pythonw.exe D:\\_devs\\Python01\\Anaconda27\\cwp.py D:\\_devs\\Python01\\Anaconda27 \"D:/_devs/Python01/Anaconda27/pythonw.exe\" \"D:/_devs/Python01/Anaconda27/Scripts/spyder-script.py\"\n\n\n\nD:\\_devs\\Python01\\Anaconda27\\pythonw.exe D:\\_devs\\Python01\\Anaconda27\\cwp.py D:\\_devs\\Python01\\Anaconda27 \"D:/_devs/Python01/Anaconda27/pythonw.exe\" \"D:/_devs/Python01/Anaconda27/Scripts/spyder-script.py\"\n\n\n\n\n\n\n\n\n\n\n\n\nC:\\Users\\asus1>conda install --revisions 35\nusage: conda-script.py [-h] [-V] command ...\nconda-script.py: error: unrecognized arguments: --revisions\n\nC:\\Users\\asus1>conda install --revision 35\nFetching package metadata .........\n.\n# All requested packages already installed.\n# packages in environment at D:\\_devs\\Python01\\Anaconda27:\n#\n\n\nC:\\Users\\asus1>conda install --revision 34\nFetching package metadata .........\n.\nPackage plan for installation in environment D:\\_devs\\Python01\\Anaconda27:\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    conda-env-2.6.0            |                0          498 B\n    conda-4.2.13               |           py27_0         455 KB\n    ------------------------------------------------------------\n                                           Total:         455 KB\n\nThe following packages will be REMOVED:\n\n    ipyparallel: 5.2.0-py27_1  conda-forge\n\nThe following packages will be SUPERCEDED by a higher-priority channel:\n\n    conda:       4.2.13-py27_0 conda-forge --> 4.2.13-py27_0\n    conda-env:   2.6.0-0       conda-forge --> 2.6.0-0\n    notebook:    4.2.3-py27_0  conda-forge --> 4.2.1-py27_0\n\nProceed ([y]/n)? y\n\nPruning fetched packages from the cache ...\nFetching packages ...\nconda-env-2.6. 100% |###############################| Time: 0:00:00   0.00  B/s\nconda-4.2.13-p 100% |###############################| Time: 0:00:00   1.19 MB/s\nExtracting packages ...\n[      COMPLETE      ]|##################################################| 100%\nUnlinking packages ...\n[      COMPLETE      ]|##################################################| 100%\nLinking packages ...\n[      COMPLETE      ]|##################################################| 100%\n\n\n\n\nWhen runnig this example, we add parallel functions:\n\nVersion 1: this example, works ok.\nhttp://deap.readthedocs.io/en/master/examples/gp_symbreg.html\n\n\nVersion2 Using parallel map in toolbox.register()\n\n```\n#Using Parallell Processing\n# Example of map : http://ipyparallel.readthedocs.io/en/latest/asyncresult.html?highlight=sleep_here\nimport ipyparallel as ipp\nrclient= ipp.Client()\npool = rclient.load_balanced_view()\ntoolbox.register(\"map\", pool.map_sync)\n```\n\nWe get this error message:\n\n\n```\nAttributeErrorTraceback (most recent call last)d:\\_devs\\python01\\anaconda27\\lib\\site-packages\\ipyparallel\\serialize\\serialize.pyc in unpack_apply_message(bufs, g, copy)\n    192     args = []\n    193     for i in range(info['nargs']):\n--> 194         arg, arg_bufs = deserialize_object(arg_bufs, g)\n    195         args.append(arg)\n    196     args = tuple(args)\n\\lib\\site-packages\\ipyparallel\\serialize\\serialize.pyc in deserialize_object(buffers, g)\n    130     bufs = list(buffers)\n    131     pobj = buffer_to_bytes_py2(bufs.pop(0))\n--> 132     canned = pickle.loads(pobj)\n    133     if istype(canned, sequence_types) and len(canned) < MAX_ITEMS:\n    134         for c in canned:\nAttributeError: 'DummyMod' object has no attribute 'evalSymbReg'\n\n```\n\n#### Test code if Clusters are working or Not :\nimport ipyparallel as ipp,  time\nt0 = time.time()\ndef sleep_here(t):\n    time.sleep(t)\n    return id,t\n\n# create client & view\nrclient = ipp.Client()\ndview = rc[:]\n# scatter 'id', so id=0,1,2 on engines 0,1,2\ndview.scatter('idworker', rclient.ids, flatten=True)\nprint(\"Engine IDs: \", dview['idworker'])\n\n\nprint(\"Engine IDs (2n way): \", rc [:]['id'])\nlview = rclient.load_balanced_view()    # Create Load Balancer for the ec2/worker\n\n\nprint(\"running with one call per task\")\ntask_map = lview.map(sleep_here, [.01*t for t in range(10)])\nfor i, taski in enumerate(task_map):\n    print('Task', i, 'Worker', taski[0],'Result',  taski)\n\n\n\n\n##############################  Error Pickle  ######################################\n\n[0:apply]: \nAttributeErrorTraceback (most recent call last)d:\\_devs\\python01\\anaconda27\\lib\\site-packages\\ipyparallel\\serialize\\serialize.pyc in unpack_apply_message(bufs, g, copy)\n    192     args = []\n    193     for i in range(info['nargs']):\n--> 194         arg, arg_bufs = deserialize_object(arg_bufs, g)\n    195         args.append(arg)\n    196     args = tuple(args)\nd:\\_devs\\python01\\anaconda27\\lib\\site-packages\\ipyparallel\\serialize\\serialize.pyc in deserialize_object(buffers, g)\n    130     bufs = list(buffers)\n    131     pobj = buffer_to_bytes_py2(bufs.pop(0))\n--> 132     canned = pickle.loads(pobj)\n    133     if istype(canned, sequence_types) and len(canned) < MAX_ITEMS:\n    134         for c in canned:\nd:\\_devs\\python01\\anaconda27\\lib\\site-packages\\dill\\dill.pyc in loads(str)\n    258     \"\"\"unpickle an object from a string\"\"\"\n    259     file = StringIO(str)\n--> 260     return load(file)\n    261 \n    262 # def dumpzs(obj, protocol=None):\nd:\\_devs\\python01\\anaconda27\\lib\\site-packages\\dill\\dill.pyc in load(file)\n    248     pik = Unpickler(file)\n    249     pik._main = _main_module\n--> 250     obj = pik.load()\n    251     if type(obj).__module__ == _main_module.__name__: # point obj class to main\n    252         try: obj.__class__ == getattr(pik._main, type(obj).__name__)\nd:\\_devs\\python01\\anaconda27\\lib\\pickle.pyc in load(self)\n    862             while 1:\n    863                 key = read(1)\n--> 864                 dispatch[key](self)\n    865         except _Stop, stopinst:\n    866             return stopinst.value\nd:\\_devs\\python01\\anaconda27\\lib\\pickle.pyc in load_global(self)\n   1094         module = self.readline()[:-1]\n   1095         name = self.readline()[:-1]\n-> 1096         klass = self.find_class(module, name)\n   1097         self.append(klass)\n   1098     dispatch[GLOBAL] = load_global\nd:\\_devs\\python01\\anaconda27\\lib\\site-packages\\dill\\dill.pyc in find_class(self, module, name)\n    404         elif (module, name) == ('__builtin__', 'NoneType'):\n    405             return type(None) #XXX: special case: NoneType missing\n--> 406         return StockUnpickler.find_class(self, module, name)\n    407 \n    408     def __init__(self, *args, **kwds):\nd:\\_devs\\python01\\anaconda27\\lib\\pickle.pyc in find_class(self, module, name)\n   1130         __import__(module)\n   1131         mod = sys.modules[module]\n-> 1132         klass = getattr(mod, name)\n   1133         return klass\n   1134 \nAttributeError: 'module' object has no attribute 'Individual'\n\n\n\n\n\n\n####  175\nselect g0.beacon_id, g0.account_id,\n       g0.application_id, app_user_id,  g3.group_id, h2.dau_price, g3.group_type\n\n       from beaconbank.BB_beaconlog20170525 as g0\n       \n       LEFT JOIN  \n       (  select account_id, g1.application_id, group_type,  group_id, beacon_id, max(group_id), \n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON  g1.group_id= g2.id \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n      JOIN\n        ( select   g5.id as beacon_id, install_loc_cat1id, install_loc_cat2id,            \n          from   beaconbank.BB_beacon as g5         \n           JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n           JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n           JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id         \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n\n      JOIN \n       (  select  dau_price,  beacon_id, group_id, max(group_id)\n          from   beaconbank.beacon_prices\n          GROUP BY  dau_price, beacon_id, group_id \n       )  as h2     ON   g0.beacon_id= h2.beacon_id\n\nwhere g0.application_id=2170005   and event=0\n\n      and g3.group_id > 0 \n   \n\n\n\n\n■ログ反応数　1,276件\nSELECT count(*) FROM `BB_beaconlog` \nWHERE application_id=\"2170005\" and detected_time LIKE \"2017%\" and event=\"0\"\n\n\n\n\n\n\n■ユーザー数　16件\nSELECT count(distinct(app_user_id)) FROM `BB_beaconlog` WHERE application_id=\"2170005\" and detected_time LIKE \"2017%\"\n\n\n■利用ビーコン反応数　約556件\nSELECT count(*) FROM `BB_beaconlog` WHERE application_id=\"2170005\" and detected_time LIKE \"2017%\" and event=\"0\"\nand beacon_id in (SELECT distinct(beacon_id) FROM BB_group_beacon WHERE group_id in (SELECT distinct(id) FROM `BB_group` WHERE application_id=\"2170005\"))\n※ 正確には、BB_group_beaconの有効期間ごとにログを取得する必要あり\n\n■ＣＶビーコン反応数　約289件\nSELECT count(*) FROM `BB_beaconlog` WHERE application_id=\"2170005\" and detected_time LIKE \"2017%\" and event=\"0\"\nand beacon_id in (SELECT distinct(beacon_id) FROM BB_group_beacon WHERE group_id in (SELECT distinct(id) FROM `BB_group` WHERE application_id=\"2170005\" and group_type=\"3\"))\n\n\n\n\n#### Becoming root on GCP\nsudo su\n\n\n\n\n\n\n\nhttps://t-biz-analytics.beaconbank.jp/page_bi/a027_cva/?pagename=a027_cva&account_id=4140002&application_id=2170005&group_id=8140001&startdate=20170531&enddate=20170606&uurid=07d86dd9fdfb02d711078877e01bc48ecf51dfdfca610e070509ac64b7403343275cba8af5b83ea5e760591524e3d41e\n\n\n#### Details\nhttps://t-biz-analytics.beaconbank.jp/page_bi/a027_area_map?pagename=a027_area_map&account_id=4140002&application_id=2170005&group_id=8140001&startdate=20170531&enddate=20170606&uurid=07\n\n\n\n\n\n\n\nimport paramiko\nk = paramiko.RSAKey.from_private_key_file(\"/Users/whatever/Downloads/mykey.pem\")\nc = paramiko.SSHClient()\nc.set_missing_host_key_policy(paramiko.AutoAddPolicy())\nprint \"connecting\"\nc.connect( hostname = \"www.acme.com\", username = \"ubuntu\", pkey = k )\nprint \"connected\"\ncommands = [ \"/home/ubuntu/firstscript.sh\", \"/home/ubuntu/secondscript.sh\" ]\nfor command in commands:\n\tprint \"Executing {}\".format( command )\n\tstdin , stdout, stderr = c.exec_command(command)\n\tprint stdout.read()\n\tprint( \"Errors\")\n\tprint stderr.read()\nc.close()\n\n\n\n\n#### 91\nselect \n\n       from beaconbank.BB_beaconlog20170525 as g0\n       \n       LEFT JOIN  \n       (  select account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON  g1.group_id= g2.id \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n      JOIN\n        ( select   g5.id as beacon_id, install_loc_cat1id, install_loc_cat2id,\n                  m5.name as install_loc_cat2id_name, \n                  m6.name as install_loc_cat1id_name\n            \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id         \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n\n      JOIN \n       (  select  dau_price, daily_price, price_type, beacon_id, group_id, max(group_id)\n          from   beaconbank.beacon_prices\n          GROUP BY  dau_price, daily_price, price_type, beacon_id, group_id \n       )  as h2     ON   g0.beacon_id= h2.beacon_id\n\nwhere g0.application_id=2170005   and event=0\n       \n\n\n\n\nselect g0.beacon_id, g0.account_id,  g0.application_id, app_user_id, g0.app_user_id\n\n       from beaconbank.BB_beaconlog20170525 as g0\n       \n       LEFT JOIN  \n       (  select account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON  g1.group_id= g2.id \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n      JOIN\n        ( select  g5.id as beacon_id,  install_loc_cat1id, install_loc_cat2id,\n                  m5.name as install_loc_cat2id_name, \n                  m6.name as install_loc_cat1id_name, min(g5.id)\n            \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id    \n\n         GROUP BY  beacon_id, install_loc_cat1id, install_loc_cat2id,install_loc_cat2id_name,  install_loc_cat1id_name    \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n\n      JOIN \n       (  select  dau_price, daily_price, price_type, beacon_id, group_id, max(group_id)\n          from   beaconbank.beacon_prices\n          GROUP BY  dau_price, daily_price, price_type, beacon_id, group_id \n       )  as h2     ON   g0.beacon_id= h2.beacon_id\n\nwhere g0.application_id=2170005   and event=0\n       \n   \n\n   \n\n\n#############################################\n#### OK   92 \n\nselect g0.detected_time, g0.beacon_id, g0.account_id,  g0.application_id, app_user_id, g3.group_id, group_type, name,event, \n       h2.dau_price,   min(g0.beacon_id)\n\n       from beaconbank.BB_beaconlog20170525 as g0\n       \n       LEFT JOIN  \n       (  select account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON  g1.group_id= g2.id \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n      JOIN\n        ( select  g5.id as beacon_id,  install_loc_cat1id, install_loc_cat2id,\n                  m5.name as install_loc_cat2id_name, \n                  m6.name as install_loc_cat1id_name, min(g5.id)\n            \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id    \n\n         GROUP BY  beacon_id, install_loc_cat1id, install_loc_cat2id,install_loc_cat2id_name,  install_loc_cat1id_name    \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n\n      LEFT JOIN \n       (  select  dau_price, daily_price, price_type, beacon_id, group_id, max(group_id)\n          from   beaconbank.beacon_prices\n          GROUP BY  dau_price, daily_price, price_type, beacon_id, group_id \n       )  as h2     ON   g0.beacon_id= h2.beacon_id\n\nwhere g0.application_id=2170005   and event=0\nGROUP BY g0.detected_time, g0.beacon_id, g0.account_id,  g0.application_id, app_user_id, g3.group_id, group_type, name,event, h2.dau_price\n   \n\n#########################################\n\n\n\n\n\n\n############# OK: 102\nselect g0.detected_time, g0.beacon_id, g0.account_id,  g0.application_id, app_user_id, g3.group_id, group_type, name,event, \n       h2.dau_price\n\n       from beaconbank.BB_beaconlog20170525 as g0\n       \n       LEFT JOIN  \n       (  select account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON  g1.group_id= g2.id \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n      JOIN\n        ( select  g5.id as beacon_id,  install_loc_cat1id, install_loc_cat2id,\n                  m5.name as install_loc_cat2id_name, \n                  m6.name as install_loc_cat1id_name, min(g5.id)\n            \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id    \n\n         GROUP BY  beacon_id, install_loc_cat1id, install_loc_cat2id,install_loc_cat2id_name,  install_loc_cat1id_name    \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n\n      JOIN \n       (  select  dau_price, daily_price, price_type, beacon_id, group_id, max(group_id)\n          from   beaconbank.beacon_prices\n          GROUP BY  dau_price, daily_price, price_type, beacon_id, group_id \n       )  as h2     ON   g0.beacon_id= h2.beacon_id\n\nwhere g0.application_id=2170005   and event=0\n\n\n\n#############################################################################################################\n#### 294 \n\nselect g0.detected_time, g0.beacon_id, g0.account_id,  g0.application_id, app_user_id, g3.group_id, group_type, name,event, \n       h2.dau_price\n\n       from beaconbank.BB_beaconlog20170525 as g0\n       \n       LEFT JOIN  \n       (  select account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON  g1.group_id= g2.id \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n      JOIN\n        ( select  g5.id as beacon_id,  install_loc_cat1id, install_loc_cat2id,\n                  m5.name as install_loc_cat2id_name, \n                  m6.name as install_loc_cat1id_name, min(g5.id)\n            \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id    \n\n         GROUP BY  beacon_id, install_loc_cat1id, install_loc_cat2id,install_loc_cat2id_name,  install_loc_cat1id_name    \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n\n      JOIN \n       (  select  dau_price, daily_price, price_type, beacon_id, group_id, max(group_id)\n          from   beaconbank.beacon_prices\n          GROUP BY  dau_price, daily_price, price_type, beacon_id, group_id \n       )  as h2     ON   g0.beacon_id= h2.beacon_id\n\nwhere g0.application_id=2170005   and event=0\n\n\n\n\n\n\n\n####### 294\nselect g0.detected_time, g0.beacon_id, g0.account_id,  g0.application_id, app_user_id, g3.group_id, group_type, name,event, \n       h2.dau_price\n\n       from beaconbank.BB_beaconlog20170525 as g0\n       \n       LEFT JOIN  \n       (  select account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON  g1.group_id= g2.id \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n      JOIN\n        ( select  g5.id as beacon_id,  install_loc_cat1id, install_loc_cat2id,\n                  m5.name as install_loc_cat2id_name, \n                  m6.name as install_loc_cat1id_name, min(g5.id)\n            \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id    \n\n         GROUP BY  beacon_id, install_loc_cat1id, install_loc_cat2id,install_loc_cat2id_name,  install_loc_cat1id_name    \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n\n      JOIN \n       (  select  dau_price, daily_price, price_type, beacon_id, group_id, max(group_id)\n          from   beaconbank.beacon_prices\n          GROUP BY  dau_price, daily_price, price_type, beacon_id, group_id \n       )  as h2     ON   g0.beacon_id= h2.beacon_id\n\nwhere g0.application_id=2170005   and event=0\n\n\n\n#####  261 \nselect count(g0.detected_time)\n       from beaconbank.BB_beaconlog20170525 as g0\nwhere g0.application_id=2170005   and event=0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n   \n         \n######################################################################################################\nselect application_id as app_id, account_id,   event, notified,  \n     group_id, group_name, group_type,   valid_from,  valid_to,\n     \n     manufacturer, model, os, sdk, \n     dau_price, daily_price, price_type,\n     \n     beacon_id,  address_prefecture, address_city,\n     address_detail, building_name,\n     install_category,is_fixed, is_outdoor,\n     is_public_area, install_loc_cat1id_name as install_loc_cat1id , install_loc_cat2id_name as install_loc_cat2id,\n     install_loc_name,  latitude as lat, longitude as lng,\n     \n     count(app_user_id) as n_hanoulog,  count(DISTINCT app_user_id) as n_user \n\nfrom \n     (\n    select g0.beacon_id, wildcard_beacon_id, g0.account_id,\n           g0.application_id, app_user_id, event, notified, \n           manufacturer, model, os, sdk,\n           \n           h1.latitude, h1.longitude, \n           h2.group_id, name as group_name, group_type,   valid_from,  valid_to,\n           dau_price, daily_price, price_type,\n           address_prefecture, address_city,\n           address_detail, building_name, \n           install_category, is_fixed, is_outdoor,\n           is_public_area, install_loc_cat1id, install_loc_cat2id,\n           install_loc_name, install_loc_detail, install_memo, install_loc_cat2id_name,\n            install_loc_cat1id_name\n       \n       from beaconbank.BB_beaconlog20170525 as g0\n     LEFT JOIN  \n       (  select account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n             CAST(FORMAT_DATE(\"%Y%m%d\", valid_form) as INT64 ) as valid_from, CAST(FORMAT_DATE(\"%Y%m%d\", valid_to) as INT64 ) as valid_to\n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON  g1.group_id= g2.id \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id, valid_from, valid_to \n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n     \n     JOIN\n        ( select   g5.id as beacon_id, latitude, longitude, \n              address_prefecture, address_city,\n              address_detail, building_name, building_floor,\n              install_category, power_supply, is_fixed, is_outdoor,\n              is_public_area, install_loc_cat1id, install_loc_cat2id,\n              install_loc_name, install_loc_detail, install_memo,\n              m5.name as install_loc_cat2id_name, \n              m6.name as install_loc_cat1id_name\n         \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id  \n        \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n     \n     JOIN \n       (  select  dau_price, daily_price, price_type, beacon_id, group_id, max(group_id)\n          from   beaconbank.beacon_prices\n          GROUP BY  dau_price, daily_price, price_type, beacon_id, group_id \n       )  as h2      ON   g0.beacon_id= h2.beacon_id\n\n)\n\nwhere valid_to >= 20170301 and valid_from <= 20210501\n      and event=0\ngroup by  application_id, account_id,\n     event, notified,  \n     group_id, group_name, group_type,   valid_from,  valid_to,\n     \n     manufacturer, model, os, sdk,\n     dau_price, daily_price, price_type,\n     beacon_id,        \n     address_prefecture, address_city,\n     address_detail, building_name,\n     install_category,  is_fixed, is_outdoor,\n     is_public_area, install_loc_cat1id, install_loc_cat2id,\n     install_loc_name,  lat, lng\norder by application_id asc, group_type, group_id\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nselect g0.beacon_id, g0.account_id,\n           g0.application_id, app_user_id\n\n       from beaconbank.BB_beaconlog20170525 as g0\n       \n       LEFT JOIN  \n       (  select account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON  g1.group_id= g2.id \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n      JOIN\n        ( select   g5.id as beacon_id, install_loc_cat1id, install_loc_cat2id,\n                  m5.name as install_loc_cat2id_name, \n                  m6.name as install_loc_cat1id_name\n            \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id         \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n\n      JOIN \n       (  select  dau_price, daily_price, price_type, beacon_id, group_id, max(group_id)\n          from   beaconbank.beacon_prices\n          GROUP BY  dau_price, daily_price, price_type, beacon_id, group_id \n       )  as h2     ON   g0.beacon_id= h2.beacon_id\n\nwhere g0.application_id=2170005   and event=0\n       \n   \n\n   \n\n##### SQL for page Area with Map\n\n       \nselect application_id as app_id, account_id,   event, app_use_detected, \n       group_id, group_name, group_type, \n     \n       beacon_id,  address_prefecture, address_city,\n       address_detail, \n       install_loc_cat1id_name as install_loc_cat1id , install_loc_cat2id_name as install_loc_cat2id,\n       latitude as lat, longitude as lng,\n     \n       count(app_user_id) as n_hanoulog,  count(DISTINCT app_user_id) as n_user \n\nfrom \n     (\n     select g0.beacon_id, g0.account_id,\n           g0.application_id, app_user_id, event, app_use_detected, \n           h1.latitude, h1.longitude, \n           h2.group_id, name as group_name, group_type, \n           address_prefecture, address_city,  address_detail, \n           install_loc_cat2id_name, install_loc_cat1id_name, min(g0.beacon_id)\n     \n       from  `beaconbank.BB_beaconlog*`     as g0\n     LEFT JOIN  \n       (  select account_id, application_id, name, group_type,  group_id, beacon_id\n\n          from (\n           select  account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n                   CAST(FORMAT_DATE(\"%Y%m%d\", valid_form) as INT64 ) as valid_from, CAST(FORMAT_DATE(\"%Y%m%d\", valid_to) as INT64 ) as valid_to1\n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON     g1.group_id= g2.id \n             wHERE  g1.is_latest=1   AND  g1.group_type= 1   \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id, valid_from, valid_to1\n            )\n          where valid_to1 >= \"\"\"+ t0 + \"\"\" and valid_from <= \"\"\" + t0 + \"\"\"\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n     LEFT JOIN\n        ( select   g5.id as beacon_id, latitude, longitude, \n              address_prefecture, address_city,   address_detail, \n              install_loc_cat1id, install_loc_cat2id,\n              m5.name as install_loc_cat2id_name, \n              m6.name as install_loc_cat1id_name, min(is_fixed)\n            \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id  \n                \n         GROUP BY beacon_id, latitude, longitude, \n              address_prefecture, address_city,   address_detail, \n              install_loc_cat1id, install_loc_cat2id,\n              install_loc_cat2id_name,    install_loc_cat1id_name           \n        )     as h1    ON  g0.beacon_id= h1.beacon_id\n               \nWHERE _TABLE_SUFFIX BETWEEN '\"\"\"+ta+\"\"\"' AND '\"\"\"+tb+\"\"\"'\nAND  CAST(FORMAT_DATETIME(\"%Y%m%d\", local_time) as INT64 )= \"\"\"+t0+\"\"\"\n\n\nGROUP BY g0.beacon_id, g0.account_id, detected_time,\n           g0.application_id, app_user_id, event, app_use_detected, \n           \n           h1.latitude, h1.longitude, \n           h2.group_id, group_name, group_type,\n\n           address_prefecture, address_city,\n           address_detail,  install_loc_cat1id, install_loc_cat2id,\n           install_loc_cat2id_name, install_loc_cat1id_name\n)\n \nwhere  event=0\n\ngroup by  application_id, account_id,\n     event, app_use_detected,  \n     group_id, group_name, group_type, \n     beacon_id, address_prefecture, address_city,\n     address_detail,  install_loc_cat1id, install_loc_cat2id,\n     lat, lng\norder by application_id asc, group_type, group_id   \n\n\n\n\n\nPython \nType \"copyright\", \"credits\" or \"license\" for more information.\n\nIPython  -- An enhanced Interactive Python.\n?         -> Introduction and overview of IPython's features.\n%quickref -> Quick reference.\nhelp      -> Python's own help system.\nobject?   -> Details about 'object', use 'object??' for extra details.\n\nIn [1]: \n\nIn [1]: dfstat= util.load(   HOME + '/data/count_table/20170702_2/dfstat.pkl' )\n   ...: \nTraceback (most recent call last):\n\n  File \"<ipython-input-1-d9ac68688699>\", line 1, in <module>\n    dfstat= util.load(   HOME + '/data/count_table/20170702_2/dfstat.pkl' )\n\nNameError: name 'util' is not defined\n\n\nIn [2]: import util\n   ...: dfstat= util.load(   HOME + '/data/count_table/20170702_2/dfstat.pkl' )\n   ...: \n   ...: \nTraceback (most recent call last):\n\n  File \"<ipython-input-2-eb37bb0cc5e6>\", line 2, in <module>\n    dfstat= util.load(   HOME + '/data/count_table/20170702_2/dfstat.pkl' )\n\nNameError: name 'HOME' is not defined\n\n\nIn [3]: \"\"\"  bbank  \"\"\"\n   ...: # %load_ext autoreload\n   ...: # %autoreload\n   ...: import os, sys\n   ...: DIRCWD=  'D:/_devs/project27/'  if  os.environ['COMPUTERNAME']=='ASUS1-PC' and sys.platform.find('win')> -1 else  'G:/_devs/project27/' if sys.platform.find('win')> -1   and  os.environ['COMPUTERNAME']=='KEVIN'   else  '/home/noel/project27/' if os.environ['HOME'].find('ubuntu')>-1 else '/home/noel/project27/'\n   ...: \n   ...: # DIRCWD=   '/home/noel/project27/'\n   ...: \n   ...: \n   ...: DIRCWD= r\"G:/_devs/google_cloud/home/noel/project27/\"\n   ...: \n   ...: \n   ...: os.chdir(DIRCWD); sys.path.append(DIRCWD + '/aapackage'); # sys.path.append(DIRCWD + '/linux/aapackage')\n   ...: # execfile( DIRCWD + '/aapackage/allmodule.py')\n   ...: import  pandas as pd, sqlalchemy as sql,  numpy as np, gc,  arrow\n   ...: from attrdict import AttrDict as dict2; from collections import defaultdict  as dict1\n   ...: \n   ...: import util\n   ...: ############################################################################################\n   ...: HOME= 'D:/_devs/google_cloud/home/noel/project27/' if  os.environ['COMPUTERNAME']=='ASUS1-PC' else  '/home/noel/project27/'  if sys.platform.find('lin')> -1  else 'G:/_devs/google_cloud/home/noel/project27/'\n   ...: # HOME=   '/home/noel/project27/'\n   ...: \n   ...: \n   ...: HOME= r\"G:/_devs/google_cloud/home/noel/project27/\"\n   ...: \n   ...: \n\nIn [4]: import util\n   ...: dfstat= util.load(   HOME + '/data/count_table/20170702_2/dfstat.pkl' )\n   ...: \nTraceback (most recent call last):\n\n  File \"<ipython-input-4-8d0fe8fd90ed>\", line 2, in <module>\n    dfstat= util.load(   HOME + '/data/count_table/20170702_2/dfstat.pkl' )\n\n  File \"G:\\_devs\\project27\\aapackage\\util.py\", line 1093, in load\n    return py_load_obj(folder=folder, isabsolutpath=isabsolutpath)\n\n  File \"G:\\_devs\\project27\\aapackage\\util.py\", line 1127, in py_load_obj\n    with open(dir1, 'rb') as f:\n\nIOError: [Errno 2] No such file or directory: 'G:/_devs/google_cloud/home/noel/project27//data/count_table/20170702_2/dfstat.pkl'\n\n\nIn [5]: import util\n   ...: dfstat= util.load(   HOME + '/data/count_table/dfstat.pkl' )\n   ...: \n   ...: \n\nIn [6]: ss= \"\"\"       \n   ...: select application_id as app_id, account_id,   event, app_use_detected, \n   ...:        group_id, group_name, group_type, \n   ...:        \n   ...:        beacon_id,  address_prefecture, address_city,\n   ...:        address_detail, \n   ...:        install_loc_cat1id_name as install_loc_cat1id , install_loc_cat2id_name as install_loc_cat2id,\n   ...:        latitude as lat, longitude as lng,\n   ...:        \n   ...:        count(app_user_id) as n_hanoulog,  count(DISTINCT app_user_id) as n_user \n   ...: \n   ...: from \n   ...:      (\n   ...:      select g0.beacon_id, g0.account_id,\n   ...:            g0.application_id, app_user_id, event, app_use_detected, \n   ...:            h1.latitude, h1.longitude, \n   ...:            h2.group_id, name as group_name, group_type, \n   ...:            address_prefecture, address_city,  address_detail, \n   ...:            install_loc_cat2id_name, install_loc_cat1id_name, min(g0.beacon_id)\n   ...:        \n   ...:        from  `beaconbank.BB_beaconlog*`     as g0\n   ...:      LEFT JOIN  \n   ...:        (  select account_id, application_id, name, group_type,  group_id, beacon_id\n   ...:           \n   ...:           from (\n   ...:            select  account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n   ...:                    CAST(FORMAT_DATE(\"%Y%m%d\", valid_form) as INT64 ) as valid_from, CAST(FORMAT_DATE(\"%Y%m%d\", valid_to) as INT64 ) as valid_to1\n   ...:              from beaconbank.BB_group_beacon as g1  \n   ...:              JOIN beaconbank.BB_group as g2 \n   ...:              ON     g1.group_id= g2.id \n   ...:              wHERE  g1.is_latest=1   AND  g1.group_type= 1   \n   ...:              GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id, valid_from, valid_to1\n   ...:             )\n   ...:           where valid_to1 >= \"\"\"+ t0 + \"\"\" and valid_from <= \"\"\" + t0 + \"\"\"\n   ...:        )  as g3   ON    g0.beacon_id=       g3.beacon_id\n   ...:                   AND   g0.application_id=  g3.application_id\n   ...:                   AND   g0.account_id=      g3.account_id\n   ...:      \n   ...:      LEFT JOIN\n   ...:         ( select   g5.id as beacon_id, latitude, longitude, \n   ...:               address_prefecture, address_city,   address_detail, \n   ...:               install_loc_cat1id, install_loc_cat2id,\n   ...:               m5.name as install_loc_cat2id_name, \n   ...:               m6.name as install_loc_cat1id_name, min(is_fixed)\n   ...:          \n   ...:          from   beaconbank.BB_beacon as g5         \n   ...:          JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n   ...:          JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n   ...:          JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id  \n   ...:          \n   ...:          GROUP BY beacon_id, latitude, longitude, \n   ...:               address_prefecture, address_city,   address_detail, \n   ...:               install_loc_cat1id, install_loc_cat2id,\n   ...:               install_loc_cat2id_name,    install_loc_cat1id_name           \n   ...:         )     as h1    ON  g0.beacon_id= h1.beacon_id\n   ...: \n   ...: WHERE _TABLE_SUFFIX BETWEEN '\"\"\"+ta+\"\"\"' AND '\"\"\"+tb+\"\"\"'\n   ...: AND  CAST(FORMAT_DATETIME(\"%Y%m%d\", local_time) as INT64 )= \"\"\"+t0+\"\"\"\n   ...: \n   ...: \n   ...: GROUP BY g0.beacon_id, g0.account_id, detected_time,\n   ...:            g0.application_id, app_user_id, event, app_use_detected, \n   ...:            \n   ...:            h1.latitude, h1.longitude, \n   ...:            h2.group_id, group_name, group_type,\n   ...:            \n   ...:            address_prefecture, address_city,\n   ...:            address_detail,  install_loc_cat1id, install_loc_cat2id,\n   ...:            install_loc_cat2id_name, install_loc_cat1id_name\n   ...: )\n   ...: \n   ...: where  event=0\n   ...: \n   ...: group by  application_id, account_id,\n   ...:      event, app_use_detected,  \n   ...:      group_id, group_name, group_type, \n   ...:      beacon_id, address_prefecture, address_city,\n   ...:      address_detail,  install_loc_cat1id, install_loc_cat2id,\n   ...:      lat, lng\n   ...: order by application_id asc, group_type, group_id   \n   ...: \"\"\"\n   ...: \n   ...: \nTraceback (most recent call last):\n\n  File \"<ipython-input-6-6e3154b765c8>\", line 58, in <module>\n    AND  CAST(FORMAT_DATETIME(\"%Y%m%d\", local_time) as INT64 )= \"\"\"+t0+\"\"\"\n\nNameError: name 't0' is not defined\n\n\nIn [7]: t0=\"20170715\"\n   ...: ta=\"20170714\"\n   ...: tb=\"20170715\"\n\nIn [8]: ss= \"\"\"       \n   ...: select application_id as app_id, account_id,   event, app_use_detected, \n   ...:        group_id, group_name, group_type, \n   ...:        \n   ...:        beacon_id,  address_prefecture, address_city,\n   ...:        address_detail, \n   ...:        install_loc_cat1id_name as install_loc_cat1id , install_loc_cat2id_name as install_loc_cat2id,\n   ...:        latitude as lat, longitude as lng,\n   ...:        \n   ...:        count(app_user_id) as n_hanoulog,  count(DISTINCT app_user_id) as n_user \n   ...: \n   ...: from \n   ...:      (\n   ...:      select g0.beacon_id, g0.account_id,\n   ...:            g0.application_id, app_user_id, event, app_use_detected, \n   ...:            h1.latitude, h1.longitude, \n   ...:            h2.group_id, name as group_name, group_type, \n   ...:            address_prefecture, address_city,  address_detail, \n   ...:            install_loc_cat2id_name, install_loc_cat1id_name, min(g0.beacon_id)\n   ...:        \n   ...:        from  `beaconbank.BB_beaconlog*`     as g0\n   ...:      LEFT JOIN  \n   ...:        (  select account_id, application_id, name, group_type,  group_id, beacon_id\n   ...:           \n   ...:           from (\n   ...:            select  account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n   ...:                    CAST(FORMAT_DATE(\"%Y%m%d\", valid_form) as INT64 ) as valid_from, CAST(FORMAT_DATE(\"%Y%m%d\", valid_to) as INT64 ) as valid_to1\n   ...:              from beaconbank.BB_group_beacon as g1  \n   ...:              JOIN beaconbank.BB_group as g2 \n   ...:              ON     g1.group_id= g2.id \n   ...:              wHERE  g1.is_latest=1   AND  g1.group_type= 1   \n   ...:              GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id, valid_from, valid_to1\n   ...:             )\n   ...:           where valid_to1 >= \"\"\"+ t0 + \"\"\" and valid_from <= \"\"\" + t0 + \"\"\"\n   ...:        )  as g3   ON    g0.beacon_id=       g3.beacon_id\n   ...:                   AND   g0.application_id=  g3.application_id\n   ...:                   AND   g0.account_id=      g3.account_id\n   ...:      \n   ...:      LEFT JOIN\n   ...:         ( select   g5.id as beacon_id, latitude, longitude, \n   ...:               address_prefecture, address_city,   address_detail, \n   ...:               install_loc_cat1id, install_loc_cat2id,\n   ...:               m5.name as install_loc_cat2id_name, \n   ...:               m6.name as install_loc_cat1id_name, min(is_fixed)\n   ...:          \n   ...:          from   beaconbank.BB_beacon as g5         \n   ...:          JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n   ...:          JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n   ...:          JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id  \n   ...:          \n   ...:          GROUP BY beacon_id, latitude, longitude, \n   ...:               address_prefecture, address_city,   address_detail, \n   ...:               install_loc_cat1id, install_loc_cat2id,\n   ...:               install_loc_cat2id_name,    install_loc_cat1id_name           \n   ...:         )     as h1    ON  g0.beacon_id= h1.beacon_id\n   ...: \n   ...: WHERE _TABLE_SUFFIX BETWEEN '\"\"\"+ta+\"\"\"' AND '\"\"\"+tb+\"\"\"'\n   ...: AND  CAST(FORMAT_DATETIME(\"%Y%m%d\", local_time) as INT64 )= \"\"\"+t0+\"\"\"\n   ...: \n   ...: \n   ...: GROUP BY g0.beacon_id, g0.account_id, detected_time,\n   ...:            g0.application_id, app_user_id, event, app_use_detected, \n   ...:            \n   ...:            h1.latitude, h1.longitude, \n   ...:            h2.group_id, group_name, group_type,\n   ...:            \n   ...:            address_prefecture, address_city,\n   ...:            address_detail,  install_loc_cat1id, install_loc_cat2id,\n   ...:            install_loc_cat2id_name, install_loc_cat1id_name\n   ...: )\n   ...: \n   ...: where  event=0\n   ...: \n   ...: group by  application_id, account_id,\n   ...:      event, app_use_detected,  \n   ...:      group_id, group_name, group_type, \n   ...:      beacon_id, address_prefecture, address_city,\n   ...:      address_detail,  install_loc_cat1id, install_loc_cat2id,\n   ...:      lat, lng\n   ...: order by application_id asc, group_type, group_id   \n   ...: \"\"\"\n   ...: \n   ...: \n   ...: \n\nIn [9]: print ss\n       \nselect application_id as app_id, account_id,   event, app_use_detected, \n       group_id, group_name, group_type, \n       \n       beacon_id,  address_prefecture, address_city,\n       address_detail, \n       install_loc_cat1id_name as install_loc_cat1id , install_loc_cat2id_name as install_loc_cat2id,\n       latitude as lat, longitude as lng,\n       \n       count(app_user_id) as n_hanoulog,  count(DISTINCT app_user_id) as n_user \n\nfrom \n     (\n     select g0.beacon_id, g0.account_id,\n           g0.application_id, app_user_id, event, app_use_detected, \n           h1.latitude, h1.longitude, \n           h2.group_id, name as group_name, group_type, \n           address_prefecture, address_city,  address_detail, \n           install_loc_cat2id_name, install_loc_cat1id_name, min(g0.beacon_id)\n       \n       from  `beaconbank.BB_beaconlog*`     as g0\n     LEFT JOIN  \n       (  select account_id, application_id, name, group_type,  group_id, beacon_id\n          \n          from (\n           select  account_id, g1.application_id, name, group_type,  group_id, beacon_id, max(group_id), \n                   CAST(FORMAT_DATE(\"%Y%m%d\", valid_form) as INT64 ) as valid_from, CAST(FORMAT_DATE(\"%Y%m%d\", valid_to) as INT64 ) as valid_to1\n             from beaconbank.BB_group_beacon as g1  \n             JOIN beaconbank.BB_group as g2 \n             ON     g1.group_id= g2.id \n             wHERE  g1.is_latest=1   AND  g1.group_type= 1   \n             GROUP BY beacon_id, account_id,  g1.application_id, name, group_type, group_id, valid_from, valid_to1\n            )\n          where valid_to1 >= 20170715 and valid_from <= 20170715\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n     \n     LEFT JOIN\n        ( select   g5.id as beacon_id, latitude, longitude, \n              address_prefecture, address_city,   address_detail, \n              install_loc_cat1id, install_loc_cat2id,\n              m5.name as install_loc_cat2id_name, \n              m6.name as install_loc_cat1id_name, min(is_fixed)\n         \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id  \n         \n         GROUP BY beacon_id, latitude, longitude, \n              address_prefecture, address_city,   address_detail, \n              install_loc_cat1id, install_loc_cat2id,\n              install_loc_cat2id_name,    install_loc_cat1id_name           \n        )     as h1    ON  g0.beacon_id= h1.beacon_id\n\nWHERE _TABLE_SUFFIX BETWEEN '20170714' AND '20170715'\nAND  CAST(FORMAT_DATETIME(\"%Y%m%d\", local_time) as INT64 )= 20170715\n\n\nGROUP BY g0.beacon_id, g0.account_id, detected_time,\n           g0.application_id, app_user_id, event, app_use_detected, \n           \n           h1.latitude, h1.longitude, \n           h2.group_id, group_name, group_type,\n           \n           address_prefecture, address_city,\n           address_detail,  install_loc_cat1id, install_loc_cat2id,\n           install_loc_cat2id_name, install_loc_cat1id_name\n)\n\nwhere  event=0\n\ngroup by  application_id, account_id,\n     event, app_use_detected,  \n     group_id, group_name, group_type, \n     beacon_id, address_prefecture, address_city,\n     address_detail,  install_loc_cat1id, install_loc_cat2id,\n     lat, lng\norder by application_id asc, group_type, group_id   \n\n\n\n\n\nPySCIPOpt   Mixed Integer Optimization\n\nPySCIPOpt\n\n\n\n\n\n\n\n\n##################################################################################################################\nI have trained two models here namely Naive Bayes classifier and Support Vector Machines (SVM). \n\nNaive Bayes classifier is a conventional and very popular method for document classification problem. \n\nIt is a supervised probabilistic classifier based on Bayes theorem assuming independence between every pair of features. \nSVMs are supervised binary classifiers which are very effective when you have higher number of features. \nThe goal of SVM is to separate some subset of training data from rest called the support vectors (boundary of separating hyper-plane). \n\nThe decision function of SVM model that predicts the class of the test data is based on support vectors and makes use of a kernel trick.\n\n\nPre-Process the Text : remove frequent words,\nInput :\n    Samples row: 15,000 emails\n    Columns     : words   with frequency.\n\nwordID = i\nfeatures_matrix[docID,wordID] = all_words.count(word)\n\n\nhttps://github.com/abhijeet3922/Mail-Spam-Filtering/blob/master/enron-spamfilter.py\n\n\n\nConfusion Matrix\n\n\n\n\n\n\n\n\n\n##################################################################################################################\n\n1) How will you handle missing data ?\n\n  Identify nature of the column data:\n      numerical, category, IDentifier\n      How many data are missing : 1% or 50% or 90%\n\n    1) Easy/fast: remove rows / columns with missing.\n\n    2) Interpolation\n       numerical :  time series: interpolate with mean / model\n                   No time series, cluster the rows together and interpolate from cluster.\n                   Model to interpolate the missing:\n                        Maximum likehood based on cluster or time series like\n\n\n    3) category : same, from cluster,   or median from column\n    4) Identifier: Find a way to identify.\n\n\n2) reduce bias\n   Increase complexity of model   (vs OVerfit)\n  Error**2=  Bias**2 + Variance + Epsilon**2\n      bias=  E[ Y - Yest    ]**2\n      var=   E[  (Y-Yest)**2 ]\n\n\n       \n\nOverfitting : \n    Put regularizer L1, L2  fit on Validation dataset.\n    Cross Validation with K-Fold.\n    Bag methodology: separate dataset in K-Fold\n\n\n    A model is trained using k-1 of the folds as training data;\n    the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n\n    http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n\n\nReduce Variance :\n     OVerfit : too complex model.\n     Noise in Input\n\n     Averaging: reduce variance :  use different uncorrelated estimators\n\n     Bagging: split dataset in separate (no effect on bias).\n     Boosting: Loss function, weight training equally.\n               After training : overweight sample on the highest error\n               ---> Issue with overfitting noisy data.\n\n     More training sample\n\n\nIOT :   Kalman filter\n\n\nP value :  Check if hypothesis is True or Not\n    Pvalue = Proba( Result is more extreme than observed / H0    )\n   Null hypothesis:  \n         if P > alpha :  H0 is True\n         If P is small: H0 is False --->  Our method is Ok.\n   \n\nANOVA : Analysis of Variance : Feature importance.\n\n\n\nConfusion Matrix:\n Disease  TP: 100%\n          TN : 5%  (5% are said \"sick\", but not sick)\n\nTotal 1/1000 are sick:\n     \n\n\n\n\n\n3) K Fold Cross Validation\n   5 datasets ---> 1 for validation, train on 4 and loop\n   Accuracy is on average.\n\n\n\n\n4) K Means Clustering:\n  Fixed K nb of clsuter, random initlization, and put point to closest clusters.\n    Recalculate the new center ---> convergence\n\n   KNN: nearest neightbor\n\n\n   Category: Hamming distance: nb of values needed for change\n             K modes for category\n             distance(sydney, melbourne)=1-similarity(sydney,melbourne).\n             pb is the mearning level : vector space\n\n\n\n\n\n\n\n\n\n\n3) What is logistic regression\nUsed for classification :  \n  Binary output  1 or 0  (or probability between 1 and 0)  :Probability of passing exam /event\n  Proba(Y= yi / X,theta) = 1/ (1 + exp(-t.Theta * X))\n\n  Input can be continous variable\n\n  Fit with Maximum Likehood\n\n  Likehood = Product ( P(y=yi / X,theta)  )   conditionnal probability\n  log-likehood   ==  Cross Entropy   -y*ln(y)\n\n  Confusion Matrix / AUC\n\n\n\n4)\n\n\n19)       A test has a true positive rate of 100% and false positive rate of 5%. \nThere is a population with a 1/1000 rate of having the condition the test identifies.\n Considering a positive test, what is the probability of having that condition?\n\nPb= 1/1000\n\nP( sick / test positive) =  P(test positive / sick ) * P(sick) / P( test positive)\n                         = 100% * 1/1000  / P( test positive)\n\nP(positive) = Proba(sick) * Proba(Positive/sick) +   Proba(nosick) * Proba(positive/nosick)\n            =  1/1000 * 1   +  (1- 1/1000) *5%\n\n\np(sick /tes positve)=   1 /  ( 1 + (1000-1)*5%) = 1 / ( 1 +    999*5%) = 1/51= 2%\n\n\n\nP( A / True) =  P(Ttrue / A) * P(A)  /  P(True)\n             =   TP * P(A)\n\nP(true) =  P(A) * P(True/A)  +   ( 1- P(A)) * P(False/A)\n        = P(A) * TF    + (1-PA) * TN\n\n\n\n1000 --> 1 is sick\n     999 are not sick ---->  5% of them will say positive == 50 persons    \n51 persons positive test -->  ony 1 has sickness\n\n (1-p) * TN  + p*TF\n\n\n\n\n5) Box Cox Transformation for Linear regression\n   Residual are not normal\n\n   Z= (Y + delta) ** lambda\n\n   Fit Z by maximum likehood\n\n   ---> Improve residual to normality\n\n\nSupervised :     Input and Output\nUn-supervised :  Only Output ---> Find Structure (ie Auto Encoder)\n\n\n\n\n5) Metrics ROC Curve\n\n\n\n\n6) K Means Algorithm\n\n   Set of data with feature (ie columns)\n   Distance euclidian\n\n\n\nARIMA : integrated mixture autoregressive moving average model\np d q :   p:lag in Xt,  d delta  and q lag in error\nPhi(L) *D * Xt =   mu +  theta(L)* et\n\n\f\n\n\n\n\n\n\n###################################################################################################\n## Question 11: About 30% of human twins are identical, and the rest are fraternal.\nIdentical twins are necessarily the same sex, half are males and the other half are females.\nOne-quarter of fraternal twins are both male,\none-quarter both female,\nand one-half are mixes: one male, one female.\n\nYou have just become a parent of twins and are told they are both girls.\nGiven this information, what is the probability that they are identical?\n\nP(iden) = 0.3\nP(   m, m  / id twins   ) =0.5\nP(   f, f  / id twins  ) =0.5\n\nP(fraternal)\nP(  m, m / fra) = 0.25\nP(  f, f/ fra) =  0.25\nP(  m, f/ fra) =  0.5\n\n\nP(  Identical /   twin +(f,f)) =   P(  twin+(f,f) / Identical) * P(Identical) / P( twin + f,f )\n                               =   p(  Iden & twin(f,f) ) / P(twin (f,f) )\n                               =\n\n\n\n\n\n\n2)  What will you do if removing missing values from a dataset cause bias?\n\n3)  How can you reduce bias in a given data set?\n\n4) How will you impute missing information in a dataset?\n\n\n\n\n\n###########################################################\nAutomobile Predictive Maintenance: implemented a nearly real-time predictive system \nto identify automobile failure causes with over 90% accuracy; Teradata, R, Random Forest, KNN, DNN\n\nDangerous Driving Analytics: analyze dangerous driving behaviors \nand find dangerous driving spots from historical automobile sensor data; Aster, Python, PCA, Logistic Regression\n\nAnalytics-Driven Automotive Navigation Improvement: \nidentify on-road obstacle avoidance timing, \npredict traffic jam, recommend optimal driving routes to drivers by applying path \nand association analysis from historical automobile sensor data; Aster, R, Python\n\n\n\n\nTatsuru Kikuchi works as a Data Scientist / Business Strategy Consultant in the team of Data Science, \nAnalytics Business Consulting at Teradata in the Tokyo practice. As a member of Analytics Business Consulting, \nhe works in collaboration with other members of the team to research, design, prototype, test and document novel algorithms and predictive analytics\nfor automated, near real time decision making on telemetry data. On a daily basis, he works with massive data sets,\nwhich includes data integration, data cleansing, exploratory analysis, predictive modeling, and rapid prototyping. He presents findings to teammates and guide the transition of new algorithms into operational code.\n\nAccomplishments:\n- Digital Channel Transformation (Finance/Retail Bank): \nlead key initiative strategy related to the retail banks' overall omni-channel strategy; delivered a know-your-customer (KYC) type analysis \nfor drive the retail bank strategy to reduce the number of branches; managed the digital channel transformation of retail bank\n by providing forecast of the number of transactions in each channels (Branch/ATM/IB).\n\n\n- Failure Diagnosis (Automobile): implemented a nearly real-time predictive system to identify automobile failure causes \nwith over 90% accuracy based on Deep Learning technique.\n\n- Demand Forecasting (Telecommunications): predicted future demand forecasting for the metal line\n considering the growth of the optical line based on ARIMA model.\n\n\nTechnical skills:\n- SQL\n- R, Python\n- Machine Learning\n- Deep Learning\n\n\n\n•Demand forecast analysis of electric power. Key methods: machine learning (SVM, random forest) to find key variables of consumer's activities.\n•Consumer segmentation analysis of retailer's customers. Key method: k-means to segment consumer into categories.\n•Web stream analysis of customer shopping behavior. Key method: machine learning (SVM, random forest) to find their major web stream categories.\n•Building optimal target selection model for retailer. Key method: k-means for customer segmentation, logistic regression for optimization.\n•Deep analysis of customer's behavior. Key method: Principal component analysis for building powerful customer related variables, Logistic regression to classify customer into groups.\n\n\n\n\n\n\n\n##################################################################################################################\nQuestions from Data Science Interviews at Top Tech Companies\nData Scientist Interview Questions for Top Tech Companies\n\n\n\n\n\nData Science Interview Questions Asked at Other Top Tech Companies\n\n1) R programming language cannot handle large amounts of data. What are the other ways of handling it without using Hadoop infrastructure? (Asked at Pyro Networks)\n\n2) Explain the working of a Random Forest Machine Learning Algorithm (Asked at Cyient)\n\n3) Describe K-Means Clustering.(Asked at Symphony Teleca)\n\n4) What is the difference between logistic and linear regression? (Asked at Symphony Teleca)\n\n5) What kind of distribution does logistic regression follow? (Asked at Symphony Teleca)\n\n6) How do you parallelize machine learning algorithms? (Asked at Vodafone)\n\n7) When required data is not available for analysis, how do you go about collecting it? (Asked at Vodafone)\n\n8) What do you understand by heteroscadisticity (Asked at Vodafone)\n\n9) What do you understand by confidence interval? (Asked at Vodafone)\n\n10) Difference between adjusted r and r square. (Asked at Vodafone)\n\n11) How Facebook recommends items to newsfeed? (Asked at Finomena)\n\n12)  What do you understand by ROC curve and how is it used? (Asked at MachinePulse)\n\n13) How will you identify the top K queries from a file? (Asked at BloomReach)\n\n14) Given a set of webpages and changes on the website, how will you test the new website feature to determine if the change works positively? (Asked at BloomReach)\n\n15) There are N pieces of rope in a bucket. You put your hand into the bucket, take one end piece of the rope .Again you put your hand into the bucket and take another end piece of a rope. You tie both the end pieces together. What is the expected value of the number of loops within the bucket? (Asked at Natera)\n\n16) How will you test if a chosen credit scoring model works or not? What data will you look at? (Asked at Square)\n\n17) There are 10 bottles where each contains coins of 1 gram each. There is one bottle of that contains 1.1 gram coins. How will you identify that bottle after only one measurement? (Data Science Puzzle asked at Latent View Analytics)\n\n18) How will you measure a cylindrical glass filled with water whether it is exactly half filled or not? You cannot measure the water, you cannot measure the height of the glass nor can you dip anything into the glass. (Data Science Puzzle asked at Latent View Analytics)\n\n19) What would you do if you were a traffic sign? (Data Science Interview Question asked at Latent View Analytics)\n\n20)  If you could get the dataset on any topic of interest, irespective of the collection methods or resources then how would the dataset look like and what will you do with it. (Data Scientist Interview Question asked at CKM Advisors)\n\n21) Given n samples from a uniform distribution [0,d], how will you estimate the value of d? (Data Scientist Interview Question asked at Spotify)\n\n22) How will you tune a Random Forest? (Data Science Interview Question asked at Instacart).\n\n23) Tell us about a project where you have extracted useful information from a large dataset. Which machine learning algorithm did you use for this and why? (Data Scientist Interview Question asked at Greenplum)\n\n24) What is the difference between Z test and T test ? (Data Scientist Interview Questions asked at Antuit)\n\n25) What are the different models you have used for analysis and what were your inferences? (Data Scientist Interview Questions asked at Cognizant)\n\n26) Given the title of a product, identify the category and sub-category of the product. (Data Scientist interview question asked at Delhivery)\n\n27) What is the difference between machine learning and deep learning? ( Data Scientist Interview Question asked at InfoObjects)\n\n28) What are the different parameters in ARIMA models ? (Data Science Interview Question asked at Morgan Stanley)\n\n29) What are the optimisations you would consider when computing the similarity matrix for a large dataset? (Data Science Interview questions asked at MakeMyTrip)\n\n30) Use Python programming language to implement a toolbox with specific image processing tasks.(Data Science Interview Question asked at Intuitive Surgical)\n\n31) Why do you use Random Forest instead of a simple classifier for one of the classification problems ? (Data Science Interview Question asked at Audi)\n\n32) What is an n-gram? (Data Science Interview Question asked at Yelp)\n\n33) What are the problems related to Overfitting and Underfitting  and how will you deal with these ? (Data Science Interview Question asked at Tiger Analytics)\n\n34) Given a MxN dimension matrix with each cell containing an alphabet, find if a string is contained in it or not.(Data Science Interview Question asked at Tiger Analytics)\n\n35) How do you \"Group By\" in R programming language without making use of any package ? (Data Scientist Interview Question asked at OLX)\n\n36) List 15 features that you will make use of to build a classifier for OLX website.(Data Scientist Interview Question asked at OLX)\n\n37) How will you build a caching system using an advanced data structure like hashmap ? (Data Scientist Interview Question asked at OLX)\n\n38) How to reverse strings that have changing positions ? (Data Scientist Interview Question asked at Tiger Analytics)\n\n\n\n\n\n\n\n\nThese questions listed here are after a thorough research of the companies’ sites and high quality discussion forums. This is not a guarantee that these very questions will be asked in data science interviews, but this is just to give the readers an idea of what can be expected when they apply for the position of Data Scientists in these tech companies.\n\nLearn Data Science in Python to Land a Top Gig as a Data Scientist at Top Tech Companies!\n\nFacebook Data Science Interview Questions\n1)         A building has 100 floors. Given 2 identical eggs, how can you use them to find the threshold floor? The egg will break from any particular floor above floor N, including floor N itself.\n\n2)         In a given day, how many birthday posts occur on Facebook?\n\n3)         You are at a Casino. You have two dices to play with. You win $10 every time you roll a 5. If you play till you win and then stop, what is the expected pay-out?\n\n4)         How many big Macs does McDonald sell every year in US?\n\n5)         You are about to get on a plane to Seattle, you want to know whether you have to bring an umbrella or not. You call three of your random friends and as each one of them if it’s raining. The probability that your friend is telling the truth is 2/3 and the probability that they are playing a prank on you by lying is 1/3. If all 3 of them tell that it is raining, then what is the probability that it is actually raining in Seattle.\n\n6)         You can roll a dice three times. You will be given $X where X is the highest roll you get. You can choose to stop rolling at any time (example, if you roll a 6 on the first roll, you can stop). What is your expected pay-out?\n\n7)         How can bogus Facebook accounts be detected?\n\n8)       You have been given the data on Facebook user’s friending or defriending each other. How will you determine whether a given pair of Facebook users are friends or not?\n\n9)         How many dentists are there in US?\n\n10)         You have 2 dices. What is the probability of getting at least one 4? Also find out the probability of getting at least one 4 if you have n dices.\n\n11)       Pick up a coin C1 given C1+C2 with probability of trials p (h1) =.7, p (h2) =.6 and doing 10 trials. And what is the probability that the given coin you picked is C1 given you have 7 heads and 3 tails? \n\n12)     You are given two tables- friend_request and request_accepted. Friend_request contains requester_id, time and sent_to_id and request_accepted table contains time, acceptor_id and requestor_id. How will you determine the overall acceptance rate of requests?\n\n13)       How would add new Facebook members to the database of members, and code their relationships to others in the database? \n\n14)       What would you add to Facebook and how would you pitch it and measure its success?\n\n15)  How will you test that there is increased probability of a user to stay active after 6 months given that a user has more friends now?\n\n16) You have two tables-the first table has data about the users and their friends, the second table has data about the users and the pages they have liked. Write an SQL query to make recommendations using pages that your friends liked. The query result should not recommend the pages that have already been liked by a user.\n\n17) What is the probability of pulling a different shape or a different colour card from a deck of 52 cards?\n\n18) Which technique will you use to compare the performance of two back-end engines that generate automatic friend recommendations on Facebook?\n\n19) Implement a sorting algorithm for a numerical dataset in Python.\n\n20) How many people are using Facebook in California at 1.30 PM on Monday?\n\n21) You are given 50 cards with five different colors- 10 Green cards, 10 Red Cards, 10 Orange Cards, 10 Blue cards, and 10 Yellow cards. The cards of each colors are numbered from one to ten. Two cards are picked at random. Find out the probability that the cards picked are not of same number and same color.\n\n22) What approach will you follow to develop the love,like, sad feature on Facebook?\n\n\n\n\nInsight Data Science Interview Questions\n\n1)         Which companies participating in Insight would you be interested in working for? \n\n2)         Create a program in a language of your choice to read a text file with various tweets. The output should be 2 text files-one that contains the list of all unique words among all tweets along with the count for repeated words and the second file should contain the medium number of unique words for all tweets.\n\n3)         What motivates you to transition from academia to data science?\n\n\n\n\nTwitter Data Scientist Interview Questions                       \n\n1)    How can you measure engagement with given Twitter data?\n\n2)    Give a large dataset, find the median.\n\n3)    What is the good measure of influence of a Twitter user?\n\n\n\n\nAirBnB Data Science Interview Questions\n\n1)  Do you have some knowledge of R - analyse a given dataset in R?\n\n2)  What will you do if removing missing values from a dataset cause bias?\n\n3)  How can you reduce bias in a given data set?\n\n4) How will you impute missing information in a dataset?\n\n\n\n\nGoogle Data Science Interview Questions\n\n1)  Explain about string parsing in R language\n\n2) A disc is spinning on a spindle and you don’t know the direction in which way the disc is spinning. You are provided with a set of pins.How will you use the pins to describe in which way the disc is spinning?\n\n3)  Describe the data analysis process.\n\n4) How will you cut a circular cake into 8 equal pieces?\n\n\n\n\nLinkedIn Data Science Interview Questions\n\n1)  Find out K most frequent numbers from a given stream of numbers on the fly.\n\n2)  Given 2 vectors, how will you generate a sorted vector?\n\n3)  Implementing pow function\n\n4)  What kind of product you want to build at LinkedIn?\n\n5)  How will you design a recommendation engine for jobs?\n\n6)  Write a program to segment a long string into a group of valid words using Dictionary. The result should return false if the string cannot be segmented. Also explain about the complexity of the devised solution.\n\n7) Define an algorithm to discover when a person is starting to search for new job.\n\n8) What are the factors used to produce “People You May Know” data product on LinkedIn?\n\n9)  How will you find the second largest element in a Binary Search tree ? (Asked for a Data Scientist Intern job role)\n\n\n\n\nMu Sigma Data Science Interview Questions\n\n1)   Explain the difference between Supervised and Unsupervised Learning through examples.\n\n2)   How would you add value to the company through your projects?\n\n3)   Case Study based questions – Cars are implanted with speed tracker so that the insurance companies can track about our driving state. Based on this new scheme what kind of business questions can be answered?\n\n4)  Define standard deviation, mean, mode and median.\n\n5) What is a joke that people say about you and how would you rate the joke on a scale of 1 to 10?\n\n6) You own a clothing enterprise and want to improve your place in the market. How will you do it from the ground level ?\n\n\n\n\nAmazon Data Science Interview Questions\n\n1) Estimate the probability of a disease in a particular city given that the probability of the disease on a national level is low.\n\n2) How will inspect missing data and when are they important for your analysis?\n\n3) How will you decide whether a customer will buy a product today or not given the income of the customer, location where the customer lives, profession and gender? Define a machine learning algorithm for this.\n\n4) From a long sorted list and a short 4 element sorted list, which algorithm will you use to search the long sorted list for 4 elements.\n\n5) How can you compare a neural network that has one layer, one input and output to a logistic regression model?\n\n6) How do you treat colinearity?\n\n7) How will you deal with unbalanced data where the ratio of negative and positive is huge?\n\n8) What is the difference between -\n\ni) Stack and Queue\n\nii) Linkedin and Array\n\n\n\n\nUber Data Science Interview Questions\n\n1) Will Uber cause city congestion?\n\n2) What are the metrics you will use to track if Uber’s paid advertising strategies to acquire customers work? How will you figure out the acceptable cost of customer acquisition?\n\n3) Explain principal components analysis with equations.\n\n4) Explain about the various time series forecasting technqiues.\n\n5) Which machine learning algorithm will you use to solve a Uber driver accepting  request?\n\n6)How will you compare the results of various machine learning algorithms?\n\n7) How to solve multi-collinearity?\n\n8) How will you design the heatmap for Uber drivers to provide recommendation on where to wait for passengers? How would you approach this?\n\n9) If we added one rider to the current SF market, how would that affect the existing riders and drivers?  \n\n10) What are the different performance metrics for evaluating Uber services?\n\n11) How will you decide which version (Version 1 or Version 2) of the Surge Pricing Algorithms is working better for Uber ?\n\n12) How will you explain JOIN function in SQL to a 10 year old ?\n\n\n\n\nNetflix Data Science Interview Questions\n\n1) How can you build and test a metric to compare ranked list of TV shows or Movies for two Netflix users?\n\n2) How can you decide if one algorithm is better than the other?\n\n\n\n\nMicrosoft Data Science Interview Questions\n\n1) Write a function to check whether a particular word is a palindrome or not.\n\n2) How can you compute an inverse matrix faster by playing with some computation tricks?\n\n3) You have a bag with 6 marbles. One marble is white.  You reach the bag 100 times. After taking out a marble, it is placed back in the bag. What is the probability of drawing a white marble at least once?\n\n\nApple Data Science Interview Questions\n\n1) How do you take millions of users with 100's of transactions each, amongst 10000's of products and group the users together in a meaningful segments?\n\n\n\nAdobe Data Scientist Interview Questions\n\n1) Check whether a given integer is a palindrome or not without converting it to a string.\n\n2) What is the degree of freedom for lasso?\n\n3) You have two sorted array of integers, write a program to find a number from each array such that the sum of the two numbers is closest to an integer i.\n\n\n\n\nAmerican Express Data Scientist Interview Questions\n\n1) Suppose that American Express has 1 million card members along with their transaction details. They also have 10,000 restaurants and 1000 food coupons. Suggest a method which can be used to pass the food coupons to users given that some users have already received the food coupons so far.\n\n2) You are given a training dataset of users that contain their demographic details, the pages on Facebook they have liked so far and results of psychology test  based on their personality i.e. their openness to like FB pages or not. How will you predict the age, gender and other demographics of unseen data?\n\n\n\nQuora Data Scientist Interview Questions\n\n1) How will you test a machine learning model for accuracy?\n\n2) Print the elements of a matrix in zig-zag manner.\n\n3) How will you overcome overfitting in predictive models?\n\n4) Develop an algorithm to sort two lists of sorted integers into a single list.\n\n\n\nGoldman Sachs Data Scientist Interview Questions\n\n1) Count the total number of trees in United States.\n\n2) Estimate the number of square feet pizza’s eaten in US each year.\n\n3) A box has 12 red cards and 12 black cards. Another box has 24 red cards and 24 black cards. You want to draw two cards at random from one of the two boxes, which box has a higher probability of getting cards of same colour and why?\n\n4) How will you prove that the square root of 2 is irrational?\n\n5) What is the probability of getting a HTT combination before getting a TTH combination?\n\n6) There are 8 identical balls and only one of the ball is slightly heavier than the others. You are given a balance scale to find the heavier ball. What is the least number of times you have to use the balance scale to find the heavier ball?\n\n\n\nWalmart Data Science Interview Questions\n\n1) Write the code to reverse a Linked list.\n\n2) What assumptions does linear regression machine learning algorithm make?\n\n3) A stranger uses a search engine to find something and you do not know anything about the person. How will you design an algorithm to determine what the stranger is looking for just after he/she types few characters in the search box?\n\n4) How will you fix multi-colinearity in a regression model?\n\n5) What data structures are available in the Pandas package in Python programming language?\n\n6) State some use cases where Hadoop MapReduce works well and where it does not.\n\n7) What is the difference between an iterator, generator and list comprehension in Python?\n\n8) What is the difference between a bagged model and a boosted model?\n\n9) What do you understand by parametric and non-parametric methods? Explain with examples.\n\n10) Have you used sampling? What are the various types of sampling have you worked with?\n\n\n\n\nIBM Data Science Interview Questions\n\n1) How will you handle missing data ?\n\n\n\n\n\nYammer Data Science Interview Questions\n\nHow can you solve a problem that has no solution?\nOn rolling a dice if you get $1 per dot on the upturned face,what are your expected earnings from rolling a dice?\nIn continuation with question #2, if you have 2 chances to roll the dice and you are given the opportunity to decide when to stop rolling the dice (in the first roll or in the second roll). What will be your rolling strategy to get maximum earnings?\n What will be your expected earnings with the two roll strategy?\nYou are creating a report for user content uploads every month and observe a sudden increase in the number of upload for the month of November. The increase in uploads is particularly in image uploads. What do you think will be the cause for this and how will you test this sudden spike?\nCiti Bank Data Science Interview Questions\n\n1) A dice is rolled twice, what is the probability that on the second chance it will be a 6?\n\n2) What are Type 1 and Type 2 errors ?\n\n3) Burn two ropes, one needs 60 minutes of time to burn and the other needs 30 minutes of time. How will you achieve this in 45 minutes of time ?\n\nData Science Interview Questions Asked at Other Top Tech Companies\n\n1) R programming language cannot handle large amounts of data. What are the other ways of handling it without using Hadoop infrastructure? (Asked at Pyro Networks)\n\n2) Explain the working of a Random Forest Machine Learning Algorithm (Asked at Cyient)\n\n3) Describe K-Means Clustering.(Asked at Symphony Teleca)\n\n4) What is the difference between logistic and linear regression? (Asked at Symphony Teleca)\n\n5) What kind of distribution does logistic regression follow? (Asked at Symphony Teleca)\n\n6) How do you parallelize machine learning algorithms? (Asked at Vodafone)\n\n7) When required data is not available for analysis, how do you go about collecting it? (Asked at Vodafone)\n\n8) What do you understand by heteroscadisticity (Asked at Vodafone)\n\n9) What do you understand by confidence interval? (Asked at Vodafone)\n\n10) Difference between adjusted r and r square. (Asked at Vodafone)\n\n11) How Facebook recommends items to newsfeed? (Asked at Finomena)\n\n12)  What do you understand by ROC curve and how is it used? (Asked at MachinePulse)\n\n13) How will you identify the top K queries from a file? (Asked at BloomReach)\n\n14) Given a set of webpages and changes on the website, how will you test the new website feature to determine if the change works positively? (Asked at BloomReach)\n\n15) There are N pieces of rope in a bucket. You put your hand into the bucket, take one end piece of the rope .Again you put your hand into the bucket and take another end piece of a rope. You tie both the end pieces together. What is the expected value of the number of loops within the bucket? (Asked at Natera)\n\n16) How will you test if a chosen credit scoring model works or not? What data will you look at? (Asked at Square)\n\n17) There are 10 bottles where each contains coins of 1 gram each. There is one bottle of that contains 1.1 gram coins. How will you identify that bottle after only one measurement? (Data Science Puzzle asked at Latent View Analytics)\n\n18) How will you measure a cylindrical glass filled with water whether it is exactly half filled or not? You cannot measure the water, you cannot measure the height of the glass nor can you dip anything into the glass. (Data Science Puzzle asked at Latent View Analytics)\n\n19) What would you do if you were a traffic sign? (Data Science Interview Question asked at Latent View Analytics)\n\n20)  If you could get the dataset on any topic of interest, irespective of the collection methods or resources then how would the dataset look like and what will you do with it. (Data Scientist Interview Question asked at CKM Advisors)\n\n21) Given n samples from a uniform distribution [0,d], how will you estimate the value of d? (Data Scientist Interview Question asked at Spotify)\n\n22) How will you tune a Random Forest? (Data Science Interview Question asked at Instacart).\n\n23) Tell us about a project where you have extracted useful information from a large dataset. Which machine learning algorithm did you use for this and why? (Data Scientist Interview Question asked at Greenplum)\n\n24) What is the difference between Z test and T test ? (Data Scientist Interview Questions asked at Antuit)\n\n25) What are the different models you have used for analysis and what were your inferences? (Data Scientist Interview Questions asked at Cognizant)\n\n26) Given the title of a product, identify the category and sub-category of the product. (Data Scientist interview question asked at Delhivery)\n\n27) What is the difference between machine learning and deep learning? ( Data Scientist Interview Question asked at InfoObjects)\n\n28) What are the different parameters in ARIMA models ? (Data Science Interview Question asked at Morgan Stanley)\n\n29) What are the optimisations you would consider when computing the similarity matrix for a large dataset? (Data Science Interview questions asked at MakeMyTrip)\n\n30) Use Python programming language to implement a toolbox with specific image processing tasks.(Data Science Interview Question asked at Intuitive Surgical)\n\n31) Why do you use Random Forest instead of a simple classifier for one of the classification problems ? (Data Science Interview Question asked at Audi)\n\n32) What is an n-gram? (Data Science Interview Question asked at Yelp)\n\n33) What are the problems related to Overfitting and Underfitting  and how will you deal with these ? (Data Science Interview Question asked at Tiger Analytics)\n\n34) Given a MxN dimension matrix with each cell containing an alphabet, find if a string is contained in it or not.(Data Science Interview Question asked at Tiger Analytics)\n\n35) How do you \"Group By\" in R programming language without making use of any package ? (Data Scientist Interview Question asked at OLX)\n\n36) List 15 features that you will make use of to build a classifier for OLX website.(Data Scientist Interview Question asked at OLX)\n\n37) How will you build a caching system using an advanced data structure like hashmap ? (Data Scientist Interview Question asked at OLX)\n\n38) How to reverse strings that have changing positions ? (Data Scientist Interview Question asked at Tiger Analytics)\n\nIf you are asked questions like what is your favourite leisure activity? Or something like what is that you like to do for fun?  Most of the people often tend to answer that they like to read programming books or do coding thinking that this is what they are supposed to say in a technical interview. Is this something you really do it for fun? A key point to bear in mind that the interviewer is also a person and interact with them as a person naturally. This will help the interviewer see you as an all-rounder who can visualize the company’s whole vision and not just view business problems from an academic viewpoint.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n##################################################################################################################\nbinary search :\n  if n==1 : return val\n\n\n  while true :\n   if left=mid : \n      return val\n   else :\n      left= FF(left, mid)\n      right= FF(mid+1, right)\n      final = Merge( left, right)\n\n\n\n\n##################\n#### Equilibrium point   \nint equi(int arr[], int n) {\n    if (n==0) return -1; \n    long long sum = 0;\n    int i; \n    for(i=0;i<n;i++) sum+=(long long) arr[i]; \n\n    long long sum_left = 0;    \n    for(i=0;i<n;i++) {\n        long long sum_right = sum - sum_left - (long long) arr[i];\n        if (sum_left == sum_right) return i;\n        sum_left += (long long) arr[i];\n    } \n    return -1; \n} \n\n\n\n\n##### Find Leader :  Sorting the table  in N*long_N\ndef solution(A): \n    n = len(A)\n    L = [-1] + A\n    L.sort()\n    count = 0\n    pos = (n + 1) // 2\n    candidate = L[pos]\n    for i in xrange(1, n + 1):\n        if (L[i] == candidate):\n            count = count + 1\n    if (2*count > n):\n        return candidate\n    return -1\n\n\n\n\n\n\n\n#########################################################################################################################\n#########################################################################################################################\nhttps://codility.com/programmers/lessons/3-time_complexity/frog_jmp/\n\n\nCodility ‘Tape Equilibrium’ Solution\nPosted on July 22, 2014 by Martin\nShort Problem Definition:\nMinimize the value |(A[0] + … + A[P-1]) – (A[P] + … + A[N-1])|.\n\nLink\nTapeEquilibrium\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nIn the first run I compute the left part up to the point i and the overall sum last. Then I compute the minimal difference between 0..i and i+1..n.\n\nSolution:\nimport sys\n \ndef solution(A):\n    #1st pass\n    parts = [0] * len(A)\n    parts[0] = A[0]\n  \n    for idx in xrange(1, len(A)):\n        parts[idx] = A[idx] + parts[idx-1]\n  \n    #2nd pass\n    solution = sys.maxint\n    for idx in xrange(0, len(parts)-1):\n        solution = min(solution, abs(parts[-1] - 2 * parts[idx]));  \n  \n    return solution\n\n\n\n#########################################################################################################################\nShort Problem Definition:\nCount minimal number of jumps from position X to Y.\n\nLink\nFrogJmp\n\nComplexity:\nexpected worst-case time complexity is O(1);\n\nexpected worst-case space complexity is O(1).\n\nExecution:\nDo not use float division if possible!\n\nSolution:\ndef solution(X, Y, D):\n    if Y < X or D <= 0:\n        raise Exception(\"Invalid arguments\")\n         \n    if (Y- X) % D == 0:\n        return (Y- X) // D\n    else:\n        return ((Y- X) // D) + 1\n\n\n\n\n######################################################################################################\nShort Problem Definition:\nFind the missing element in a given permutation.\n\nLink\nPermMissingElem\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(1)\n\nExecution:\nSum all elements that should be in the list and sum all elements that actually are in the list. The sum is 0 based, so +1 is required. The first solution using the + operator can cause int overflow in not-python languages. Therefore the use of a binary XOR is adequate.\n\nSolution:\ndef solution(A):\n    should_be = len(A) # you never see N+1 in the iteration\n    sum_is = 0\n \n    for idx in xrange(len(A)):\n        sum_is += A[idx]\n        should_be += idx+1\n \n    return should_be - sum_is +1\n\n\n\n\n###################################################################################################\nShort Problem Definition:\nCheck whether array N is a permutation.\n\nLink\nPermCheck\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nMark elements as seen in a boolean array. Elements seen twice or out of bounds of the size indicate that the list is no permutation. The check if the boolean array only contains true elements is not required. This solution only works with permutations starting from 1.\n\nSolution:\n\ndef solution(A):\n    seen = [False] * len(A)\n \n    for value in A:\n        if 0 <= value > len(A):\n            return 0\n        if seen[value-1] == True:\n            return 0\n        seen[value-1] = True\n \n    return 1\n\n\n\n\n###################################################################################################\nShort Problem Definition:\nFind the earliest time when a frog can jump to the other side of a river.\n\nLink\nFrogRiverOne\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(X)\n\nExecution:\nMark seen elements as such in a boolean array. I do not like the idea of returning the first second as 0. But specifications are specifications ????\n\nSolution:\ndef solution(X, A):\n    passable = [False] * X\n    uncovered = X\n \n    for idx in xrange(len(A)):\n        if A[idx] <= 0 or A[idx] > X:\n            raise Exception(\"Invalid value\", A[idx])\n        if passable[A[idx]-1] == False:\n            passable[A[idx]-1] = True\n            uncovered -= 1\n            if uncovered == 0:\n                return idx\n \n    return -1\n\n\n\n###################################################################################################\nShort Problem Definition:\nCalculate the values of counters after applying all alternating operations: increase counter by 1; set value of all counters to current maximum.\n\nLink\nMaxCounters\n\nComplexity:\nexpected worst-case time complexity is O(N+M);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nThe idea is to perform the specified operation as stated. It is not required to iterate over the whole array if a new value is set for all the values. Just save the value and check it when an increase on that position is performed.\n\nSolution:\n#include <algorithm>\n \nvector<int> solution(int N, vector<int> &A) {\n    vector<int> sol;\n    int current_max = 0;\n    int last_increase = 0;\n \n    for(int i=0; i<N;i++){\n        sol.push_back(0);\n    }\n \n    for(unsigned int i=0; i<A.size();i++){\n        if (A[i] > N) {\n            last_increase = current_max;\n        } else {\n            sol[A[i]-1] = max(sol[A[i]-1], last_increase);\n            sol[A[i]-1]++;\n            current_max = max(current_max, sol[A[i]-1]);\n        }\n    }\n \n    for(int i=0; i<N;i++){\n        sol[i] = max(sol[i], last_increase);\n    }\n \n    return sol;\n}\n\n\n\n###################################################################################################\nShort Problem Definition:\nFind the minimal positive integer not occurring in a given sequence.\n\nLink\nMissingInteger\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nYou only need to consider the first (N) positive integers. In this specification 0 does not count as a valid candidate! Any value that is below 1 or above N can be ignored.\n\nSolution:\ndef solution(A):\n    seen = [False] * len(A)\n    for value in A:\n        if 0 < value <= len(A):\n            seen[value-1] = True\n \n    for idx in xrange(len(seen)):\n        if seen[idx] == False:\n            return idx + 1\n \n    return len(A)+1\n\n\n\n\n\n\n\n###################################################################################################\nShort Problem Definition:\nCount the number of passing cars on the road.\n\nLink\nPassingCars\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(1)\n\nExecution:\nCount all cars heading in one direction (west). Each car heading the other direction (east) passes all cars that went west so far. Note that east cars at the beginning of the list pass no cars! Also do not forget the upper limit!\n\nSolution:\ndef solution(A):\n    west_cars = 0\n    cnt_passings = 0\n \n    for idx in xrange(len(A)-1, -1, -1):\n        if A[idx] == 0:\n            cnt_passings += west_cars\n            if cnt_passings > 1000000000:\n                return -1\n        else:\n            west_cars += 1\n \n    return cnt_passings\n\n\n\n\n######################################################################################################\nShort Problem Definition:\nFind the minimal nucleotide from a range of sequence DNA.\n\nLink\nGenomicRangeQuery\n\nComplexity:\nexpected worst-case time complexity is O(N+M);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nRemember the last position on which was the genome (A, C, G, T) was seen. If the distance between Q and P is lower than the distance to the last seen genome, we have found the right candidate.\n\nSolution:\ndef writeCharToList(S, last_seen, c, idx):\n    if S[idx] == c:\n        last_seen[idx] = idx\n    elif idx > 0:\n        last_seen[idx] = last_seen[idx -1]\n \ndef solution(S, P, Q):\n     \n    if len(P) != len(Q):\n        raise Exception(\"Invalid input\")\n     \n    last_seen_A = [-1] * len(S)\n    last_seen_C = [-1] * len(S)\n    last_seen_G = [-1] * len(S)\n    last_seen_T = [-1] * len(S)\n         \n    for idx in xrange(len(S)):\n        writeCharToList(S, last_seen_A, 'A', idx)\n        writeCharToList(S, last_seen_C, 'C', idx)\n        writeCharToList(S, last_seen_G, 'G', idx)\n        writeCharToList(S, last_seen_T, 'T', idx)\n     \n     \n    solution = [0] * len(Q)\n     \n    for idx in xrange(len(Q)):\n        if last_seen_A[Q[idx]] >= P[idx]:\n            solution[idx] = 1\n        elif last_seen_C[Q[idx]] >= P[idx]:\n            solution[idx] = 2\n        elif last_seen_G[Q[idx]] >= P[idx]:\n            solution[idx] = 3\n        elif last_seen_T[Q[idx]] >= P[idx]:\n            solution[idx] = 4\n        else:    \n            raise Exception(\"Should never happen\")\n         \n    return solution\n\n\n\n######################################################################################################\nShort Problem Definition:\nCompute number of integers divisible by k in range [a..b].\n\nLink\nCountDiv\n\nComplexity:\nexpected worst-case time complexity is O(1);\n\nexpected worst-case space complexity is O(1)\n\nExecution:\nThis little check required a bit of experimentation. One needs to start from the first valid value that is bigger than A and a multiply of K.\n\nSolution:\ndef solution(A, B, K):\n    if B < A or K <= 0:\n        raise Exception(\"Invalid Input\")\n \n    min_value =  ((A + K -1) // K) * K\n \n    if min_value > B:\n      return 0\n \n    return ((B - min_value) // K) + 1\n\n\n\n\n\n\n\n\n\n######################################################################################################\nShort Problem Definition:\nDetermine whether a given string of parentheses is properly nested.\n\nLink\nBrackets\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nPut every opening bracket on a stack. If a closing bracket is not the same as the top stack bracket, the string is not properly nested.\n\nSolution:\ndef isValidPair(left, right):\n    if left == '(' and right == ')':\n        return True\n    if left == '[' and right == ']':\n        return True \n    if left == '{' and right == '}':\n        return True   \n    return False\n \ndef solution(S):\n    stack = []\n     \n    for symbol in S:\n        if symbol == '[' or symbol == '{' or symbol == '(':\n            stack.append(symbol)\n        else:\n            if len(stack) == 0:\n                return 0\n            last = stack.pop()\n            if not isValidPair(last, symbol):\n                return 0\n     \n    if len(stack) != 0:\n        return 0\n             \n    return 1\n\n\n######################################################################################################\n\n\n\n\n######################################################################################################\nCodility ‘MaxSliceSum’ Solution\nPosted on January 6, 2015 by Martin\nShort Problem Definition:\nFind a maximum sum of a compact subsequence of array elements.\n\nLink\nMaxSliceSum\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nThe only difference to the example given by Codility is the minimal slice length, which is 1.\n\n\nSolution:\ndef solution(A):\n    max_ending = max_slice = -1000000\n    for a in A:\n        max_ending = max(a, max_ending +a)\n        max_slice = max(max_slice, max_ending)\n         \n    return max_slice\n\n\n\n######################################################################################################\nCodility ‘MaxDoubleSliceSum’ Solution\nPosted on December 30, 2014 by Martin\nShort Problem Definition:\nFind the maximal sum of any double slice.\nA non-empty zero-indexed array A consisting of N integers is given.\n\nA triplet (X, Y, Z), such that 0 ≤ X < Y < Z < N, is called a double slice.\nThe sum of double slice (X, Y, Z) is the total of A[X + 1] + A[X + 2] + ... + A[Y − 1] + A[Y + 1] + A[Y + 2] + ... + A[Z − 1].\nFor example, array A such that:\n\n    A[0] = 3\n    A[1] = 2\n    A[2] = 6\n    A[3] = -1\n    A[4] = 4\n    A[5] = 5\n    A[6] = -1\n    A[7] = 2\ncontains the following example double slices:\n\ndouble slice (0, 3, 6), sum is 2 + 6 + 4 + 5 = 17,\ndouble slice (0, 3, 7), sum is 2 + 6 + 4 + 5 − 1 = 16,\ndouble slice (3, 4, 5), sum is 0.\n\n\n\nLink\nMaxDoubleSliceSum\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nTo solve this task, you need to keep track of two slice arrays. The optimal double slice can be found at an index that has the maximal sum of those two arrays. It can not be the 0th or the last index.\n\n### Solution:\ndef solution(A):\n    ending_here = [0] * len(A)\n    starting_here = [0] * len(A)\n     \n    for idx in xrange(1, len(A)):\n        ending_here[idx] = max(0, ending_here[idx-1] + A[idx])\n     \n    for idx in reversed(xrange(len(A)-1)):\n        starting_here[idx] = max(0, starting_here[idx+1] + A[idx])\n     \n    max_double_slice = 0\n     \n    for idx in xrange(1, len(A)-1):\n        max_double_slice = max(max_double_slice, starting_here[idx+1] + ending_here[idx-1])\n         \n         \n    return max_double_slice\n\n\n\n\n######################################################################################################\ndef sieve(N):\n    semi = set()\n    sieve = [True]* (N+1)\n    sieve[0] = sieve[1] = False\n \n    i = 2\n    while (i*i <= N):\n        if sieve[i] == True:\n            for j in xrange(i*i, N+1, i):\n                sieve[j] = False\n        i += 1\n \n    i = 2\n    while (i*i <= N):\n        if sieve[i] == True:\n            for j in xrange(i*i, N+1, i):\n                if (j % i == 0 and sieve[j/i] == True):\n                    semi.add(j)\n        i += 1\n \n    return semi\n \ndef solution(N, P, Q):\n \n    semi_set = sieve(N)\n \n    prefix = []\n \n    prefix.append(0) # 0\n    prefix.append(0) # 1\n    prefix.append(0) # 2\n    prefix.append(0) # 3\n    prefix.append(1) # 4\n \n    for idx in xrange(5, max(Q)+1):\n        if idx in semi_set:\n            prefix.append(prefix[-1]+1)\n        else:\n            prefix.append(prefix[-1])\n \n    solution = []\n \n    for idx in xrange(len(Q)):\n        solution.append(prefix[Q[idx]] - prefix[P[idx]-1])\n \n    return solution\n\n\n\n\n######################################################################################################\nCodility ‘FibFrog’ Solution\nPosted on December 28, 2014 by Martin\nShort Problem Definition:\nCount the minimum number of jumps required for a frog to get to the other side of a river.\n\nThe Fibonacci sequence is defined using the following recursive formula:\n\n    F(0) = 0\n    F(1) = 1\n    F(M) = F(M - 1) + F(M - 2) if M >= 2\nA small frog wants to get to the other side of a river. The frog is initially located at one bank of the river (position −1) and wants to get to the other bank (position N). The frog can jump over any distance F(K), where F(K) is the K-th Fibonacci number. Luckily, there are many leaves on the river, and the frog can jump between the leaves, but only in the direction of the bank at position N.\n\nThe leaves on the river are represented in a zero-indexed array A consisting of N integers. Consecutive elements of array A represent consecutive positions from 0 to N − 1 on the river. Array A contains only 0s and/or 1s:\n\n0 represents a position without a leaf;\n1 represents a position containing a leaf.\nThe goal is to count the minimum number of jumps in which the frog can get to the other side of the river (from position −1 to position N). The frog can jump between positions −1 and N (the banks of the river) and every position containing a leaf.\n\nFor example, consider array A such that:\n\n    A[0] = 0\n    A[1] = 0\n    A[2] = 0\n    A[3] = 1\n    A[4] = 1\n    A[5] = 0\n    A[6] = 1\n    A[7] = 0\n    A[8] = 0\n    A[9] = 0\n    A[10] = 0\nThe frog can make three jumps of length F(5) = 5, F(3) = 2 and F(5) = 5.\n\n\n\nLink\nFibFrog\n\nComplexity:\nexpected worst-case time complexity is O(N*log(N))\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nThis problem can be solved by in a Dynamic Programming way. You need to know the optimal count of jumps that can reach a given leaf. You get those by either reaching the leaf from the first shore or by reaching it from another leaf.\n\nThe N*log(N) time complexity is given by the fact, that there are approximately log(N) Fibonacci numbers up to N and you visit each position once.\n\nAs for the sequence hack: there are 26 Fibonacci numbers smaller than 100k, so I just preallocate an array of this size.\n\nSolution:\ndef get_fib_seq_up_to_n(N):\n    # there are 26 numbers smaller than 100k\n    fib = [0] * (27)\n    fib[1] = 1\n    for i in xrange(2, 27):\n        fib[i] = fib[i - 1] + fib[i - 2]\n        if fib[i] > N:\n            return fib[2:i]\n        else:\n            last_valid = i\n     \n     \n     \ndef solution(A):\n    # you can always step on the other shore, this simplifies the algorithm\n    A.append(1)\n \n    fib_set = get_fib_seq_up_to_n(len(A))\n     \n    # this array will hold the optimal jump count that reaches this index\n    reachable = [-1] * (len(A))\n     \n    # get the leafs that can be reached from the starting shore\n    for jump in fib_set:\n        if A[jump-1] == 1:\n            reachable[jump-1] = 1\n     \n    # iterate all the positions until you reach the other shore\n    for idx in xrange(len(A)):\n        # ignore non-leafs and already found paths\n        if A[idx] == 0 or reachable[idx] > 0:\n            continue\n \n        # get the optimal jump count to reach this leaf\n        min_idx = -1\n        min_value = 100000\n        for jump in fib_set:\n            previous_idx = idx - jump\n            if previous_idx < 0:\n                break\n            if reachable[previous_idx] > 0 and min_value > reachable[previous_idx]:\n                min_value = reachable[previous_idx]\n                min_idx = previous_idx\n        if min_idx != -1:\n            reachable[idx] = min_value +1\n \n    return reachable[len(A)-1]\n\n\n\n\n######################################################################################################\nCodility ‘AbsDistinct’ Solution\nPosted on August 14, 2014 by Martin\nShort Problem Definition:\nCompute number of distinct absolute values of sorted array elements.\n\nLink\nAbsDistinct\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nAdditional storage is allowed. Therefore a simple python solution will suffice.\n\nSolution:\ndef solution(A):\n    return len(set([abs(x) for x in A]))\n\n\n\n\n######################################################################################################\nCodility ‘TieRopes’ Solution\nPosted on August 25, 2014 by Martin\nShort Problem Definition:\nTie adjacent ropes to achieve the maximum number of ropes of length >= K.\n\nThere are N ropes numbered from 0 to N − 1, whose lengths are given in a zero-indexed array A, lying on the floor in a line. For each I (0 ≤ I < N), the length of rope I on the line is A[I].\n\nWe say that two ropes I and I + 1 are adjacent. Two adjacent ropes can be tied together with a knot, and the length of the tied rope is the sum of lengths of both ropes. The resulting new rope can then be tied again.\n\nFor a given integer K, the goal is to tie the ropes in such a way that the number of ropes whose length is greater than or equal to K is maximal.\n\nFor example, consider K = 4 and array A such that:\n\n    A[0] = 1\n    A[1] = 2\n    A[2] = 3\n    A[3] = 4\n    A[4] = 1\n    A[5] = 1\n    A[6] = 3\n\nWe can tie:\n\nrope 1 with rope 2 to produce a rope of length A[1] + A[2] = 5;\nrope 4 with rope 5 with rope 6 to produce a rope of length A[4] + A[5] + A[6] = 5.\nAfter that, there will be three ropes whose lengths are greater than or equal to K = 4. It is not possible to produce four such ropes.\nFor example, given K = 4 and array A such that:\n\n    A[0] = 1\n    A[1] = 2\n    A[2] = 3\n    A[3] = 4\n    A[4] = 1\n    A[5] = 1\n    A[6] = 3\nthe function should return 3, as explained above.\n\n\nLink\nTieRopes\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nI am a bit skeptical about the correctness of my solution. It gets 100/100 through…\n\nSolution:\ndef solution(K, A):\n    cnt = 0\n    current = 0\n    for part in A:\n        current += part\n        if current >= K:\n            cnt +=1\n            current = 0\n \n    return cnt\n######################################################################################################\n\n\n\n######################################################################################################\nCodility ‘Max Nonoverlapping Segments’ Solution\nShort Problem Definition:\nFind a maximal set of non((-))overlapping segments.\n\n\nLocated on a line are N segments, numbered from 0 to N − 1, whose positions are given in zero-indexed arrays A and B. For each I (0 ≤ I < N) the position of segment I is from A[I] to B[I] (inclusive). The segments are sorted by their ends, which means that B[K] ≤ B[K + 1] for K such that 0 ≤ K < N − 1.\n\nTwo segments I and J, such that I ≠ J, are overlapping if they share at least one common point. In other words, A[I] ≤ A[J] ≤ B[I] or A[J] ≤ A[I] ≤ B[J].\n\nWe say that the set of segments is non-overlapping if it contains no two overlapping segments. The goal is to find the size of a non-overlapping set containing the maximal number of segments.\n\nFor example, consider arrays A, B such that:\n\n    A[0] = 1    B[0] = 5\n    A[1] = 3    B[1] = 6\n    A[2] = 7    B[2] = 8\n    A[3] = 9    B[3] = 9\n    A[4] = 9    B[4] = 10\nThe segments are shown in the figure below.\n\n\n\nThe size of a non-overlapping set containing a maximal number of segments is 3. For example, possible sets are {0, 2, 3}, {0, 2, 4}, {1, 2, 3} or {1, 2, 4}. There is no non-overlapping set with four segments.\n\nWrite a function:\n\ndef solution(A, B)\n\nthat, given two zero-indexed arrays A and B consisting of N integers, returns the size of a non-overlapping set containing a maximal number of segments.\n\nFor example, given arrays A, B shown above, the function should return 3, as explained above.\n\nAssume that:\n\nN is an integer within the range [0..30,000];\neach element of arrays A, B is an integer within the range [0..1,000,000,000];\nA[I] ≤ B[I], for each I (0 ≤ I < N);\nB[K] ≤ B[K + 1], for each K (0 ≤ K < N − 1).\nComplexity:\n\nexpected worst-case time complexity is O(N);\nexpected worst-case space complexity is O(N), beyond input storage (not counting the storage required for input arguments).\nElements of input arrays can be modified.\n\n\nLink\nMaxNonoverlappingSegments\n\nComplexity:\nexpected worst-case time complexity is O(N)\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nThis can be solved by using greedy search. The beginning of the next segment must come strictly after its predecessor.\n\nSolution:\ndef solution(A, B):\n    if len(A) < 1:\n        return 0\n     \n    cnt = 1\n    prev_end = B[0]\n     \n    for idx in xrange(1, len(A)):\n        if A[idx] > prev_end:\n            cnt += 1\n            prev_end = B[idx]\n     \n    return cnt\n\n\n\n\n######################################################################################################\nCodility ‘BinaryGap’ Solution\nPosted on August 2, 2014 by Martin\nShort Problem Definition:\nFind longest sequence of zeros in binary representation of an integer.\n\nLink\nBinaryGap\n\nComplexity:\nexpected worst-case time complexity is O(log(N));\n\nexpected worst-case space complexity is O(1)\n\nExecution:\nThe solution is straight-forward! Use of binary shift.\n\nSolution:\ndef solution(N):\n    cnt = 0\n    result = 0\n    found_one = False\n \n    i = N    \n         \n    while i:\n        if i & 1 == 1:\n            if (found_one == False):\n                found_one = True\n            else:\n                result = max(result,cnt)\n            cnt = 0\n        else:\n            cnt += 1\n        i >>= 1\n    \n    return result\n\n\n\n######################################################################################################\nShort Problem Definition:\nFind a symmetry point of a string, if any.\n\nLink\nStrSymmetryPoint\n\nComplexity:\nexpected worst-case time complexity is O(length(S));\n\nexpected worst-case space complexity is O(1) (not counting the storage required for input arguments).\n\nExecution:\nThis problem gave me a lot of headache. It is so trivial I that over-complicated it. I thought that you should find a symmetry point at any possible position, ignoring the residual characters. You would obviously try to maximize the length of this symmetrical sub-array. I was not able to come with any O(S) algorithm for this problem derivation. So just to remind you, this problem is a simple palindrome check. Additionally, you drop all evenly sized strings as their symmetry point is between the indexes.\n\nSolution:\ndef solution(S):\n    l = len(S)\n \n    if l % 2 == 0:\n        return -1\n \n    mid_point = l // 2\n \n    for idx in xrange(0, mid_point):\n        if S[idx] != S[l - idx - 1]:\n            return -1\n \n    return mid_point\n\n\n\n\n\n######################################################################################################\nCodility ‘OddOccurrencesInArray’ Solution\nFind value that occurs in odd number of elements.\n\nLink\nOddOccurrencesInArray\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(1)\n\nExecution:\nThis problem can be found in many algorithm books. A xor A cancels itself and B xor 0 is B. Therefore A xor A xor B xor C xor C is B.\n\nSolution:\ndef solution(A):\n    missing_int = 0\n    for value in A:\n        missing_int ^= value\n    return missing_int\n\n\n\n\n\n######################################################################################################\nCodility ‘TreeHeight’ Solution\nShort Problem Definition:\nCompute the height of a binary link-tree.\n\nLink\nTreeHeight\n\nComplexity:\nexpected worst-case time complexity is O(N);\n\nexpected worst-case space complexity is O(N)\n\nExecution:\nThe height of a tree is the maximal height +1 of its subtrees. In this specification a tree with just the root node has a height of 0.\n\nSolution:\n'''\nclass Tree(object):\n  x = 0\n  l = None\n  r = None\n'''\n \ndef getHeight(sub_T):\n    if sub_T == None:\n        return 0\n    return max(getHeight(sub_T.l), getHeight(sub_T.r))+1\n \ndef solution(T):\n    return max(getHeight(T.l), getHeight(T.r))\n\n\n\n\n\n######################################################################################################\nCodility ‘CyclicRotation’ Solution\nPosted on January 19, 2016 by Martin\nShort Problem Definition:\nRotate an array to the right by a given number of steps.\n\nLink\nCyclic Rotation\n\nComplexity:\nexpected worst-case time complexity is O(N)\n\nExecution:\nThere are multiple solutions to this problem. I picked the one that does not create a copy of the array.\n\nSolution:\ndef reverse(arr, i, j):\n    for idx in xrange((j - i + 1) / 2):\n        arr[i+idx], arr[j-idx] = arr[j-idx], arr[i+idx]\n \ndef solution(A, K):\n    l = len(A)\n    if l == 0:\n        return []\n         \n    K = K%l\n     \n    reverse(A, l - K, l -1)\n    reverse(A, 0, l - K -1)\n    reverse(A, 0, l - 1)\n \n    return A\n\n\n\n\n######################################################################\ndef solution(A) :\n  n= len(A)\n  \n  def isequi(k) :\n    if k==0  : \n      if 0==sum(A[k+1:]) : return 1\n   \n    if k== n-1 :\n      if sum(A[0:k-1])==0 : return 1\n      \n    \n    if sum(A[:k-1+1]) ==  sum(A[k+1:]) : return 1\n    else : return 0\n\n  l1= []\n  for k in xrange(0, n) :\n     if isequi(k) : \n         l1.append(k)\n\n  if len(l1) ==0 : return -1\n  else : return l1[0]\n  \n  \n\nFor example, consider the following array A consisting of N = 8 elements:\n\n  A[0] = -1\n  A[1] =  3\n  A[2] = -4\n  A[3] =  5\n  A[4] =  1\n  A[5] = -6\n  A[6] =  2\n  A[7] =  1\nP = 1 is an equilibrium index of this array, because:\n\nA[0] = −1 = A[2] + A[3] + A[4] + A[5] + A[6] + A[7]\nP = 3 is an equilibrium index of this array, because:\n\nA[0] + A[1] + A[2] = −2 = A[4] + A[5] + A[6] + A[7]\nP = 7 is also an equilibrium index, because:\n\nA[0] + A[1] + A[2] + A[3] + A[4] + A[5] + A[6] = 0\n\n\n\nWrite a function:\n\ndef solution(A)\n\nthat, given a zero-indexed array A consisting of N integers, returns any of its equilibrium indices. \nThe function should return −1 if no equilibrium index exists.\n\n\n##########################################################################################################\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest cases\n\nSo far, their test cases follow a predictable methodology :\n\nthe examples provided are explicitly tested\nCorrectness tests\n\nan empty or zero test case is devised and tested - the expected result is often not explicit or obvious, but will actually be there implicitly, such that you may not realise it is indeed specified until you work out what the answer should be.\na minimal test case - using just one input, or whatever is the absolute minimal conceiveable input - again, probably not explicitly described, but there implicitly nonetheless\nedge cases - test cases written to root out those awkward -off-by-one- scenarios that inevitably suck up 80% of the time required to devise a solution\na simple, or 'small' test case or two - just some basic, as you might reasonably anticipate, examples\nPerformance tests\n\nworst case scenario is tested - the biggest possible numbers in the biggest resultsets - with the intent to test the speed and space restraints\nnot always, as the problem dictates, some medium sized test cases eg: ~100 - ~5000 length arrays\nalways some 'extreme' test cases typically involving generating maximal random datasets\nOther notes\n\nyou're safe to assume they won't test, mark you down for, failing to guard against the explicit assumptions described. So if it says N is 0..1000, they won't feed in an N=1001 just to see if you protected against it.\nthe \"Open reading material\", currently at the top of each lesson, is worth reading before attempting the exercises as they are short and focus exactly on what you'll need to solve the following puzzles\nduring the actual interview testing/exam, the report sent to the candidate is much more sparesly detailed than the one sent to the company?!\nif you use the browser to actually build your solution - every edit and run is recorded and presented to the client\nif you are given multiple tasks, you are permitted to read them, and commence them, and submit them in any order.\n\n\nif there seems to be a lack of specificity in every puzzle around what is the correct response to error conditions; \n\nlook, read, look again, as after seeing the solution that apparent lack always seems like a debateably reasonable assumption implied by the specs. For example:\n\"MissingInteger\" (Lesson 4) does not specify the correct response if the input sequence is [-1,-2,-3]: there are no positive integers so what is the correct response? The 'minimal positive integer' is 1.\nSimilarly, it does not explicitly state that if the input set is full (no integers are missing) then return the largest value—plus one. Again, seems perfectly reasonable in hindsight, but a source of uncertainty in the moment\nbefore submitting your solution, there is no feedback regarding it's efficiency; but it does affect your score and report\nUnderstanding the O factors reveals the nature of the optimal solution:\nO(1) there is a formulaic solution\nO(n) the solution has no nested loops and all happens in a single pass\nO(n+m) the solution has no nested loops, and passes over n and m only once\nO(n+n) the solution has no nested loops, but you can pass over the sequence twice\nO(n*n) the solution has a loop through n nested inside a loop through n\nthe python in operator is a list loop and could contribute an O(N) all on it's own. ie:\nfoo in bar is ok if bar is a dictionary, but a potential problem if bar is a list\nfoo in bar.keys() is a nested loop (sequentially visiting every item in the list of keys)\ncoming up with reasonable test cases, and determining the correct answers, is half the puzzle! Passing the example is not enough. Every puzzle is subjected to 'simple' tests, not unlike the one provided, and 'medium' tests- which involve arrays of significant length, to be sure you pass these tests you need to work out some way to generate a sizeable test sequence but still know the correct answer. Then there are the 'maximal' tests which seek to max-out the size and complexity so, to be certain of 100%, you need to devise tests-and the correct answers-for that too.\n\n\n\n##########################################################################################################\n\nhttps://cloud.google.com/compute/docs/instances/adding-removing-ssh-keys\n\nhttps://cloud.google.com/compute/docs/api/how-tos/authorization\n\n\n\n\n\n\n\n\n\n\n\n#############################################################\nサーバ構成\n\nPROD環境\nPROD(STG)環境 ← PRODと全く同じ構成 Hot Standby的なイメージ\nTEST環境\nPROD環境はどちらもRAILS_ENVはPRODで動かします。\nTEST環境はSTGで動かします。\n\n※PROD, PROD(STG)の場合分けはENVではできないので、\n　.envにマッピングされるインスタンスメタデータで設定値を分ける形になります。\n\nSDK設置場所情報\n\n- プロジェクト名：beaconbank-core\n- バケット名：beaconbank-sdk\n- フォルダ構成： (OS種別)/(バージョン)/sdkファイル(zip形式)\n    - Android SDK -> Android/v1.0.0/BeaconBank_AndroidSDK.zip\n    - iOS SDK -> iOS/v1.0.0/BeaconBank_iOSSDK.zip\nGCSアクセス用証明書\njson beaconbank-core-ffaada3635a8.json\n\nTEST環境情報\n\nプロジェクトID: test-beaconbank-biz\nドメイン: t-biz.beaconbank.jp\n\nサービスアカウント用 JSON ファイル\n Key_JSON_for_GCE_test-biz\n\nLB: 130.211.24.62\nWEB01(Redis): エフェメラルIP(可変)\nWEB02: エフェメラルIP(可変)\n\nDBユーザ: beaconbank\nDBパスワード: 8gRs1T4H\n\nCORE_DBユーザ: bizbb\nCORE_DBパスワード: KPhgZtW7sUpX\n\nログの退避先: gs://test-biz-documents\n※サーバ内部ではlogrotateさせていて、\n※cronで毎朝2時にnginx, application, redisのログをCloudStorageに投げるようになっています。\n※applicationログの詳細はアプリケーションログ を参照\n\n※Cloud SQLに接続方法はsystemdに登録されたCloud SQL Proxyを使用しています。\n　各インスタンス内からmysql -u [USER] -p -h 127.0.0.1で接続できます。\n\n※GCPは同N/W上であればインスタンス名で接続できるので、redisはインスタンス名をhostとして接続する\n\nサーバ構成\n\n※全てGCP内リソース\n\nロードバランサ * 1台\nWEBサーバ + Redisサーバ * 1台\nWEBサーバ * 1台\nCloud SQL * 1台\n構成管理\n\nリソース管理（インスタンスの作成等）\nGoogle Cloud Deployment Manager\nミドル管理（nginx, ruby等のインストール）\nitamae\nデプロイ（railsアプリケーションのデプロイ）\nCapistrano（ローカル実行）\n外部連携も多いとのことで任意のタイミングでデプロイできるのがのぞましいとのことだったのでCircle CIに組み込まずローカルからcap deployで実行を想定\n構築手順\n\nGCPリソースのデプロイ\n\ndown\n[インフラ] Deployment Managerの使い方\nlink https://unerry.docbase.io/posts/215812\n\nプロビジョニング\n\ndown\n[インフラ] itamaeの使い方\nlink https://unerry.docbase.io/posts/216009\n\n秘匿情報の配置\n\n秘匿情報はbiz-envリポジトリで管理します。\n\n事前準備\n\n配置スクリプトでjqコマンドを使用するので事前にインストールしてください。\nbiz-envリポジトリルートに移動してデプロイ先の秘密鍵をssh-agentに登録します。\n\ncd biz-env/\nssh-add <xxx.biz-deploy-key> # xxx は dev|test|staging|production\n.envの配置\n\n./upload_env.sh <env> # envはdev|test|staging|production\nGCEアクセス証明書の配置\n\n./upload_key_json.sh <env> # envはdev|test|staging|production\nhtaccessの配置\n\n./upload_htaccess.sh <env> # envはdev|test|staging\nデプロイ\n\ndeployユーザのデプロイキー\n deploy_stg\nリモートからgithubへの接続必要なのでssh-agentに登録してから実行してください。\n\n注意事項\nサーバIPが変わる可能性があるのでgcloudコマンドからbiz-webNNというインスタンス名のインスタンスIPを取得してデプロイするようになっています。\ngcloudコマンドこちらからインストール・設定してください。\nソースデプロイとDBマイグレーションはtaskを分けています。マイグレーションが必要な際はメンテ画面と合わせて適宜実行してください。\n以下TEST環境へのデプロイの例\n\n// マイグレーション無しのソースのみのデプロイ\nUSE_RBENV=true bundle exec cap test deploy\n// マイグレーション有りのデプロイ\n// ※メンテにいれなくていい場合はメンテ部分はスルーで大丈夫です。\n\n// メンテナンスに入れる\nbundle exec cap test maintenance:on\n\n// ソース反映\nUSE_RBENV=true bundle exec cap test deploy\n\n// マイグレーション\nbundle exec cap test db:migrate\n\n// 許可IPのみメンテナンス解除\nbundle exec cap test maintenance:allow_ips\n\n// 確認後メンテナンス解除\nbundle exec cap test maintenance:off\nメンテナンス\n\nnginxでメンテ判定をするように設定しています。\nshared/maintenance.htmlというファイルが存在するかどうかで判定しています。\n存在する場合はshared/maintenance.htmlが表示されます。\ncapistranoからcurrent/maintenance/maintenance.htmlからコピーするタスクがあるのでそちらからon/off切り替えられます。\n\nbundle exec cap staging maintenance:on\nbundle exec cap staging maintenance:off\nshared/maintenance_allow_ipsというファイルが存在する場合は、許可IPのみメンテナンス中にアクセス可能になります。\ncapistranoからtouchで作成するタスクがあるのでそちらから切り替えます。\n\nbundle exec cap staging maintenance:allow_ips\nメンテ中に貫通できるIPは、nginx.confで管理していて、\nbeaconbank/cookbooks/itamae/nodes/*で設定するようになっています。\n追加等ある場合はこちらを編集してitamaeをdeployしてください。\n\nアプリケーションログ\n\n過去のログについては退避先のGCSバケット(※)に入っています。\n※TEST環境なら test-biz-documents\n\nログの場所\n\n各サーバーの /var/www/bizBB/shared/log/ 以下に出力されています。\n\nRailsのログ\n\nPROD環境/PROD(STG)環境: production.log\nTEST環境: staging.log\n\n※開発環境のdevelopment.logもファイルは作られますが無視してOKです\n\nSidekiqのログ\n\n※メール送信やCSVダウンロードなどのバックグラウンドワーカー\nsidekiq.log\n\nWhenever\n\n※バッチ処理\nwhenever.log\n\nその他\n\nアプリサーバーミドルウェアのログ\n\nunicorn-stdout.log\nunicorn-error.log\n\n\n\n\nkevin [9:45 AM] \n\n\nlogin: test5@example.com        pass: testtest\n\n\n\n\n\n\ncache={}\ndef fib(n) :\n   if n==0 or n==1 : return 1\n\n   try :\n     return cache[n]\n   except :\n      fb= fib(n-1) + fib(n-2)\n      cache[n]= fb\n      return fb\n\n\ndef fib2(n) :\n   if n==0 or n==1 : return 1\n\n   try :\n     return cache[n]\n   except :\n\n      fb1= fb2= 1\n      for i in xrange(2, n) :\n         fb3= fb1 + fb2\n         fb1= fb3  # n --> n-1\n         fb2= fb1  # n-1 --> n-2\n\n      cache[n]= fb3\n      return fb3\n\n\n\n\nfib(25)\n\nfib2(3700)\n\n\n\n 5/6月ともリピータは一貫して効果が高い\n\n 6月はa,bで効果が上昇\n\n\n###########################################################\na.職域（ホワイト）\nb.職域（ブルー）\nc.大規模小売店\nd.交通\ne.学校\nf.娯楽施設\ng.パチンコ\nh.スポーツ施設\ni.病院\nj.宿泊施設\nk.その他\nl.アウトドア\n\n\n\n\ne.学校\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n moto.*,saki.*\nfrom\n\n\n (select\n  ggb.group_id,log.beacon_id,log.adid,log.detected_time\n from\n  BB_beaconlog log\n  inner join\n  (select\n    gb.group_id,\n    gb.beacon_id\n   from\n    BB_group_beacon gb\n    inner join\n    (select id from BB_group where group_type=\"2\" and deleted=\"0\") g\n    on gb.group_id = g.id) ggb\n  on log.beacon_id = ggb.beacon_id\n where log.event=\"0\"\n and log.application_id=\"2170005\"\n group by ggb.group_id,log.beacon_id,log.adid,log.detected_time) moto,\n\n\n\n (select\n  ggb.group_id,log.beacon_id,log.adid,log.detected_time\n from\n  BB_beaconlog log\n  inner join\n  (select\n    gb.group_id,\n    gb.beacon_id\n   from\n    BB_group_beacon gb\n    inner join\n    (select id from BB_group where group_type=\"2\" and deleted=\"0\") g\n    on gb.group_id = g.id) ggb\n  on log.beacon_id = ggb.beacon_id\n where log.event=\"0\"\n and log.application_id=\"2170005\"\n group by ggb.group_id,log.beacon_id,log.adid,log.detected_time) saki\n\nwhere moto.adid = saki.adid\nand   moto.group_id <> saki.group_id\nand   moto.detected_time < saki.detected_time\n\n\n\n\n\n\nhttp://sinhrks.hatenablog.com/entry/2014/12/12/081841\n\n\n\n\nselect application_id as app_id, account_id,   event, app_use_detected, \n     group_id, group_name, group_type, \n     \n     manufacturer, model, os, sdk, \n     \n     beacon_id,  address_prefecture, address_city,\n     address_detail, is_fixed, is_outdoor,\n     is_public_area, install_loc_cat1id_name as install_loc_cat1id , install_loc_cat2id_name as install_loc_cat2id,\n     latitude as lat, longitude as lng,\n     \n     count(app_user_id) as n_hanoulog,  count(DISTINCT app_user_id) as n_user \n\nfrom \n   (\n  select g0.beacon_id, g0.account_id, detected_time,\n         g0.application_id, app_user_id, event, app_use_detected, \n         manufacturer, model, os, sdk,\n         \n         h1.latitude, h1.longitude, \n         group_id, name as group_name, group_type, \n         \n         address_prefecture, address_city,  address_detail, \n         is_fixed, is_outdoor,\n         is_public_area, install_loc_cat1id, install_loc_cat2id,\n         install_loc_cat2id_name, install_loc_cat1id_name, min(g0.beacon_id)\n     \n     from  `beaconbank.BB_beaconlog*`     as g0\n   LEFT JOIN  \n     (  select account_id, application_id, name, group_type,  group_id, beacon_id, latest_version\n        \n        from (\n            select  account_id, u1.application_id, name, group_type,  group_id, beacon_id, max(group_id),\n                  latest_version, \n                  CAST(FORMAT_DATE(\"%Y%m%d\", valid_form) as INT64 ) as valid_from, CAST(FORMAT_DATE(\"%Y%m%d\", valid_to) as INT64 ) as valid_to1\n            \n            FROM      beaconbank.BB_group as u1\n              LEFT JOIN  beaconbank.BB_group_beacon as u2  \n              ON         u1.id= u2.group_id AND u1.latest_version= u2.version\n            WHERE     u1.deleted=0 AND u2.is_latest=1\n            \n            GROUP BY beacon_id, account_id,  u1.application_id, name, group_type, group_id, valid_from, valid_to1, latest_version       \n            )\n        where valid_to1 >= 20170719 and valid_from <= 20170719\n     )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                AND   g0.application_id=  g3.application_id\n                AND   g0.account_id=      g3.account_id\n   \n   JOIN\n      ( select   g5.id as beacon_id, latitude, longitude, \n            address_prefecture, address_city,   address_detail, \n            is_fixed, is_outdoor,\n            is_public_area, install_loc_cat1id, install_loc_cat2id,\n            m5.name as install_loc_cat2id_name, \n            m6.name as install_loc_cat1id_name, min(is_fixed)\n       \n       from   beaconbank.BB_beacon as g5         \n       JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n       JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n       JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id  \n       \n       GROUP BY beacon_id, latitude, longitude, \n            address_prefecture, address_city,   address_detail, \n            is_fixed, is_outdoor, is_public_area, install_loc_cat1id, install_loc_cat2id,\n            install_loc_cat2id_name,    install_loc_cat1id_name           \n      )  as h1      ON  g0.beacon_id= h1.beacon_id\n\n\nWHERE _TABLE_SUFFIX BETWEEN '20170718' AND '20170719'\n    AND  CAST(FORMAT_DATETIME(\"%Y%m%d\", local_time) as INT64 )= 20170719\n\n\nGROUP BY g0.beacon_id, g0.account_id, detected_time,\n         g0.application_id, app_user_id, event, app_use_detected, \n         manufacturer, model, os, sdk,\n         \n         h1.latitude, h1.longitude, \n         group_id, group_name, group_type,\n         \n         address_prefecture, address_city,\n         address_detail,  is_fixed, is_outdoor,\n         is_public_area, install_loc_cat1id, install_loc_cat2id,\n         install_loc_cat2id_name, install_loc_cat1id_name\n)\n\nwhere  event=0\n\ngroup by  application_id, account_id,\n   event, app_use_detected,  \n   group_id, group_name, group_type, \n   manufacturer, model, os, sdk,\n   \n   beacon_id, address_prefecture, address_city,\n   address_detail,  is_fixed, is_outdoor,\n   is_public_area, install_loc_cat1id, install_loc_cat2id,\n   lat, lng\norder by application_id asc, group_type, group_id      \n\n\nss2= \"\"\"\n    select g0.beacon_id, g0.account_id, detected_time,\n           g0.application_id, app_user_id, event, app_use_detected, \n           manufacturer, model, os, sdk,\n           \n           h1.latitude, h1.longitude, \n           group_id, name as group_name, group_type, \n\n           address_prefecture, address_city,  address_detail, \n           is_fixed, is_outdoor,\n           is_public_area, install_loc_cat1id, install_loc_cat2id,\n           install_loc_cat2id_name, install_loc_cat1id_name, min(g0.beacon_id)\n     \n       from  `beaconbank.BB_beaconlog*`     as g0\n     LEFT JOIN  \n       (  select account_id, application_id, name, group_type,  group_id, beacon_id, latest_version\n\n          from (\n              select  account_id, u1.application_id, name, group_type,  group_id, beacon_id, max(group_id),\n                    latest_version, \n                    CAST(FORMAT_DATE(\"%Y%m%d\", valid_form) as INT64 ) as valid_from, CAST(FORMAT_DATE(\"%Y%m%d\", valid_to) as INT64 ) as valid_to1\n\n              FROM      beaconbank.BB_group as u1\n                LEFT JOIN  beaconbank.BB_group_beacon as u2  \n                ON         u1.id= u2.group_id AND u1.latest_version= u2.version\n              WHERE     u1.deleted=0 AND u2.is_latest=1\n\n              GROUP BY beacon_id, account_id,  u1.application_id, name, group_type, group_id, valid_from, valid_to1, latest_version       \n              )\n          where valid_to1 >= \"\"\"+ t0 + \"\"\" and valid_from <= \"\"\" + t0 + \"\"\"\n       )  as g3   ON    g0.beacon_id=       g3.beacon_id\n                  AND   g0.application_id=  g3.application_id\n                  AND   g0.account_id=      g3.account_id\n\n     JOIN\n        ( select   g5.id as beacon_id, latitude, longitude, \n              address_prefecture, address_city,   address_detail, \n              is_fixed, is_outdoor,\n              is_public_area, install_loc_cat1id, install_loc_cat2id,\n              m5.name as install_loc_cat2id_name, \n              m6.name as install_loc_cat1id_name, min(is_fixed)\n            \n         from   beaconbank.BB_beacon as g5         \n         JOIN   beaconbank.BB_beacon_attribute as g6    ON  g5.attr_estimate_id   =  g6.id\n         JOIN   beaconbank.BB_loc_category2    as m5    ON  g6.install_loc_cat2id =  m5.id  \n         JOIN   beaconbank.BB_loc_category1    as m6    ON  g6.install_loc_cat1id =  m6.id  \n                \n         GROUP BY beacon_id, latitude, longitude, \n              address_prefecture, address_city,   address_detail, \n              is_fixed, is_outdoor, is_public_area, install_loc_cat1id, install_loc_cat2id,\n              install_loc_cat2id_name,    install_loc_cat1id_name           \n        )  as h1      ON  g0.beacon_id= h1.beacon_id\n               \n\nWHERE _TABLE_SUFFIX BETWEEN '\"\"\"+ta+\"\"\"' AND '\"\"\"+tb+\"\"\"'\n      AND  CAST(FORMAT_DATETIME(\"%Y%m%d\", local_time) as INT64 )= \"\"\"+t0+\"\"\"\n\n\nGROUP BY g0.beacon_id, g0.account_id, detected_time,\n           g0.application_id, app_user_id, event, app_use_detected, \n           manufacturer, model, os, sdk,\n           \n           h1.latitude, h1.longitude, \n           group_id, group_name, group_type,\n\n           address_prefecture, address_city,\n           address_detail,  is_fixed, is_outdoor,\n           is_public_area, install_loc_cat1id, install_loc_cat2id,\n           install_loc_cat2id_name, install_loc_cat1id_name\n\n \n\n\"\"\"\n\n以下のロケごとに, HOT-COLDプロファイル:\n a.職域（ホワイト）\t\n b.職域（ブルー）\n c.大規模小売店\t\t\n d.交通\n e.学校\n g.パチンコ\t\t\t \n l.アウトドア \n\n\n\n\nCOFFEE-BLACK-CAN-190\nCOFFEE-BLACK-BOTTLECAN-300\nCOFFEE-CAN-190\nCOFFEE-BOTTLECAN-300\nCOFFEE-CAFEOLAIT-CAN-190\nCOFFEE-CAFEOLAIT-PET-280\nCOFFEE-SUGAR-CAN-190\nTEA-PET-280\nBLACK TEA-CAN-280\n\n\n\n\n\ndf2  = bq_sql(  ss2  )\n  \n\n\n\n\n######################################################################\n######\nPackages Ubuntu \n\n\napache2-bin (2.4.7-1ubuntu4.17 [amd64, i386], 2.4.7-1ubuntu4 [arm64, armhf, powerpc, ppc64el]) [security]\nApache HTTP Server (binary files and modules)\napache2-data (2.4.7-1ubuntu4.17) [security]\nApache HTTP Server (common files)\napache2-dev (2.4.7-1ubuntu4.17 [amd64, i386], 2.4.7-1ubuntu4 [arm64, armhf, powerpc, ppc64el]) [security]\nApache HTTP Server (development headers)\napache2-suexec-pristine (2.4.7-1ubuntu4.17 [amd64, i386], 2.4.7-1ubuntu4 [arm64, armhf, powerpc, ppc64el]) [universe] [security]\nApache HTTP Server standard suexec program for mod_suexec\napache2.2-bin (2.4.7-1ubuntu4.17 [amd64, i386], 2.4.7-1ubuntu4 [arm64, armhf, powerpc, ppc64el]) [security]\nTransitional package for apache2-bin\nerlang-yaws (1.98-2) [universe]\nErlang application which implements HTTP webserver\nlibapache2-mod-auth-pgsql (2.0.3-6)\nModule for Apache2 which provides PostgreSQL authentication\nlibapache2-mod-auth-pubtkt (0.8-3) [universe]\nkey-based single-sign-on authentication module for Apache\nlibapache2-mod-auth-tkt (2.1.0-8) [universe]\nlightweight single-sign-on authentication module for Apache\nlibapache2-mod-authn-webid (0~20110301-2) [universe]\nWebID FOAF+SSL authentication module for Apache\nlibapache2-mod-dacs (1.4.28b-3ubuntu1) [universe]\nDistributed Access Control System (DACS) - Apache Module\nlibapache2-mod-musicindex (1.4.1-1) [universe]\nBrowse, stream, download and search through MP3/Ogg/FLAC/MP4 files\nlibapache2-mod-netcgi-apache (3.7.3-3build2) [universe]\nOCaml application-level Internet libraries - netcgi2 Apache2 connector\nlibapache2-mod-php5 (5.5.9+dfsg-1ubuntu4.21 [amd64, i386], 5.5.9+dfsg-1ubuntu4 [arm64, armhf, powerpc, ppc64el]) [security]\nserver-side, HTML-embedded scripting language (Apache 2 module)\nlibapache2-mod-php5filter (5.5.9+dfsg-1ubuntu4.21 [amd64, i386], 5.5.9+dfsg-1ubuntu4 [arm64, armhf, powerpc, ppc64el]) [universe] [security]\nserver-side, HTML-embedded scripting language (apache 2 filter module)\nlibapache2-mod-proxy-msrpc (0.4-1ubuntu1) [universe]\nApache module for Outlook Anywhere support in reverse proxy setups\nlibapache2-mod-qos (10.28-1) [universe]\nquality of service module for the apache2\nlibapache2-mod-security2 (2.7.7-2) [universe]\nTighten web applications security for Apache\nlibapache2-mod-svn (1.8.8-1ubuntu3.2 [amd64, i386], 1.8.8-1ubuntu3 [arm64, armhf, powerpc, ppc64el]) [universe] [security]\nApache Subversion server modules for Apache httpd\nlibapache2-mod-webauth (4.5.5-2) [universe]\nApache module for WebAuth authentication\nlibapache2-mod-webauthldap (4.5.5-2) [universe]\nApache module for WebAuth LDAP lookup and authorization\nlibapache2-mod-webkdc (4.5.5-2) [universe]\nApache modules for a WebAuth authentication KDC\nlibapache2-mod-wsgi-py3 (3.4-4ubuntu2.1.14.04.2 [amd64, i386], 3.4-4ubuntu2 [arm64, armhf, powerpc, ppc64el]) [universe] [security]\nPython 3 WSGI adapter module for Apache\nlibapache2-modsecurity (2.7.7-2) [universe]\nDummy transitional package\nmodsecurity-crs (2.2.8-1) [universe]\nmodsecurity's Core Rule Set\nnginx-common (1.4.6-1ubuntu3.8) [security]\nsmall, powerful, scalable web/proxy server - common files\nnginx-core (1.4.6-1ubuntu3.8 [amd64, i386], 1.4.6-1ubuntu3 [arm64, armhf, powerpc, ppc64el]) [security]\nnginx web/proxy server (core version)\nnginx-extras (1.4.6-1ubuntu3.8 [amd64, i386], 1.4.6-1ubuntu3 [arm64, armhf, powerpc, ppc64el]) [universe] [security]\nnginx web/proxy server (extended version)\nnginx-full (1.4.6-1ubuntu3.8 [amd64, i386], 1.4.6-1ubuntu3 [arm64, armhf, powerpc, ppc64el]) [universe] [security]\nnginx web/proxy server (standard version)\nnginx-light (1.4.6-1ubuntu3.8 [amd64, i386], 1.4.6-1ubuntu3 [arm64, armhf, powerpc, ppc64el]) [universe] [security]\nnginx web/proxy server (basic version)\nnginx-naxsi (1.4.6-1ubuntu3.8 [amd64, i386], 1.4.6-1ubuntu3 [arm64, armhf, powerpc, ppc64el]) [universe] [security]\nnginx web/proxy server (version with naxsi)\nnginx-naxsi-ui (1.4.6-1ubuntu3.8) [universe] [security]\nnginx web/proxy server - naxsi configuration front-end\nocsigenserver (2.2.0-3) [universe]\nweb server of the Ocsigen project\nqweborf (0.13-3) [universe]\nShares files using the HTTP protocol\nweborf-daemon (0.13-3) [universe]\ninit script for weborf\n\n\n\n\nhttps://packages.ubuntu.com/trusty/devel/\n\n\nsudo apt-get install default-jdk\nsudo apt-get install gzip\n\nsudo apt-get update\napt-cache dump\n\nsudo apt-get install dos2unix\nsudo software-properties-gtk\nsudo apt-get update\nsudo apt-get install rar\n\n\n\nZsh\n\nTmux\n\nVim\n\nRVM\n\nBashrc \n\n\n\n\n\n\n\n\n\n\n\nJulia Install Instructions :\nGeneric Linux Binaries\n https://julialang.org/downloads/platform.html\n\n The generic Linux binaries do not require any special installation steps, \n but you will need to ensure that your system can find the julia executable. \n First, extract the .tar.gz file downloaded from the downloads page to a folder on your computer. \n To run Julia, you can do any of the following:\n\n  Create a symbolic link to julia inside a folder which is on your system PATH\n  Add Julia’s bin folder to your system PATH environment variable\n  Invoke the julia executable by using its full path, as in <where you extracted Julia>/bin/julia\n  For example, to create a symbolic link to julia inside the /usr/local/bin folder, you can do the following:\n\n  sudo ln -s <where you extracted the julia archive>/bin/julia /usr/local/bin/julia\n\n\n\n\nsudo apt-get remove scala-library scala\nsudo wget www.scala-lang.org/files/archive/scala-2.10.4.deb\nsudo dpkg -i scala-2.10.4.deb\nsudo apt-get update\nsudo apt-get install scala\nwget http://scalasbt.artifactoryonline.com/scalasbt/sbt-native-packages/org/scala-sbt/sbt/0.12.4/sbt.deb\nsudo dpkg -i sbt.deb\nsudo apt-get update\nsudo apt-get install sbt\nsudo add-apt-repository ppa:webupd8team/sublime-text-3\nsudo apt-get update\nsudo apt-get install sublime-text-installer\n\n\n\nsudo add-apt-repository ppa:ubuntu-elisp/ppa\nsudo apt-get update\nsudo apt-get install emacs-snapshot emacs-snapshot-el\nsudo apt-get install virtualbox\n\n\nsudo apt-get install cue2toc - converts CUE files to cdrdao's TOC format\nsudo apt-get install easytag - viewing, editing and writing ID3 tags\nsudo apt-get install id3v2 - A command line id3v2 tag editor\n\n\n\nこれはあなたが提案している通りです。\n\n\n\n\ncd\nwget -c http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh\nchmod +x Miniconda-latest-Linux-x86_64.sh\n./Miniconda-latest-Linux-x86_64.sh\n\n\n#Install into :\n/home/noel/anaconda27\n\n\nconda install numba\n\n\nsudo apt-get install r-base-dev\n\nsudo dpkg -i cuda-repo-ubuntu1404_7.5-18_amd64.deb \nsudo apt-get install cuda\n\n\n\n\n\napache2-bin \napache2-data \napache2-dev \napache2-suexec-pristine \napache2.2-bin \nerlang-yaws \nlibapache2-mod-auth-pubtkt \nlibapache2-mod-auth-tkt \nlibapache2-mod-authn-webid \nlibapache2-mod-dacs \nlibapache2-mod-musicindex \nlibapache2-mod-netcgi-apache \nlibapache2-mod-php5 \nlibapache2-mod-php5filter \nlibapache2-mod-proxy-msrpc \nlibapache2-mod-qos \nlibapache2-mod-security2 \nlibapache2-mod-svn \nlibapache2-mod-webauth \nlibapache2-mod-webauthldap \nlibapache2-mod-webkdc \nlibapache2-mod-wsgi-py3 \nlibapache2-modsecurity \nmodsecurity-crs \nnginx-common \nnginx-core \nnginx-extras \nnginx-full \nnginx-light \nnginx-naxsi \nnginx-naxsi-ui \nocsigenserver \nqweborf \nweborf-daemon \n\n\n\n\n\n\n\n Package Name\tAccess\tSummary\t Updated\n numba\tpublic\ta just-in-time Python function compiler based on LLVM\t2017-07-17\n conda-build\tpublic\tCommands and tools for building conda packages\t2017-07-14\n scipy\tpublic\tScientific Library for Python\t2017-07-14\n six\tpublic\tNo Summary\t2017-07-13\n glob2\tpublic\tEnhanced glob that can capture patterns and supports recursive wildcards\t2017-07-13\n cx_oracle\tpublic\tPython interface to Oracle\t2017-07-12\n openjdk\tpublic\tNo Summary\t2017-07-11\n cudatoolkit\tpublic\tNo Summary\t2017-07-11\n fastparquet\tpublic\tPython interface to the parquet format\t2017-07-11\n cudnn\tpublic\tNo Summary\t2017-07-11\n pyutilib\tpublic\tPyUtilib: A collection of Python utilities\t2017-07-11\n maven\tpublic\tA software project management and comprehension tool.\t2017-07-11\n nose-parameterized\tpublic\tParameterized testing with any Python test framework\t2017-07-11\n leveldb\tpublic\tA fast key-value storage library providing ordered mappings.\t2017-07-11\n gtest\tpublic\tGoogle's C++ test framework\t2017-07-11\n pandas-profiling\tpublic\tGenerate profile report for pandas DataFrame\t2017-07-11\n neo4j-python-driver\tpublic\tDatabase connector for Neo4j graph database\t2017-07-11\n llvmlite\tpublic\tA lightweight LLVM python binding for writing JIT compilers\t2017-07-11\n entrypoints\tpublic\tNo Summary\t2017-07-10\n sympy\tpublic\tPython library for symbolic mathematics\t2017-07-10\n dbus\tpublic\tmessage bus system, a simple way for applications to talk to one another\t2017-07-10\n pillow\tpublic\tThe friendly Python Imaging Library(PIL) fork\t2017-07-08\n numpy\tpublic\tarray processing for numbers, strings, records, and objects\t2017-07-07\n astropy\tpublic\tCommunity-developed Python Library for Astronomy\t2017-07-07\n gflags\tpublic\tA C++ library that implements commandline flags processing.\t2017-07-07\n service_identity\tpublic\tService identity verification for pyOpenSSL\t2017-07-06\n holoviews\tpublic\tStop plotting your data - annotate your data and let it visualize itself.\t2017-07-06\n lz4\tpublic\tBindings for the lz4 compression library\t2017-07-05\n s3fs\tpublic\tconvenient Filesystem interface over S3\t2017-07-05\n hdf5\tpublic\tNo Summary\t2017-07-05\n django\tpublic\tWeb framework that encourages rapid development\t2017-07-05\n nccl\tpublic\tOptimized primitives for collective multi-GPU communication\t2017-07-05\n icu\tpublic\tNo Summary\t2017-07-05\n caffe-gpu\tpublic\tA deep learning framework made with expression, speed, and modularity in mind.\t2017-07-05\n caffe\tpublic\tA deep learning framework made with expression, speed, and modularity in mind.\t2017-07-05\n boost\tpublic\tNo Summary\t2017-07-05\n libtorch-gpu\tpublic\tTorch libraries for use in PyTorch, GPU enabled version.\t2017-07-05\n libtorch\tpublic\tTorch libraries for use in PyTorch.\t2017-07-05\n pyodbc\tpublic\tDB API Module for ODBC\t2017-07-03\n thinc\tpublic\tLearn sparse linear models\t2017-06-30\n spacy\tpublic\tIndustrial-strength Natural Language Processing\t2017-06-30\n ftfy\tpublic\tfixes some problems with Unicode text after the fact\t2017-06-30\n regex\tpublic\talternative regular expression module, to replace re\t2017-06-30\n preshed\tpublic\tCython hash table that trusts the keys are pre-hashed\t2017-06-30\n murmurhash\tpublic\tA non-cryptographic hash function\t2017-06-30\n\n\n Package Name\tAccess\tSummary\t Updated\n pymc3\tpublic\tprobabilistic Programming in Python\t2017-06-30\n python-blosc\tpublic\tA Python wrapper for the extremely fast Blosc compression library\t2017-06-30\n pytest-xdist\tpublic\tpy.test xdist plugin for distributed testing and loop-on-failing modes\t2017-06-30\n pydotplus\tpublic\tPython interface to the Graphviz Dot language\t2017-06-30\n lmdb\tpublic\tA high-performance embedded transactional key-value store database.\t2017-06-30\n glog\tpublic\tSimple Google-style logging wrapper for Python.\t2017-06-30\n curl\tpublic\tTool and library for transferring data with URL syntax\t2017-06-30\n c-blosc\tpublic\tNo Summary\t2017-06-30\n protobuf\tpublic\tNo Summary\t2017-06-29\n termcolor\tpublic\tANSII Color formatting for output in terminal\t2017-06-29\n pathlib\tpublic\tobject-oriented filesystem paths\t2017-06-29\n chainer\tpublic\tflexible framework of neural networks for deep learning\t2017-06-29\n yarl\tpublic\tYet another URL library\t2017-06-29\n continuum-docs\tpublic\tNo Summary\t2017-06-29\n mkl\tpublic\tMath library for Intel and compatible processors\t2017-06-29\n urllib3\tpublic\tHTTP library with thread-safe connection pooling, file post, and more.\t2017-06-29\n typing\tpublic\tbackport of the standard library typing module to Python versions older than 3.6\t2017-06-29\n the-silver-searcher\tpublic\tA code searching tool similar to ack, with a focus on speed.\t2017-06-29\n sphinxcontrib-websupport\tpublic\tSphinx API for Web Apps\t2017-06-29\n sphinxcontrib\tpublic\tPython namespace for sphinxcontrib\t2017-06-29\n scikit-learn\tpublic\tset of python modules for machine learning and data mining\t2017-06-29\n rapidjson\tpublic\tA fast JSON parser/generator for C++ with both SAX/DOM style API\t2017-06-29\n qgrid\tpublic\tPandas DataFrame viewer for IPython Notebook\t2017-06-29\n python-rapidjson\tpublic\tPython wrapper around rapidjson\t2017-06-29\n pytest-asyncio\tpublic\tPytest support for asyncio\t2017-06-29\n pygpu\tpublic\tNo Summary\t2017-06-29\n ninja\tpublic\tA small build system with a focus on speed\t2017-06-29\n libssh2\tpublic\tthe SSH library\t2017-06-29\n libgpuarray\tpublic\tNo Summary\t2017-06-29\n libconda\tpublic\tconda 4.0 based library\t2017-06-29\n jupyter_client\tpublic\tJupyter protocol implementation and client libraries\t2017-06-29\n isort\tpublic\tPython utility / library to sort Python imports\t2017-06-29\n hyperlink\tpublic\tImmutable, Pythonic, correct URLs\t2017-06-29\n cram\tpublic\tA simple testing framework for command line applications\t2017-06-29\n functools_lru_cache\tpublic\tbackport of functools.lru_cache from Python 3.3\t2017-06-29\n coverage\tpublic\tCode coverage measurement for Python\t2017-06-29\n aiofiles\tpublic\tPython library for handling local disk files in asyncio applications\t2017-06-29\n word2vec\tpublic\tPython interface to Google word2vec\t2017-06-29\n portpicker\tpublic\tA library to choose unique available network ports.\t2017-06-29\n pattern\tpublic\tVisual analysis and diagnostic tools to facilitate ML model selection\t2017-06-29\n tensorflow\tpublic\tNo Summary\t2017-06-23\n funcsigs\tpublic\tNo Summary\t2017-06-23\n gensim\tpublic\tNo Summary\t2017-06-23\n netcdf4\tpublic\tNo Summary\t2017-06-22\n libnetcdf\tpublic\tNo Summary\t2017-06-22\n param\tpublic\tNo Summary\t2017-06-22\n wget\tpublic\tNo Summary\t2017-06-22\n vs2015_runtime\tpublic\tNo Summary\t2017-06-21\n libprotobuf\tpublic\tNo Summary\t2017-06-21\n numexpr\tpublic\tNo Summary\t2017-06-20\n\n\n Package Name\tAccess\tSummary\t Updated\n cvxopt\tpublic\tNo Summary\t2017-06-20\n sqlalchemy\tpublic\tNo Summary\t2017-06-20\n _nb_ext_conf\tpublic\tNo Summary\t2017-06-20\n lazy-object-proxy\tpublic\tNo Summary\t2017-06-20\n astroid\tpublic\tNo Summary\t2017-06-20\n pytest\tpublic\tNo Summary\t2017-06-19\n nb_conda_kernels\tpublic\tNo Summary\t2017-06-19\n nb_conda\tpublic\tNo Summary\t2017-06-19\n nb_anacondacloud\tpublic\tNo Summary\t2017-06-19\n zope.interface\tpublic\tNo Summary\t2017-06-18\n twisted\tpublic\tNo Summary\t2017-06-18\n sphinx\tpublic\tNo Summary\t2017-06-18\n smart_open\tpublic\tNo Summary\t2017-06-18\n pomegranate\tpublic\tNo Summary\t2017-06-18\n more-itertools\tpublic\tNo Summary\t2017-06-18\n distributed\tpublic\tNo Summary\t2017-06-18\n dask\tpublic\tNo Summary\t2017-06-18\n conda\tpublic\tNo Summary\t2017-06-18\n chardet\tpublic\tNo Summary\t2017-06-18\n botocore\tpublic\tNo Summary\t2017-06-18\n bokeh\tpublic\tNo Summary\t2017-06-18\n bkcharts\tpublic\tNo Summary\t2017-06-18\n anaconda-verify\tpublic\tNo Summary\t2017-06-18\n anaconda-navigator\tpublic\tNo Summary\t2017-06-18\n bazel\tpublic\tNo Summary\t2017-06-18\n xarray\tpublic\tNo Summary\t2017-06-09\n aiohttp\tpublic\tNo Summary\t2017-06-08\n pyopengl-accelerate\tpublic\tNo Summary\t2017-06-08\n pyopengl\tpublic\tNo Summary\t2017-06-08\n pyamg\tpublic\tNo Summary\t2017-06-08\n scikit-bio\tpublic\tNo Summary\t2017-06-08\n pywavelets\tpublic\tNo Summary\t2017-06-08\n bottleneck\tpublic\tNo Summary\t2017-06-08\n basemap\tpublic\tNo Summary\t2017-06-08\n biopython\tpublic\tNo Summary\t2017-06-08\n scikit-image\tpublic\tNo Summary\t2017-06-08\n pytables\tpublic\tNo Summary\t2017-06-08\n matplotlib\tpublic\tNo Summary\t2017-06-08\n h5py\tpublic\tNo Summary\t2017-06-08\n statsmodels\tpublic\tNo Summary\t2017-06-08\n pandas\tpublic\tNo Summary\t2017-06-08\n pytest-mock\tpublic\tNo Summary\t2017-06-07\n plotly\tpublic\tNo Summary\t2017-06-07\n gevent\tpublic\tNo Summary\t2017-06-07\n multidict\tpublic\tNo Summary\t2017-06-07\n async-timeout\tpublic\tNo Summary\t2017-06-07\n javabridge\tpublic\tNo Summary\t2017-06-07\n glueviz\tpublic\tNo Summary\t2017-06-07\n glue-vispy-viewers\tpublic\tNo Summary\t2017-06-07\n glue-core\tpublic\tNo Summary\t2017-06-07\n\n graphviz\tpublic\tNo Summary\t2017-06-06\n py\tpublic\tNo Summary\t2017-06-05\n lxml\tpublic\tNo Summary\t2017-06-05\n parsel\tpublic\tNo Summary\t2017-06-02\n nodejs\tpublic\tNo Summary\t2017-06-02\n ipython\tpublic\tNo Summary\t2017-06-02\n bcolz\tpublic\tNo Summary\t2017-06-02\n requests-ftp\tpublic\tNo Summary\t2017-06-01\n pandas-datareader\tpublic\tNo Summary\t2017-06-01\n hdf4\tpublic\tNo Summary\t2017-06-01\n boto\tpublic\tNo Summary\t2017-06-01\n testpath\tpublic\tNo Summary\t2017-06-01\n nltk\tpublic\tNo Summary\t2017-06-01\n fabric\tpublic\tNo Summary\t2017-06-01\n tqdm\tpublic\tNo Summary\t2017-06-01\n semver\tpublic\tNo Summary\t2017-06-01\n nbconvert\tpublic\tNo Summary\t2017-06-01\n navigator-updater\tpublic\tNo Summary\t2017-05-30\n anaconda\tpublic\tNo Summary\t2017-05-30\n anaconda-project\tpublic\tNo Summary\t2017-05-26\n openssl\tpublic\tNo Summary\t2017-05-25\n munch\tpublic\tNo Summary\t2017-05-24\n pycrypto\tpublic\tNo Summary\t2017-05-24\n caffe-nv-gpu\tpublic\tNo Summary\t2017-05-23\n python-graphviz\tpublic\tNo Summary\t2017-05-22\n menuinst\tpublic\tNo Summary\t2017-05-19\n libgfortran\tpublic\tNo Summary\t2017-05-19\n qt\tpublic\tNo Summary\t2017-05-17\n contextlib2\tpublic\tNo Summary\t2017-05-17\n flask\tpublic\tNo Summary\t2017-05-17\n futures\tpublic\tNo Summary\t2017-05-16\n colorama\tpublic\tNo Summary\t2017-05-16\n werkzeug\tpublic\tNo Summary\t2017-05-16\n pyopenssl\tpublic\tNo Summary\t2017-05-16\n packaging\tpublic\tNo Summary\t2017-05-16\n openpyxl\tpublic\tNo Summary\t2017-05-16\n idna\tpublic\tNo Summary\t2017-05-16\n cryptography\tpublic\tNo Summary\t2017-05-16\n cffi\tpublic\tNo Summary\t2017-05-16\n asn1crypto\tpublic\tNo Summary\t2017-05-16\n jedi\tpublic\tNo Summary\t2017-05-15\n python\tpublic\tNo Summary\t2017-05-15\n nsis\tpublic\tNo Summary\t2017-05-15\n requests\tpublic\tNo Summary\t2017-05-12\n beautifulsoup4\tpublic\tNo Summary\t2017-05-11\n natsort\tpublic\tNo Summary\t2017-05-10\n markdown2\tpublic\tNo Summary\t2017-05-10\n zict\tpublic\tNo Summary\t2017-05-09\n tornado\tpublic\tNo Summary\t2017-05-09\n snappy\tpublic\tNo Summary\t2017-05-09\n\n\npartd\tpublic\tNo Summary\t2017-05-09\n anaconda-client\tpublic\tNo Summary\t2017-05-09\n theano\tpublic\tNo Summary\t2017-05-08\n scikit-fmm\tpublic\tNo Summary\t2017-05-08\n python-socketio\tpublic\tNo Summary\t2017-05-08\n python-lmdb\tpublic\tNo Summary\t2017-05-08\n python-leveldb\tpublic\tNo Summary\t2017-05-08\n python-gflags\tpublic\tNo Summary\t2017-05-08\n python-engineio\tpublic\tNo Summary\t2017-05-08\n opencv\tpublic\tNo Summary\t2017-05-08\n flask-socketio\tpublic\tNo Summary\t2017-05-08\n eigen\tpublic\tNo Summary\t2017-05-08\n caffe-nv\tpublic\tNo Summary\t2017-05-08\n spyder\tpublic\tNo Summary\t2017-05-02\n datashader\tpublic\tNo Summary\t2017-04-25\n msinttypes\tpublic\tNo Summary\t2017-04-25\n progressbar2\tpublic\tNo Summary\t2017-04-18\n path.py\tpublic\tNo Summary\t2017-04-18\n jsonschema\tpublic\tNo Summary\t2017-04-18\n cssselect\tpublic\tNo Summary\t2017-04-18\n joblib\tpublic\tNo Summary\t2017-04-17\n ipykernel\tpublic\tNo Summary\t2017-04-17\n humanize\tpublic\tNo Summary\t2017-04-17\n keras-gpu\tpublic\tNo Summary\t2017-04-13\n keras\tpublic\tNo Summary\t2017-04-13\n setuptools_scm\tpublic\tNo Summary\t2017-04-13\n pytest-runner\tpublic\tNo Summary\t2017-04-13\n tblib\tpublic\tNo Summary\t2017-04-12\n kealib\tpublic\tNo Summary\t2017-04-12\n python-utils\tpublic\tNo Summary\t2017-04-12\n psutil\tpublic\tNo Summary\t2017-04-12\n picklable-itertools\tpublic\tNo Summary\t2017-04-12\n gevent-websocket\tpublic\tNo Summary\t2017-04-12\n fuel\tpublic\tNo Summary\t2017-04-12\n dill\tpublic\tNo Summary\t2017-04-12\n pyqtgraph\tpublic\tNo Summary\t2017-04-09\n orange3\tpublic\tNo Summary\t2017-04-09\n anyqt\tpublic\tNo Summary\t2017-04-09\n pathlib2\tpublic\tNo Summary\t2017-04-07\n tornado-json\tpublic\tNo Summary\t2017-04-07\n tabpy-server\tpublic\tNo Summary\t2017-04-07\n tabpy-client\tpublic\tNo Summary\t2017-04-07\n jinja2\tpublic\tNo Summary\t2017-04-07\n gitpython\tpublic\tNo Summary\t2017-04-07\n genson\tpublic\tNo Summary\t2017-04-07\n wrapt\tpublic\tNo Summary\t2017-04-05\n sortedcollections\tpublic\tNo Summary\t2017-04-05\n prompt_toolkit\tpublic\tNo Summary\t2017-04-05\n notebook\tpublic\tNo Summary\t2017-04-05\n sphinx_rtd_theme\tpublic\tNo Summary\t2017-04-04\n\n\n\n\n\n\n\n####  Packages #########################################\nBabel\t2.3.3\t2.4.0\nBottleneck\t1.1.0\t1.2.1\nCython\t0.24\t0.26\nDjango\t1.10.5\t1.11.3\nFlask\t0.11.1\t0.12.2\nFlask-Cors\t2.1.2\t3.0.3\nGDAL\t2.2.0\t2.2.1\nHeapDict\t1.0.0\t1.0.0\nJinja2\t2.8\t2.9.6\nMarkupSafe\t0.23\t1.0\nOrange\t2.7.8\t2.7.8\nPattern\t2.6\t2.6\nPillow\t3.2.0\t4.2.1\nPyDrive\t1.2.1\t1.3.1\nPyMySQL\t0.7.9\t0.7.11\nPyYAML\t3.11\t3.12\nPygments\t2.1.3\t2.2.0\nQtPy\t1.0.2\t1.2.1\nQuandl\t2.8.9\t3.2.0\nSQLAlchemy\t1.0.13\t1.2.0b1\nStarCluster\t0.95.6\t0.95.6\nTPOT\t0.6.4\t0.8.3\nWerkzeug\t0.11.10\t0.12.2\nXlsxWriter\t0.9.2\t0.9.8\nYahoo-ticker-downloader\t0.8.1\t2.1.0\n_nb_ext_conf\t0.2.0\t\nalabaster\t0.7.8\t0.7.10\namqp\t1.4.9\t2.2.1\nanaconda-client\t1.4.0\t1.2.2\nanaconda-navigator\t1.2.1\t\nanyjson\t0.3.3\t0.3.3\nargcomplete\t1.0.0\t1.8.2\nargs\t0.1.0\t0.1.0\narrow\t0.10.0\t0.10.0\nattrdict\t2.0.0\t2.0.0\nbabel\t2.3.3\t\nbackports\t1.0\t1.0\nbackports-abc\t0.4\t\nbackports.shutil-get-terminal-size\t1.0.0\t\nbackports.ssl-match-hostname\t3.4.0.2\t\nbackports_abc\t0.4\t0.5\nbcolz\t1.0.0\t1.1.2\nbeautifulsoup4\t4.4.1\t4.6.0\nbilliard\t3.3.0.23\t3.5.0.3\nbitarray\t0.8.1\t0.8.1\nblaze\t0.11.2\t0.10.1\nbokeh\t0.12.3\t0.12.6\nboost\t1.57.0\t0.1\nboto\t2.40.0\t2.48.0\nboto3\t1.4.1\t1.4.4\nboto3\t1.4.0\t1.4.4\nbotocore\t1.4.68\t1.5.85\nbotocore\t1.4.49\t1.5.85\nbottleneck\t1.1.0\t\nbqplot\t0.8.4\t0.10.0a2\nbrewer2mpl\t1.4.1\t1.4.1\nbzip2\t1.0.6\t1.0.6\ncategory-encoders\t1.2.2\t\ncategory_encoders\t1.2.2\t1.2.4\ncdecimal\t2.3\t2.3\ncelery\t3.1.23\t4.0.2\ncertifi\t2017.4.17\t2017.4.17\ncffi\t1.6.0\t1.10.0\nchardet\t3.0.4\t3.0.4\nchest\t0.2.3\t0.2.3\nclick\t6.7\t6.7\nclick\t6.6\t6.7\nclint\t0.5.1\t0.5.1\ncloudpickle\t0.2.2\t0.3.1\nclyent\t1.2.2\t1.2.1\ncolorama\t0.3.7\t0.3.9\ncomtypes\t1.1.2\t1.1.3\nconda\t4.3.22\t4.3.16\nconda-build\t1.21.14\t2.1.5\nconda-build\t1.21.14+0.g4dfebe9.dirty\t2.1.5\nconda-env\t2.6.0\t2.4.2\nconfigobj\t5.0.6\t5.0.6\nconfigparser\t3.5.0b2\t3.5.0b2\nconsole_shortcut\t0.1.1\t\ncontextlib2\t0.5.3\t0.5.5\nconvertdate\t2.1.0\t\ncryptography\t1.4\t1.8.1\ncurl\t7.49.0\t\ncycler\t0.10.0\t\ncython\t0.24\t\ncytoolz\t0.8.2\t0.8.2\ndask\t0.13.0\t0.15.0\ndatacleaner\t0.1.4\t\ndatashape\t0.5.3\t0.5.4\ndateparser\t0.5.1\t\ndeap\t1.0.2\t\ndeap\t1.0.2.post2\t\ndecorator\t4.0.10\t4.0.11\ndill\t0.2.5\t0.2.6\ndiskcache\t2.4.1\t\ndistributed\t1.15.0\t1.17.1\ndjango\t1.10.5\t1.10.5\ndjango-ipware\t1.1.6\t\ndjango-registration-redux\t1.4\t\ndocutils\t0.12\t0.13.1\nentrypoints\t0.2.2\t0.2.2\nenum34\t1.1.6\t1.1.6\nephem\t3.7.6.0\t3.7.5.3\net-xmlfile\t1.0.1\t\net_xmlfile\t1.0.1\t1.0.1\nexpat\t2.1.0\t\nfastcache\t1.0.2\t1.0.2\nfastcluster\t1.1.20\t\nfastcsv\t0.1.2\t\nfastnumbers\t1.0.0\t\nfilterpy\t0.1.4\t\nflask\t0.11.1\t0.12.2\nflask-cors\t2.1.2\t3.0.2\nfolium\t0.2.1\t\nfreetype\t2.5.5\t2.5.5\nfreexl\t1.0.2\t\nfuncsigs\t1.0.2\t1.0.2\nfunctools32\t3.2.3.post2\t3.2.3.2\nfunctools32\t3.2.3.2\t3.2.3.2\nfuture\t0.15.2\t0.16.0\nfutures\t3.0.5\t3.1.1\ngdal\t2.2.0\t2.1.0\ngeopy\t1.11.0\t\ngeos\t3.5.0\t3.5.0\nget_terminal_size\t1.0.0\t1.0.0\ngevent\t1.1.1\t1.2.2\nggplot\t0.11.5\t\ngoogle-api-python-client\t1.6.2\t\ngoogle-api-python-client\t1.5.3\t\ngplearn\t0.1.0\t\ngreenlet\t0.4.10\t0.4.12\ngrin\t1.2.1\t1.2.1\ngspread\t0.4.1\t\nguidata\t1.7.6\t\nh2o\t3.10.0.8\t3.10.0.9\nh5py\t2.7.0\t2.7.0\nhdbscan\t0.8.3\t\nhdf4\t4.2.12\t4.2.12\nhdf5\t1.8.17\t1.8.17\nheapdict\t1.0.0\t1.0.0\nhttplib2\t0.10.3\t\nidna\t2.1\t2.5\nidna\t2.5\t2.5\nimagesize\t0.7.1\t0.7.1\nipaddress\t1.0.16\t1.0.18\niptools\t0.6.1\t\nipykernel\t4.3.1\t4.6.1\nipyleaflet\t0.2.1\t\nipyparallel\t5.2.0\t6.0.2\nipython\t4.2.0\t6.1.0\nipython-genutils\t0.1.0\t\nipython_genutils\t0.1.0\t0.2.0\nipywidgets\t5.2.2\t6.0.0\niso8601\t0.1.11\t0.1.11\nitsdangerous\t0.24\t0.24\njavabridge\t1.0.14\t1.0.14\njdatetime\t1.8.1\t\njdcal\t1.2\t1.3\njedi\t0.8.1\t0.10.2\njedi\t0.9.0\t0.10.2\njinja2\t2.8\t2.9.6\njmespath\t0.9.0\t0.9.0\njoblib\t0.10.2\t0.11\njpeg\t9b\t9b\njsonschema\t2.5.1\t2.6.0\njupyter\t1.0.0\t1.0.0\njupyter-client\t4.3.0\t\njupyter-console\t4.1.1\t\njupyter-core\t4.1.0\t\njupyter-dashboards\t0.6.1\t\njupyter_client\t4.3.0\t5.0.1\njupyter_console\t4.1.1\t5.1.0\njupyter_core\t4.1.0\t4.3.0\njupyter_dashboards\t0.6.1\t\nkealib\t1.4.7\t1.4.6\nkmodes\t0.6\t\nkombu\t3.0.35\t\nlibgdal\t2.0.0\t2.1.0\nlibiconv\t1.14\t1.14\nlibnetcdf\t4.4.1.1\t4.3.3.1\nlibpng\t1.6.28\t1.6.27\nlibpq\t9.5.4\t9.5.4\nlibspatialite\t4.3.0a\t\nlibtiff\t4.0.6\t4.0.6\nlibxml2\t2.9.3\t\nllvmlite\t0.11.0\t0.18.0\nlocket\t0.2.0\t0.2.0\nlogilab-astng\t0.24.3\t\nlogilab-common\t1.2.2\t1.0.2\nlxml\t3.6.0\t3.8.0\nmarkupsafe\t0.23\t0.23\nmarshmallow\t2.13.5\t\nmatplotlib\t1.5.1\t2.0.2\nmenuinst\t1.4.1\t1.4.7\nmistune\t0.7.2\t0.7.4\nmkl\t11.3.3\t2017.0.1\nmkl-service\t1.1.2\t1.1.2\nmlxtend\t0.4.2\t\nmpld3\t0.3\t0.2\nmplleaflet\t0.0.5\t\nmpmath\t0.19\t0.19\nmsgpack-python\t0.4.7\t0.4.8\nmultipledispatch\t0.4.8\t0.4.9\nmysql-connector-python\t2.0.4\t2.0.4\nmystic\t0.2a2.dev0\t\nnb-anacondacloud\t1.1.0\t\nnb-conda\t1.1.0\t\nnb-conda-kernels\t1.0.3\t\nnb_anacondacloud\t1.1.0\t1.2.0\nnb_conda\t1.1.0\t2.0.0\nnb_conda_kernels\t1.0.3\t2.0.0\nnbconvert\t4.2.0\t5.2.1\nnbformat\t4.0.1\t4.3.0\nnbpresent\t3.0.2\t3.0.2\nnetworkx\t1.11\t1.11\nnltk\t3.2.1\t3.2.4\nnose\t1.3.7\t1.3.7\nnotebook\t4.2.3\t5.0.0\nnumba\t0.26.0\t0.33.0\nnumexpr\t2.6.0\t2.6.2\nnumpy\t1.11.1\t1.13.0\noauth2client\t4.0.0\t\nodo\t0.5.0\t0.5.0\nopenjpeg\t2.1.2\t\nopenpyxl\t2.3.2\t2.4.7\nopenssl\t1.0.2h\t1.0.2l\noptcomplete\t1.2-devel\t\norange\t2.7.8\t2.7.8\npandas\t0.19.2\t0.20.2\npandas-gbq\t0.1.6\t\npandasql\t0.7.3\t0.7.3\nparamiko\t2.0.2\t2.1.2\npartd\t0.3.7\t0.3.8\npatch\t2.5.9\t2.5.9\npath.py\t8.2.1\t10.3.1\npath.py\t0.0.0\t10.3.1\npathlib2\t2.1.0\t2.2.1\npatsy\t0.4.1\t0.4.1\npep8\t1.7.0\t1.7.0\npickleshare\t0.7.2\t0.7.4\npillow\t3.2.0\t4.1.1\npip\t8.1.2\t9.0.1\npivottablejs\t0.1.0\t2.7.0\npivottablejs\t2.1.0\t2.7.0\nplotly\t1.12.12\t2.0.9\nply\t3.8\t3.10\nproj4\t4.9.3\t4.9.2\npsutil\t4.0.0\t5.2.2\npsycopg2\t2.6.2\t2.7.1\npy\t1.4.31\t1.4.34\npyOpenSSL\t16.2.0\t\npyasn1\t0.1.9\t0.2.3\npyasn1-modules\t0.0.8\t0.0.8\npycosat\t0.6.1\t0.6.2\npycparser\t2.14\t2.17\npycrypto\t2.6.1\t2.6.1\npycurl\t7.43.0\t7.43.0\npyflakes\t1.2.3\t1.5.0\npygments\t2.1.3\t2.2.0\npygmo\t1.1.5\t\npylint\t0.25.0\t1.6.4\npymysql\t0.7.9\t0.7.9\npyopenssl\t16.2.0\t17.0.0\npyparsing\t2.1.4\t2.1.4\npyqt\t4.11.4\t5.6.0\npyreadline\t2.1\t2.1\npysftp\t0.2.9\t\npystan\t2.14.0.0\t\npytables\t3.4.2\t3.3.0\npytest\t2.9.2\t3.1.1\npython\t2.7.12\t3.6.1\npython-dateutil\t2.5.3\t2.6.0\npython-google-places\t1.4.0\t\npython-weka-wrapper\t0.3.9\t\npytz\t2016.4\t2017.2\npytz\t2017.2\t2017.2\npywin32\t220\t220\npyyaml\t3.11\t3.12\npyzmq\t15.2.0\t16.0.2\nqgrid\t0.3.2\t0.3.2\nqt\t4.8.7\t5.6.2\nqtconsole\t4.2.1\t4.3.0\nqtpy\t1.0.2\t1.2.1\nquandl\t2.8.9\t3.1.0\nregex\t2017.6.23\t\nregex\t2017.06.23\t\nrequests\t2.18.1\t2.14.2\nrequests\t2.12.4\t2.14.2\nrequests-toolbelt\t0.8.0\t\nrope\t0.9.4\t0.9.4\nrsa\t3.4.2\t\nruamel-yaml\t-VERSION\t\nruamel.ordereddict\t0.4.6\t\nruamel.yaml\t0.15.18\t\nruamel_yaml\t0.11.14\t0.11.14\ns3fs\t0.0.8\t0.1.0\ns3fs\t0.0.7\t0.1.0\ns3transfer\t0.1.9\t0.1.10\ns3transfer\t0.1.7\t0.1.10\nscikit-image\t0.12.3\t0.13.0\nscikit-learn\t0.18.1\t0.18.1\nscipy\t0.18.0\t0.19.0\nscp\t0.10.2\t\nseaborn\t0.7.1\t0.7.1\nselenium\t2.53.5\t\nsetuptools\t23.0.0\t27.2.0\nshortuuid\t0.5.0\t\nsimplegeneric\t0.8.1\t0.8.1\nsimplejson\t3.10.0\t3.10.0\nsingledispatch\t3.4.0.3\t3.4.0.3\nsip\t4.16.9\t4.18\nsix\t1.10.0\t1.10.0\nsklearn-deap\t0.1.7\t\nsnowballstemmer\t1.2.1\t1.2.1\nsockjs-tornado\t1.0.3\t1.0.3\nsortedcontainers\t1.5.3\t1.5.7\nsphinx\t1.4.1\t1.6.2\nsphinx-rtd-theme\t0.1.9\t\nsphinx_rtd_theme\t0.1.9\t0.2.4\nspyder\t2.3.9\t3.1.4\nsqlalchemy\t1.0.13\t1.1.10\nsqlite\t3.13.0\t3.13.0\nssl_match_hostname\t3.4.0.2\t3.4.0.2\nstatsmodels\t0.8.0\t0.8.0\ntables\t3.4.2\t\ntablib\t0.11.2\t\ntabulate\t0.7.7\t0.7.5\ntblib\t1.3.0\t1.3.2\ntk\t8.5.18\t8.5.18\ntoolz\t0.8.0\t0.8.2\ntornado\t4.3\t4.5.1\ntpot\t0.6.4\t\ntqdm\t4.8.4\t4.14.0\ntraitlets\t4.3.1\t4.3.2\ntraittypes\t0.0.6\t\ntyping\t3.6.1\t3.6.1\ntzlocal\t1.4\t\numalqurra\t0.2\t\nunicodecsv\t0.14.1\t0.14.1\nupdate-checker\t0.12\t\nupdate_checker\t0.12\t\nuritemplate\t0.6\t\nuritemplate\t3.0.0\t\nurllib3\t1.21.1\t\nvc\t9\t14\nvs2008_runtime\t9.00.30729.1\t9.00.30729.5054\nweka\t1.0.0\t\nwerkzeug\t0.11.10\t0.12.2\nwheel\t0.29.0\t0.29.0\nwhitenoise\t3.3.0\t\nwidgetsnbextension\t1.2.6\t2.0.0\nworkerpool\t0.9.4\t0.9.4\nwsgiref\t0.1.2\t\nxerces-c\t3.1.4\t3.1.4\nxlrd\t1.0.0\t1.0.0\nxlsxwriter\t0.9.2\t0.9.6\nxlwings\t0.7.2\t0.10.4\nxlwt\t1.1.2\t1.2.0\nzict\t0.1.1\t0.1.2\nzlib\t1.2.8\t1.2.8\n\n\n\n\n\n\n\n\n\n\n\n\n\nHypothesis: Independant:\n\nprobaDensity(X,Y) = probaDensity(X) * ProbaDensity(Y)\nDistance in distribution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
			"file": "/D/Dropbox/_text/msg.txt",
			"file_size": 294539,
			"file_write_time": 131923809890000000,
			"settings":
			{
				"buffer_size": 282036,
				"line_ending": "Windows"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"Package Control: ",
				"Package Control: Install Package"
			]
		],
		"width": 0.0
	},
	"console":
	{
		"height": 0.0,
		"history":
		[
		]
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"expanded_folders":
	[
		"/D/_devs/Python01/aws/aapackage"
	],
	"file_history":
	[
		"/D/_devs/Python01/aws/aapackage/batch/util_cpu.py",
		"/D/_devs/Python01/aws/aapackage/batch/util_cpu2.py",
		"/D/_devs/Python01/aws/aapackage/batch/batch_daemon_monitor_cli.py",
		"/D/_devs/Python01/aws/aapackage/batch/util_batch.py",
		"/D/_devs/Python01/aws/_latest.py",
		"/D/_devs/Python01/aws/aapackage/batch/tasks/task_demo/subprocess_pygmo.py",
		"/D/_devs/Python01/aws/aapackage/batch/tasks/task_demo/subprocess_optim.py",
		"/D/_devs/Python01/aws/aapackage/batch/tasks/task_demo/main.py",
		"/D/_devs/Python01/aws/aapackage/_batch/__init__.py",
		"/D/_devs/Python01/aws/aapackage/ztest/ztest_log_all.txt",
		"/D/_devs/Python01/aws/aapackage/_batch/batch_sequencer.py",
		"/D/_devs/Python01/aws/aapackage/_batch/elvis_prod_20160102/batch_b_subprocess_launch.py",
		"/D/_devs/Python01/aws/aapackage/_batch/elvis_prod_20160102/batch_a_tasks_launch.py",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher_old/task/elvis_prod_20160102/elvis_pygmo_optim.py",
		"/D/_devs/Python01/aws/aapackage/_batch/elvis_prod_20160102/pygmo_batch_generic.py",
		"/D/_devs/Python01/aws/aapackage/_batch/elvis_prod_20160102/elvis_pygmo_optim.py",
		"/D/_devs/Python01/aws/aapackage/_batch/elvis_prod_20160102/subprocess_launcher_01.py",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher_old/task/elvis_prod_20160102/subprocess_launcher_01.py",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher_old/task/elvis_prod_20160102/pygmo_batch_generic.py",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher_old/task/elvis_prod_20160102/05_batch_getresults.py",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher_old/task/elvis_prod_20160102/01_batch_param_generator.py",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher_old/task/elvis_prod_20160102/00_AWS_BATCH.py",
		"/D/_devs/Python01/aws/aapackage/zzarchive/aws_zip_latest.py",
		"/D/_devs/Python01/project27/tasks/elvis_prod_20161228/subprocess_launcher_01.py",
		"/D/_devs/Python01/awsdoc/ec_config.json",
		"/C/Users/zenbook/Desktop/START Spot EC2.bat",
		"/D/_devs/Python01/project27/tasks/elvis_prod_20161228/00_AWS_BATCH.py",
		"/D/_devs/Python01/project27/tasks/elvis_prod_20161228/ec2_config.py",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher_old/task/_task_batch_template/01_batch_param_generator.py",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher_old/task/_task_batch_template/ec2_config.py",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher/AWS_BATCH_launcher.py",
		"/D/_devs/Python01/aws/aapackage/batch/batch_monitor/task_parallel.py",
		"/D/_devs/Python01/aws/aapackage/batch/batch_monitor/test_main.py",
		"/D/_devs/Python01/aws/aapackage/batch/batch_monitor/ospipen.py",
		"/D/_devs/Python01/aws/aapackage/batch/batch_monitor/mybatch.py",
		"/D/_devs/Python01/aws/aapackage/batch/batch_monitor/batch.py",
		"/D/_devs/Python01/aws/aapackage/batch/batch_monitor/todo",
		"/D/_devs/Python01/aws/aapackage/batch/batch_monitor/README.md",
		"/D/Downloads/RegistryShortcutsW1064bit/Enable s Folder Win10 64 - Copy.reg",
		"/D/_devs/Python01/project27/zdisks3/results/elvis_prod_28asset_1/output/20170103/batch_20170103_081704872381/output_result.txt",
		"/D/_devs/Python01/aws/ec2_rev2.py",
		"/D/_devs/keypair/oregon/aws_ec2_oregon.pem",
		"/D/_devs/keypair/config.cfg",
		"/D/_devs/Python01/aws/aapackage/zz_ec2_instance.csv",
		"/D/_devs/Python01/py27_win.yml",
		"/D/Dropbox/_text/__credit.txt",
		"/D/_devs/Python01/awsdoc/ec_config2.json",
		"/D/_devs/keypair/config.py",
		"/D/_devs/Python01/aws/ec2_instance.csv",
		"/D/_devs/keypair/aws_access.py",
		"/D/_devs/Python01/aws/arita37/index.html",
		"/D/_devs/Python01/aws/ec2_rev1.py",
		"/D/_devs/Python01/aws/aapackage/batch/batch_old/test_aws.py",
		"/D/app/xplorer2/changes.txt",
		"/D/_devs/Python01/aws/aapackage/batch/batch_old/config.cfg",
		"/D/_devs/Python01/aws/aapackage/batch/aws_batcher_old/task/_task_batch_template/00_AWS_BATCH.py",
		"/D/_devs/Python01/aws/aapackage/.travis.yml",
		"/D/Dropbox/inter_prep.txt",
		"/D/Dropbox/_text/email1.txt",
		"/D/Dropbox/ok",
		"/D/Downloads/Downloads/_NewInstall/MediaMonkey 3.2.0.1294/info.txt",
		"/D/Dropbox/_text/msg.txt",
		"/D/Dropbox/_text/jap_listening.txt",
		"/D/Dropbox/_text/interview3.txt",
		"/D/Dropbox/_text/_raku (asus1-PC's conflicted copy 2017-10-22).txt",
		"/D/Dropbox/_text/interview.txt",
		"/D/Dropbox/_text/japanese.txt",
		"/C/Program Files (x86)/Dropbox/Client/Dropbox.exe",
		"/D/_devs/Python01/project27/cloud/google_cloud_setup.py",
		"/D/_devs/Python01/aws/aapackage/batch/batcher/task_parallel.py",
		"/D/_devs/Python01/aws/aapackage/batch/batcher/aws_batch_launcher/AWS_BATCH_launcher.py",
		"/D/_devs/Python01/aws/aapackage/batch/batcher/todo",
		"/D/_devs/Python01/aws/aapackage/batch/batcher/test_main.py",
		"/D/_devs/Python01/aws/aapackage/tool/codesource.py",
		"/D/_devs/Python01/aws/aapackage/tool/codeanalysis.py",
		"/D/_devs/Python01/project27/github/configmy/configmy/configmy.py",
		"/D/_devs/Python01/project27/github/configmy/zpypi_publish.py",
		"/D/_devs/aws/keypairs/oregon/aws_ec2_oregon.pem",
		"/D/Downloads/ACDSEE/ACD.Systems.ACDSee.Pro.v7.0.137.x64.Incl.Keymaker-CORE/ACD.Systems.ACDSee.Pro.v7.0.137.x64.Incl.Keymaker-CORE/ACD.Systems.ACDSee.Pro.v7.0.137.x64.Incl/CORE.NFO",
		"/D/_devs/Python01/pkensho/cloud/cloud_aws/aws_main.py",
		"/D/_devs/Python01/pkensho/aapackage/__init__.py",
		"/D/app/xplorer64/changes.txt"
	],
	"find":
	{
		"height": 40.0
	},
	"find_in_files":
	{
		"height": 0.0,
		"where_history":
		[
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"noelkev0",
			"conda env",
			"export",
			"':",
			":,",
			"linked",
			"face",
			"xplorer",
			"noelkevin1",
			"passpo"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": false,
		"replace_history":
		[
			"',",
			","
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "/D/Dropbox/_text/email1.txt",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 127650,
						"regions":
						{
						},
						"selection":
						[
							[
								3876,
								3868
							]
						],
						"settings":
						{
							"syntax": "Packages/Text/Plain text.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 3883.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "/D/Dropbox/_text/coding.txt",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 277050,
						"regions":
						{
						},
						"selection":
						[
							[
								26720,
								26670
							]
						],
						"settings":
						{
							"syntax": "Packages/Text/Plain text.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 1101.0,
						"zoom_level": 1.0
					},
					"stack_index": 4,
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "ztodo_list.txt",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 3952,
						"regions":
						{
						},
						"selection":
						[
							[
								0,
								0
							]
						],
						"settings":
						{
							"syntax": "Packages/Text/Plain text.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 736.0,
						"zoom_level": 1.0
					},
					"stack_index": 3,
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "/D/Dropbox/_text/interview3.txt",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 7593,
						"regions":
						{
						},
						"selection":
						[
							[
								461,
								461
							]
						],
						"settings":
						{
							"syntax": "Packages/Text/Plain text.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				},
				{
					"buffer": 4,
					"file": "/D/Dropbox/inter_prep.txt",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 4546,
						"regions":
						{
						},
						"selection":
						[
							[
								0,
								0
							]
						],
						"settings":
						{
							"syntax": "Packages/Text/Plain text.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 5,
					"type": "text"
				},
				{
					"buffer": 5,
					"file": "/D/Dropbox/_text/msg.txt",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 282036,
						"regions":
						{
						},
						"selection":
						[
							[
								1587,
								1587
							]
						],
						"settings":
						{
							"syntax": "Packages/Text/Plain text.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 25.0
	},
	"input":
	{
		"height": 0.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.find_results":
	{
		"height": 0.0
	},
	"pinned_build_system": "",
	"project": "zzsublime.sublime-project",
	"replace":
	{
		"height": 46.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_symbol":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": false,
	"show_open_files": true,
	"show_tabs": true,
	"side_bar_visible": false,
	"side_bar_width": 150.0,
	"status_bar_visible": false,
	"template_settings":
	{
	}
}
